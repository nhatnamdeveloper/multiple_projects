# ğŸ§  Explainable AI (XAI) - Diá»…n giáº£i vÃ  Tin cáº­y trong AI

> **Má»¥c tiÃªu**: Hiá»ƒu táº§m quan trá»ng cá»§a viá»‡c diá»…n giáº£i mÃ´ hÃ¬nh, náº¯m vá»¯ng cÃ¡c ká»¹ thuáº­t phá»• biáº¿n nhÆ° LIME vÃ  SHAP, vÃ  nháº­n thá»©c Ä‘Æ°á»£c cÃ¡c khÃ­a cáº¡nh Ä‘áº¡o Ä‘á»©c liÃªn quan Ä‘áº¿n AI.

## ğŸ“‹ Tá»•ng quan ná»™i dung

```mermaid
graph TD
    A[ğŸ§  Explainable AI] --> B[ğŸ¤” Táº¡i sao cáº§n XAI?]
    A --> C[âš™ï¸ CÃ¡c phÆ°Æ¡ng phÃ¡p diá»…n giáº£i]
    A --> D[ğŸ› ï¸ CÃ´ng cá»¥ Model-Agnostic]
    A --> E[âš–ï¸ Äáº¡o Ä‘á»©c vÃ  Sá»± cÃ´ng báº±ng]
    
    B --> B1[XÃ¢y dá»±ng lÃ²ng tin]
    B --> B2[Debug vÃ  cáº£i thiá»‡n mÃ´ hÃ¬nh]
    B --> B3[TuÃ¢n thá»§ phÃ¡p lÃ½ (GDPR)]
    B --> B4[PhÃ¡t hiá»‡n vÃ  giáº£m thiá»ƒu thiÃªn vá»‹ (bias)]
    
    C --> C1[Global vs. Local Explanations]
    C --> C2[Model-Specific vs. Model-Agnostic]
    C --> C3[Intrinsic vs. Post-hoc]
    
    D --> D1[LIME (Local Interpretable Model-agnostic Explanations)]
    D --> D2[SHAP (SHapley Additive exPlanations)]
    D --> D3[Feature Importance]
    
    E --> E1[Fairness (CÃ´ng báº±ng)]
    E --> E2[Accountability (TrÃ¡ch nhiá»‡m giáº£i trÃ¬nh)]
    E --> E3[Transparency (Minh báº¡ch)]
```

## ğŸ“– 1. Glossary (Äá»‹nh nghÄ©a cá»‘t lÃµi)

-   **Interpretability (Kháº£ nÄƒng diá»…n giáº£i ná»™i táº¡i)**: Má»©c Ä‘á»™ mÃ  má»™t ngÆ°á»i cÃ³ thá»ƒ hiá»ƒu nguyÃªn nhÃ¢n dáº«n Ä‘áº¿n má»™t quyáº¿t Ä‘á»‹nh cá»§a mÃ´ hÃ¬nh. CÃ¡c mÃ´ hÃ¬nh Ä‘Æ¡n giáº£n nhÆ° Linear Regression hay Decision Tree cÃ³ tÃ­nh diá»…n giáº£i ná»™i táº¡i cao.
-   **Explainability (Kháº£ nÄƒng giáº£i thÃ­ch sau hoc)**: Kháº£ nÄƒng giáº£i thÃ­ch cÃ¡c hoáº¡t Ä‘á»™ng bÃªn trong cá»§a má»™t mÃ´ hÃ¬nh phá»©c táº¡p (thÆ°á»ng lÃ  "há»™p Ä‘en" - black box) báº±ng má»™t mÃ´ hÃ¬nh khÃ¡c, Ä‘Æ¡n giáº£n hÆ¡n.
-   **Global Explanation**: Giáº£i thÃ­ch hÃ nh vi tá»•ng thá»ƒ cá»§a mÃ´ hÃ¬nh. *VÃ­ dá»¥: "NhÃ¬n chung, diá»‡n tÃ­ch vÃ  vá»‹ trÃ­ lÃ  hai yáº¿utoos quan trá»ng nháº¥t áº£nh hÆ°á»Ÿng Ä‘áº¿n giÃ¡ nhÃ ."*
-   **Local Explanation**: Giáº£i thÃ­ch lÃ½ do cho má»™t dá»± Ä‘oÃ¡n **cá»¥ thá»ƒ**. *VÃ­ dá»¥: "GiÃ¡ cá»§a ngÃ´i nhÃ  nÃ y Ä‘Æ°á»£c dá»± Ä‘oÃ¡n lÃ  cao vÃ¬ nÃ³ cÃ³ diá»‡n tÃ­ch lá»›n, máº·c dÃ¹ vá»‹ trÃ­ cá»§a nÃ³ khÃ´ng pháº£i lÃ  tá»‘t nháº¥t."*
-   **Model-Agnostic**: PhÆ°Æ¡ng phÃ¡p cÃ³ thá»ƒ Ã¡p dá»¥ng cho báº¥t ká»³ loáº¡i mÃ´ hÃ¬nh nÃ o (Linear Regression, Random Forest, Neural Network, ...).
-   **Model-Specific**: PhÆ°Æ¡ng phÃ¡p chá»‰ hoáº¡t Ä‘á»™ng vá»›i má»™t loáº¡i mÃ´ hÃ¬nh cá»¥ thá»ƒ (vÃ­ dá»¥: xem xÃ©t trá»ng sá»‘ cá»§a Linear Regression).

---

## ğŸ¤” 2. Táº¡i sao XAI láº¡i quan trá»ng?

Khi cÃ¡c mÃ´ hÃ¬nh AI ngÃ y cÃ ng phá»©c táº¡p (nhÆ° Deep Learning) vÃ  Ä‘Æ°á»£c Ã¡p dá»¥ng vÃ o cÃ¡c lÄ©nh vá»±c cÃ³ áº£nh hÆ°á»Ÿng lá»›n (y táº¿, tÃ i chÃ­nh, phÃ¡p luáº­t), cÃ¢u há»i "Táº¡i sao mÃ´ hÃ¬nh láº¡i Ä‘Æ°a ra quyáº¿t Ä‘á»‹nh nÃ y?" trá»Ÿ nÃªn cá»±c ká»³ quan trá»ng.

-   **XÃ¢y dá»±ng lÃ²ng tin**: NgÆ°á»i dÃ¹ng (bÃ¡c sÄ©, nhÃ¢n viÃªn ngÃ¢n hÃ ng, khÃ¡ch hÃ ng) sáº½ khÃ´ng tin tÆ°á»Ÿng má»™t há»‡ thá»‘ng "há»™p Ä‘en" náº¿u khÃ´ng hiá»ƒu lÃ½ do Ä‘áº±ng sau cÃ¡c quyáº¿t Ä‘á»‹nh cá»§a nÃ³.
-   **Debug vÃ  Cáº£i thiá»‡n**: Khi mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n sai, XAI giÃºp ta tÃ¬m ra *táº¡i sao* nÃ³ sai. CÃ³ pháº£i do dá»¯ liá»‡u nhiá»…u, do feature sai, hay do logic cá»§a mÃ´ hÃ¬nh cÃ³ váº¥n Ä‘á»?
-   **PhÃ¡t hiá»‡n ThiÃªn vá»‹ (Bias)**: XAI cÃ³ thá»ƒ phÆ¡i bÃ y viá»‡c mÃ´ hÃ¬nh Ä‘ang dá»±a vÃ o cÃ¡c thuá»™c tÃ­nh nháº¡y cáº£m (nhÆ° giá»›i tÃ­nh, chá»§ng tá»™c) Ä‘á»ƒ Ä‘Æ°a ra quyáº¿t Ä‘á»‹nh, giÃºp ta xÃ¢y dá»±ng cÃ¡c há»‡ thá»‘ng cÃ´ng báº±ng hÆ¡n.
-   **TuÃ¢n thá»§ phÃ¡p lÃ½**: Nhiá»u quy Ä‘á»‹nh (nhÆ° GDPR cá»§a ChÃ¢u Ã‚u) yÃªu cáº§u "quyá»n Ä‘Æ°á»£c giáº£i thÃ­ch" (right to explanation) cho cÃ¡c quyáº¿t Ä‘á»‹nh tá»± Ä‘á»™ng.

---

## âš™ï¸ 3. Tháº» thuáº­t toÃ¡n - LIME (Local Interpretable Model-agnostic Explanations)

### 1. BÃ i toÃ¡n & dá»¯ liá»‡u
- **BÃ i toÃ¡n**: Giáº£i thÃ­ch dá»± Ä‘oÃ¡n cá»§a báº¥t ká»³ mÃ´ hÃ¬nh "há»™p Ä‘en" nÃ o (bá»™ phÃ¢n loáº¡i hoáº·c há»“i quy) báº±ng cÃ¡ch xáº¥p xá»‰ cá»¥c bá»™ nÃ³ báº±ng má»™t mÃ´ hÃ¬nh cÃ³ thá»ƒ diá»…n giáº£i Ä‘Æ°á»£c (linear model, decision tree).
- **Dá»¯ liá»‡u**: Má»™t máº«u dá»¯ liá»‡u Ä‘Æ¡n láº» mÃ  báº¡n muá»‘n giáº£i thÃ­ch dá»± Ä‘oÃ¡n cá»§a nÃ³, cÃ¹ng vá»›i mÃ´ hÃ¬nh "há»™p Ä‘en" Ä‘Ã£ huáº¥n luyá»‡n.
- **á»¨ng dá»¥ng**: Giáº£i thÃ­ch cÃ¡c dá»± Ä‘oÃ¡n cho áº£nh, vÄƒn báº£n, dá»¯ liá»‡u báº£ng.

### 2. MÃ´ hÃ¬nh & cÃ´ng thá»©c
- **Ã tÆ°á»Ÿng cá»‘t lÃµi**: MÃ´ hÃ¬nh phá»©c táº¡p cÃ³ thá»ƒ Ä‘Æ°á»£c xáº¥p xá»‰ báº±ng má»™t mÃ´ hÃ¬nh Ä‘Æ¡n giáº£n hÆ¡n (nhÆ° Linear Regression) trong má»™t vÃ¹ng lÃ¢n cáº­n cá»¥c bá»™ cá»§a Ä‘iá»ƒm dá»¯ liá»‡u cáº§n giáº£i thÃ­ch.
- **CÃ´ng thá»©c (tá»•ng quÃ¡t)**: LIME tá»‘i thiá»ƒu hÃ³a hÃ m máº¥t mÃ¡t:
  $$ \xi(x) = \operatorname*{argmin}_{g \in \mathcal{G}} \mathcal{L}(f, g, \pi_x) + \Omega(g) $$
  Trong Ä‘Ã³:
  -   $f$: MÃ´ hÃ¬nh "há»™p Ä‘en" gá»‘c.
  -   $g$: MÃ´ hÃ¬nh cÃ³ thá»ƒ diá»…n giáº£i Ä‘Æ°á»£c (linear, tree).
  -   $\pi_x$: HÃ m trá»ng sá»‘ thá»ƒ hiá»‡n khoáº£ng cÃ¡ch cá»§a máº«u Ä‘Æ°á»£c nhiá»…u Ä‘áº¿n máº«u gá»‘c $x$.
  -   $\mathcal{L}(f, g, \pi_x)$: HÃ m Ä‘o lÆ°á»ng má»©c Ä‘á»™ $g$ xáº¥p xá»‰ $f$ trong vÃ¹ng lÃ¢n cáº­n cá»§a $x$.
  -   $\Omega(g)$: HÃ m Ä‘á»™ phá»©c táº¡p cá»§a mÃ´ hÃ¬nh $g$ (vÃ­ dá»¥: sá»‘ feature trong linear model).

### 3. Loss & má»¥c tiÃªu
- **Má»¥c tiÃªu**: TÃ¬m má»™t mÃ´ hÃ¬nh $g$ Ä‘Æ¡n giáº£n, cÃ³ thá»ƒ diá»…n giáº£i Ä‘Æ°á»£c, xáº¥p xá»‰ tá»‘t mÃ´ hÃ¬nh $f$ phá»©c táº¡p trong vÃ¹ng lÃ¢n cáº­n cá»§a máº«u $x$ cáº§n giáº£i thÃ­ch.

### 4. Tá»‘i Æ°u hoÃ¡ & cáº­p nháº­t
- **Algorithm**:
  1.  Táº¡o cÃ¡c máº«u dá»¯ liá»‡u nhiá»…u xung quanh máº«u gá»‘c $x$.
  2.  Thu tháº­p dá»± Ä‘oÃ¡n cá»§a mÃ´ hÃ¬nh $f$ cho cÃ¡c máº«u nhiá»…u nÃ y.
  3.  TÃ­nh trá»ng sá»‘ cho cÃ¡c máº«u nhiá»…u dá»±a trÃªn khoáº£ng cÃ¡ch cá»§a chÃºng Ä‘áº¿n $x$.
  4.  Huáº¥n luyá»‡n má»™t mÃ´ hÃ¬nh $g$ Ä‘Æ¡n giáº£n (vÃ­ dá»¥: Linear Regression) trÃªn cÃ¡c máº«u nhiá»…u vÃ  dá»± Ä‘oÃ¡n cá»§a $f$, cÃ³ tÃ­nh Ä‘áº¿n trá»ng sá»‘.
  5.  CÃ¡c há»‡ sá»‘ cá»§a $g$ chÃ­nh lÃ  lá»i giáº£i thÃ­ch.

### 5. Hyperparams
- **Sá»‘ máº«u nhiá»…u**: Sá»‘ lÆ°á»£ng máº«u Ä‘Æ°á»£c táº¡o ra xung quanh máº«u gá»‘c.
- **Kernel width**: Pháº¡m vi cá»§a hÃ m trá»ng sá»‘ $\pi_x$.
- **Sá»‘ feature trong mÃ´ hÃ¬nh diá»…n giáº£i**: GiÃºp kiá»ƒm soÃ¡t Ä‘á»™ phá»©c táº¡p cá»§a $g$.

### 6. Äá»™ phá»©c táº¡p
- **Time**: Phá»¥ thuá»™c vÃ o sá»‘ máº«u nhiá»…u vÃ  thá»i gian dá»± Ä‘oÃ¡n cá»§a mÃ´ hÃ¬nh "há»™p Ä‘en".
- **Space**: KhÃ´ng Ä‘Ã¡ng ká»ƒ.

### 7. Metrics Ä‘Ã¡nh giÃ¡
- **Äá»™ tin cáº­y cá»§a giáº£i thÃ­ch**: LIME khÃ´ng cÃ³ metric ná»™i táº¡i, cáº§n Ä‘Ã¡nh giÃ¡ qua trá»±c quan hÃ³a vÃ  kiá»ƒm tra.
- **Local fidelity**: Kiá»ƒm tra xem mÃ´ hÃ¬nh $g$ cÃ³ thá»±c sá»± xáº¥p xá»‰ tá»‘t $f$ trong vÃ¹ng cá»¥c bá»™ khÃ´ng.

### 8. Æ¯u / NhÆ°á»£c Ä‘iá»ƒm
**Æ¯u Ä‘iá»ƒm**:
-   **Model-Agnostic**: Ãp dá»¥ng Ä‘Æ°á»£c cho má»i mÃ´ hÃ¬nh.
-   **Local Explanation**: Cung cáº¥p giáº£i thÃ­ch cho tá»«ng dá»± Ä‘oÃ¡n cá»¥ thá»ƒ.
-   Dá»… hiá»ƒu vÃ  trá»±c quan hÃ³a.

**NhÆ°á»£c Ä‘iá»ƒm**:
-   **TÃ­nh khÃ´ng á»•n Ä‘á»‹nh (Instability)**: CÃ¡c lá»i giáº£i thÃ­ch cÃ³ thá»ƒ thay Ä‘á»•i Ä‘Ã¡ng ká»ƒ náº¿u cÃ¡c máº«u nhiá»…u Ä‘Æ°á»£c táº¡o ra khÃ¡c nhau má»™t chÃºt.
-   **Pháº¡m vi cá»¥c bá»™**: Giáº£i thÃ­ch chá»‰ cÃ³ giÃ¡ trá»‹ trong má»™t vÃ¹ng nhá», khÃ´ng thá»ƒ khÃ¡i quÃ¡t hÃ³a toÃ n cá»¥c.
-   Cáº§n xÃ¡c Ä‘á»‹nh cÃ¡c hyperparameter (sá»‘ máº«u nhiá»…u, kernel width).

### 9. Báº«y & máº¹o
- **Báº«y**: Chá»n sá»‘ máº«u nhiá»…u quÃ¡ Ã­t hoáº·c kernel width quÃ¡ lá»›n cÃ³ thá»ƒ dáº«n Ä‘áº¿n giáº£i thÃ­ch sai lá»‡ch.
- **Máº¹o**: Káº¿t há»£p vá»›i Domain Knowledge Ä‘á»ƒ kiá»ƒm tra tÃ­nh há»£p lÃ½ cá»§a giáº£i thÃ­ch.
- **Máº¹o**: LuÃ´n trá»±c quan hÃ³a káº¿t quáº£ Ä‘á»ƒ hiá»ƒu rÃµ hÆ¡n.

### 10. Pseudocode:
```python
def LIME_explanation(model, instance, num_perturbations, feature_names, kernel_width):
    # 1. Generate perturbed samples
    perturbed_samples, distances = generate_samples_around_instance(instance, num_perturbations, kernel_width)
    
    # 2. Get predictions from black-box model
    predictions = model.predict(perturbed_samples)
    
    # 3. Compute weights based on distance
    weights = calculate_weights(distances)
    
    # 4. Train an interpretable model (e.g., Weighted Linear Regression)
    interpretable_model = train_weighted_linear_model(perturbed_samples, predictions, weights)
    
    # 5. Extract explanation (e.g., coefficients)
    explanation = get_coefficients(interpretable_model, feature_names)
    
    return explanation
```

### 11. Code máº«u (LIME cho mÃ´ hÃ¬nh phÃ¢n loáº¡i vÄƒn báº£n)
```python
import lime
import lime.lime_text
from sklearn.pipeline import make_pipeline
from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.datasets import fetch_20newsgroups

# 1. Load data vÃ  train mÃ´ hÃ¬nh Ä‘Æ¡n giáº£n
categories = ['alt.atheism', 'soc.religion.christian']
newsgroups_train = fetch_20newsgroups(subset='train', categories=categories, remove=('headers', 'footers', 'quotes'))
newsgroups_test = fetch_20newsgroups(subset='test', categories=categories, remove=('headers', 'footers', 'quotes'))

vectorizer = TfidfVectorizer(lowercase=False)
train_vectors = vectorizer.fit_transform(newsgroups_train.data)
test_vectors = vectorizer.transform(newsgroups_test.data)

rf_model = RandomForestClassifier(n_estimators=500, random_state=42)
rf_model.fit(train_vectors, newsgroups_train.target)

# 2. Chá»n má»™t instance Ä‘á»ƒ giáº£i thÃ­ch
idx = 8
text_instance = newsgroups_test.data[idx]
true_class = newsgroups_test.target_names[newsgroups_test.target[idx]]
predicted_class = newsgroups_test.target_names[rf_model.predict(test_vectors[idx])[0]]

print(f"Máº«u vÄƒn báº£n:\n{text_instance}")
print(f"Lá»›p tháº­t: {true_class}, Lá»›p dá»± Ä‘oÃ¡n: {predicted_class}")

# 3. Khá»Ÿi táº¡o LIME Explainer
# HÃ m predict_proba cá»§a mÃ´ hÃ¬nh cáº§n Ä‘Æ°á»£c cung cáº¥p cho LIME
c = make_pipeline(vectorizer, rf_model)
explainer = lime.lime_text.LimeTextExplainer(
    class_names=newsgroups_train.target_names,
    split_expression=r'\W+', # TÃ¡ch tá»« theo khoáº£ng tráº¯ng/kÃ½ tá»± khÃ´ng pháº£i tá»«
    random_state=42
)

# 4. Giáº£i thÃ­ch dá»± Ä‘oÃ¡n
num_features = 10 # Sá»‘ lÆ°á»£ng tá»« quan trá»ng muá»‘n hiá»ƒn thá»‹
explanation = explainer.explain_instance(
    text_instance, 
    c.predict_proba, 
    num_features=num_features, 
    labels=(rf_model.predict(test_vectors[idx])[0],) # Chá»‰ giáº£i thÃ­ch cho lá»›p dá»± Ä‘oÃ¡n
)

print("\n--- Giáº£i thÃ­ch LIME ---")
# CÃ¡c tá»« cÃ³ trá»ng sá»‘ dÆ°Æ¡ng Ä‘áº©y dá»± Ä‘oÃ¡n vá» lá»›p má»¥c tiÃªu, Ã¢m Ä‘áº©y ra xa
for word, weight in explanation.as_list():
    print(f"'{word}': {weight:.4f}")

# explanation.show_in_notebook(text=True) # DÃ¹ng trong Jupyter Notebook Ä‘á»ƒ trá»±c quan hÃ³a
```

### 12. Checklist kiá»ƒm tra nhanh:
- [ ] LIME cÃ³ Ä‘Æ°á»£c Ã¡p dá»¥ng cho má»™t máº«u cá»¥ thá»ƒ khÃ´ng?
- [ ] Sá»‘ feature Ä‘Æ°á»£c hiá»ƒn thá»‹ cÃ³ phÃ¹ há»£p khÃ´ng?
- [ ] Giáº£i thÃ­ch cÃ³ phÃ¹ há»£p vá»›i kiáº¿n thá»©c nghiá»‡p vá»¥ khÃ´ng?
- [ ] CÃ¡c tham sá»‘ (num_features, kernel_width) cÃ³ Ä‘Æ°á»£c Ä‘iá»u chá»‰nh Ä‘á»ƒ giáº£i thÃ­ch tá»‘t nháº¥t khÃ´ng?

ÄÃ¢y lÃ  cÃ¡c cÃ´ng cá»¥ máº¡nh máº½ nháº¥t vÃ¬ chÃºng cÃ³ thá»ƒ Ä‘Æ°á»£c Ã¡p dá»¥ng cho báº¥t ká»³ mÃ´ hÃ¬nh nÃ o sau khi Ä‘Ã£ huáº¥n luyá»‡n xong.

### 4.1 LIME (Local Interpretable Model-agnostic Explanations)

-   **TÆ° tÆ°á»Ÿng cá»‘t lÃµi**: "Máº·c dÃ¹ má»™t mÃ´ hÃ¬nh phá»©c táº¡p cÃ³ thá»ƒ cÃ³ ranh giá»›i quyáº¿t Ä‘á»‹nh ráº¥t ngoáº±n ngoÃ¨o trÃªn toÃ n cá»¥c, nhÆ°ng á»Ÿ má»™t khu vá»±c **cá»¥c bá»™ (local)** ráº¥t nhá» xung quanh má»™t Ä‘iá»ƒm dá»¯ liá»‡u, ranh giá»›i Ä‘Ã³ cÃ³ thá»ƒ Ä‘Æ°á»£c xáº¥p xá»‰ báº±ng má»™t mÃ´ hÃ¬nh Ä‘Æ¡n giáº£n (nhÆ° má»™t Ä‘Æ°á»ng tháº³ng)."
-   **Quy trÃ¬nh hoáº¡t Ä‘á»™ng (Ä‘á»ƒ giáº£i thÃ­ch má»™t dá»± Ä‘oÃ¡n)**:
    1.  **Chá»n má»™t máº«u dá»¯ liá»‡u** báº¡n muá»‘n giáº£i thÃ­ch (vÃ­ dá»¥: má»™t khÃ¡ch hÃ ng cá»¥ thá»ƒ Ä‘Æ°á»£c dá»± Ä‘oÃ¡n lÃ  sáº½ churn).
    2.  **Táº¡o dá»¯ liá»‡u giáº£ (Perturbation)**: LIME táº¡o ra hÃ ng trÄƒm/nghÃ¬n máº«u dá»¯ liá»‡u má»›i báº±ng cÃ¡ch thay Ä‘á»•i má»™t chÃºt cÃ¡c feature cá»§a máº«u gá»‘c (vÃ­ dá»¥: thay Ä‘á»•i `monthly_charges` má»™t chÃºt, hoáº·c xÃ³a má»™t vÃ i tá»« trong má»™t cÃ¢u vÄƒn báº£n).
    3.  **Láº¥y dá»± Ä‘oÃ¡n tá»« mÃ´ hÃ¬nh há»™p Ä‘en**: ÄÆ°a táº¥t cáº£ cÃ¡c máº«u dá»¯ liá»‡u giáº£ nÃ y qua mÃ´ hÃ¬nh phá»©c táº¡p cá»§a báº¡n Ä‘á»ƒ láº¥y dá»± Ä‘oÃ¡n cá»§a nÃ³.
    4.  **Huáº¥n luyá»‡n má»™t mÃ´ hÃ¬nh Ä‘Æ¡n giáº£n**: BÃ¢y giá», LIME huáº¥n luyá»‡n má»™t mÃ´ hÃ¬nh tuyáº¿n tÃ­nh Ä‘Æ¡n giáº£n (cÃ³ thá»ƒ diá»…n giáº£i Ä‘Æ°á»£c) Ä‘á»ƒ há»c cÃ¡ch Ã¡nh xáº¡ tá»« cÃ¡c máº«u dá»¯ liá»‡u giáº£ Ä‘áº¿n dá»± Ä‘oÃ¡n cá»§a mÃ´ hÃ¬nh há»™p Ä‘en. CÃ¡c máº«u giáº£ á»Ÿ gáº§n máº«u gá»‘c sáº½ Ä‘Æ°á»£c gÃ¡n trá»ng sá»‘ cao hÆ¡n.
    5.  **Diá»…n giáº£i mÃ´ hÃ¬nh Ä‘Æ¡n giáº£n**: CÃ¡c trá»ng sá»‘ cá»§a mÃ´ hÃ¬nh tuyáº¿n tÃ­nh nÃ y chÃ­nh lÃ  lá»i giáº£i thÃ­ch. Má»™t trá»ng sá»‘ dÆ°Æ¡ng lá»›n cho má»™t feature cÃ³ nghÄ©a lÃ  feature Ä‘Ã³ Ä‘Ã£ "Ä‘áº©y" dá»± Ä‘oÃ¡n lÃªn cao, vÃ  ngÆ°á»£c láº¡i.

-   **Káº¿t quáº£**: "Dá»± Ä‘oÃ¡n cho khÃ¡ch hÃ ng nÃ y lÃ  'Churn' **bá»Ÿi vÃ¬** `contract_type` lÃ  'Month-to-month' (Ä‘Ã³ng gÃ³p +0.4) vÃ  `tenure` tháº¥p (Ä‘Ã³ng gÃ³p +0.3), máº·c dÃ¹ `monthly_charges` khÃ´ng cao (Ä‘Ã³ng gÃ³p -0.1)."

#### VÃ­ dá»¥ Code: Giáº£i thÃ­ch phÃ¢n loáº¡i áº£nh vá»›i LIME

ÄÃ¢y lÃ  vÃ­ dá»¥ sá»­ dá»¥ng LIME Ä‘á»ƒ giáº£i thÃ­ch dá»± Ä‘oÃ¡n cá»§a má»™t mÃ´ hÃ¬nh phÃ¢n loáº¡i áº£nh (vÃ­ dá»¥: InceptionV3 trÃªn ImageNet). LIME sáº½ chá»‰ ra nhá»¯ng vÃ¹ng pixel nÃ o trong áº£nh Ä‘Ã£ Ä‘Ã³ng gÃ³p nhiá»u nháº¥t vÃ o dá»± Ä‘oÃ¡n cá»§a mÃ´ hÃ¬nh.

```python
import numpy as np
import requests
from PIL import Image
from io import BytesIO
import matplotlib.pyplot as plt
from skimage.segmentation import mark_boundaries

# ThÆ° viá»‡n LIME
import lime
from lime import lime_image

# PyTorch
import torch
import torch.nn.functional as F
from torchvision import models, transforms

# 1. Táº£i mÃ´ hÃ¬nh vÃ  tiá»n xá»­ lÃ½ áº£nh
# Táº£i mÃ´ hÃ¬nh InceptionV3 Ä‘Ã£ Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c trÃªn ImageNet
model = models.inception_v3(pretrained=True, aux_logits=True)
model.eval() # Chuyá»ƒn sang cháº¿ Ä‘á»™ Ä‘Ã¡nh giÃ¡

# Tiá»n xá»­ lÃ½ áº£nh cho InceptionV3
preprocess = transforms.Compose([
    transforms.Resize(299),
    transforms.CenterCrop(299),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

# 2. Táº£i vÃ  xá»­ lÃ½ nhÃ£n ImageNet
LABELS_URL = "https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json"
response = requests.get(LABELS_URL)
labels_map = response.json()
idx2label = [labels_map[str(k)][1] for k in range(len(labels_map))]

# 3. Äá»‹nh nghÄ©a hÃ m dá»± Ä‘oÃ¡n cá»§a mÃ´ hÃ¬nh cho LIME
# LIME yÃªu cáº§u hÃ m predict_proba tráº£ vá» xÃ¡c suáº¥t cho táº¥t cáº£ cÃ¡c lá»›p
def predict_fn(images):
    # images lÃ  má»™t máº£ng numpy (num_samples, H, W, C)
    # Cáº§n chuyá»ƒn Ä‘á»•i vá» tensor vÃ  Ä‘á»‹nh dáº¡ng (num_samples, C, H, W)
    images_tensor = torch.stack([preprocess(Image.fromarray((img * 255).astype(np.uint8))) for img in images])
    with torch.no_grad():
        logits = model(images_tensor)
    if isinstance(logits, tuple): # InceptionV3 cÃ³ aux_logits
        logits = logits[0]
    return F.softmax(logits, dim=1).numpy()

# 4. Táº£i áº£nh máº«u
img_url = "https://raw.githubusercontent.com/marcotcr/lime/master/doc/notebooks/7_5.png"
response = requests.get(img_url)
img_original = Image.open(BytesIO(response.content)).convert('RGB')
img_np = np.array(img_original) / 255.0 # Chuyá»ƒn vá» float [0, 1]

# Dá»± Ä‘oÃ¡n ban Ä‘áº§u cá»§a mÃ´ hÃ¬nh
logits_orig = model(preprocess(img_original).unsqueeze(0))
if isinstance(logits_orig, tuple):
    logits_orig = logits_orig[0]
pred_class_idx = torch.argmax(logits_orig).item()
pred_class_name = idx2label[pred_class_idx]
print(f"MÃ´ hÃ¬nh dá»± Ä‘oÃ¡n: {pred_class_name} (Class ID: {pred_class_idx})")

# 5. Khá»Ÿi táº¡o LIMEImageExplainer
explainer = lime_image.LimeImageExplainer(random_state=42)

# 6. Giáº£i thÃ­ch dá»± Ä‘oÃ¡n cá»§a mÃ´ hÃ¬nh
# num_samples: sá»‘ lÆ°á»£ng áº£nh nhiá»…u Ä‘á»ƒ táº¡o ra
# batch_size: sá»‘ lÆ°á»£ng áº£nh Ä‘Æ°a vÃ o predict_fn cÃ¹ng lÃºc
explanation = explainer.explain_instance(
    img_np, 
    predict_fn, 
    top_labels=5, 
    hide_color=0, 
    num_samples=1000, 
    batch_size=50
)

# 7. Trá»±c quan hÃ³a káº¿t quáº£
temp, mask = explanation.get_image_and_mask(
    explanation.top_labels[0], 
    positive_only=False, 
    num_features=10, 
    hide_rest=False
)

# Váº½ áº£nh gá»‘c vÃ  giáº£i thÃ­ch
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))
ax1.imshow(img_np)
ax1.set_title("áº¢nh gá»‘c")
ax1.axis('off')

# LIME explanation (vÃ¹ng áº£nh quan trá»ng Ä‘Æ°á»£c highlight)
ax2.imshow(mark_boundaries(temp / 2 + 0.5, mask))
ax2.set_title(f"LIME giáº£i thÃ­ch cho: {idx2label[explanation.top_labels[0]]}")
ax2.axis('off')
plt.tight_layout()
plt.show()

# Hiá»ƒn thá»‹ cÃ¡c giáº£i thÃ­ch chi tiáº¿t hÆ¡n cho cÃ¡c lá»›p khÃ¡c
# for label in explanation.top_labels:
#     print(f"\nGiáº£i thÃ­ch cho lá»›p '{idx2label[label]}':")
#     image, mask = explanation.get_image_and_mask(label, positive_only=True, num_features=5, hide_rest=True)
#     plt.imshow(image / 2 + 0.5)
#     plt.title(f"LIME cho lá»›p: {idx2label[label]}")
#     plt.axis('off')
#     plt.show()
```

### 4.2 SHAP (SHapley Additive exPlanations)

-   **TÆ° tÆ°á»Ÿng cá»‘t lÃµi**: Dá»±a trÃªn **GiÃ¡ trá»‹ Shapley** tá»« lÃ½ thuyáº¿t trÃ² chÆ¡i há»£p tÃ¡c. SHAP tÃ­nh toÃ¡n sá»± "Ä‘Ã³ng gÃ³p" cÃ´ng báº±ng cá»§a má»—i feature vÃ o viá»‡c táº¡o ra dá»± Ä‘oÃ¡n cuá»‘i cÃ¹ng cá»§a mÃ´ hÃ¬nh. GiÃ¡ trá»‹ Shapley cho má»—i feature lÃ  má»©c Ä‘Ã³ng gÃ³p trung bÃ¬nh mÃ  feature Ä‘Ã³ mang láº¡i cho dá»± Ä‘oÃ¡n trÃªn táº¥t cáº£ cÃ¡c káº¿t há»£p (coalitions) cÃ³ thá»ƒ cÃ³ cá»§a cÃ¡c feature.
-   **CÃ¢u há»i nÃ³ tráº£ lá»i**: "GiÃ¡ trá»‹ cá»§a feature X Ä‘Ã£ lÃ m thay Ä‘á»•i dá»± Ä‘oÃ¡n cuá»‘i cÃ¹ng bao nhiÃªu so vá»›i dá»± Ä‘oÃ¡n trung bÃ¬nh (baseline) cá»§a mÃ´ hÃ¬nh?"
-   **CÃ¡ch hoáº¡t Ä‘á»™ng (trá»±c quan)**:
    -   Äá»ƒ tÃ­nh Ä‘Ã³ng gÃ³p cá»§a feature `tuá»•i` cho má»™t dá»± Ä‘oÃ¡n cá»¥ thá»ƒ, SHAP xem xÃ©t táº¥t cáº£ cÃ¡c táº­p con feature cÃ³ thá»ƒ cÃ³.
    -   NÃ³ so sÃ¡nh dá»± Ä‘oÃ¡n cá»§a mÃ´ hÃ¬nh khi cÃ³ feature `tuá»•i` vÃ  khi khÃ´ng cÃ³ feature `tuá»•i` (thÆ°á»ng Ä‘Æ°á»£c thay tháº¿ báº±ng giÃ¡ trá»‹ trung bÃ¬nh hoáº·c ngáº«u nhiÃªn tá»« dá»¯ liá»‡u khÃ¡c) trong má»i bá»‘i cáº£nh káº¿t há»£p feature khÃ¡c nhau.
    -   ÄÃ³ng gÃ³p cá»§a `tuá»•i` Ä‘Æ°á»£c tÃ­nh lÃ  sá»± thay Ä‘á»•i trung bÃ¬nh trong dá»± Ä‘oÃ¡n trÃªn táº¥t cáº£ cÃ¡c bá»‘i cáº£nh nÃ y.
-   **Æ¯u Ä‘iá»ƒm so vá»›i LIME**:
    -   **Ná»n táº£ng lÃ½ thuyáº¿t vá»¯ng cháº¯c**: Dá»±a trÃªn giÃ¡ trá»‹ Shapley, cÃ³ cÃ¡c thuá»™c tÃ­nh toÃ¡n há»c tá»‘t (local accuracy, missingness, consistency) Ä‘áº£m báº£o sá»± cÃ´ng báº±ng vÃ  nháº¥t quÃ¡n cá»§a giáº£i thÃ­ch.
    -   **Giáº£i thÃ­ch toÃ n cá»¥c vÃ  cá»¥c bá»™**: SHAP cÃ³ thá»ƒ cung cáº¥p cáº£ giáº£i thÃ­ch cho tá»«ng dá»± Ä‘oÃ¡n riÃªng láº» (local) vÃ  tÃ³m táº¯t táº§m quan trá»ng cá»§a feature trÃªn toÃ n bá»™ táº­p dá»¯ liá»‡u (global) má»™t cÃ¡ch nháº¥t quÃ¡n.
-   **CÃ¡c loáº¡i biá»ƒu Ä‘á»“ phá»• biáº¿n**:
    -   **Force Plot**: Trá»±c quan hÃ³a cÃ¡c feature "Ä‘áº©y" dá»± Ä‘oÃ¡n lÃªn hoáº·c xuá»‘ng so vá»›i baseline cho má»™t máº«u cá»¥ thá»ƒ.
    -   **Summary Plot**: Tá»•ng há»£p táº§m quan trá»ng vÃ  hÆ°á»›ng áº£nh hÆ°á»Ÿng cá»§a táº¥t cáº£ cÃ¡c feature trÃªn nhiá»u máº«u, cho tháº¥y bá»©c tranh toÃ n cáº£nh vá» cÃ¡ch mÃ´ hÃ¬nh hoáº¡t Ä‘á»™ng.
    -   **Dependence Plot**: Hiá»ƒn thá»‹ tÃ¡c Ä‘á»™ng cá»§a má»™t feature lÃªn dá»± Ä‘oÃ¡n cá»§a mÃ´ hÃ¬nh, vÃ  cÃ¡ch tÃ¡c Ä‘á»™ng nÃ y thay Ä‘á»•i khi má»™t feature khÃ¡c thay Ä‘á»•i.

#### VÃ­ dá»¥ Code: Giáº£i thÃ­ch mÃ´ hÃ¬nh báº£ng vá»›i SHAP

ÄÃ¢y lÃ  vÃ­ dá»¥ sá»­ dá»¥ng SHAP Ä‘á»ƒ giáº£i thÃ­ch dá»± Ä‘oÃ¡n cá»§a má»™t mÃ´ hÃ¬nh `RandomForestClassifier` trÃªn bá»™ dá»¯ liá»‡u `Iris`.

```python
import pandas as pd
import numpy as np
import shap
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.datasets import load_iris
import matplotlib.pyplot as plt

# 1. Load dá»¯ liá»‡u vÃ  huáº¥n luyá»‡n mÃ´ hÃ¬nh
iris = load_iris()
X, y = iris.data, iris.target
feature_names = iris.feature_names
target_names = iris.target_names

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# 2. Chá»n má»™t instance Ä‘á»ƒ giáº£i thÃ­ch
instance_idx = 5 # Chá»n máº«u thá»© 5 trong táº­p test
instance_to_explain = X_test[instance_idx]
true_class = target_names[y_test[instance_idx]]
predicted_class_idx = model.predict(instance_to_explain.reshape(1, -1))[0]
predicted_class_name = target_names[predicted_class_idx]

print(f"Máº«u dá»¯ liá»‡u cáº§n giáº£i thÃ­ch: {instance_to_explain}")
print(f"Lá»›p tháº­t: {true_class}, Lá»›p dá»± Ä‘oÃ¡n: {predicted_class_name}")

# 3. Khá»Ÿi táº¡o SHAP Explainer
# Äá»‘i vá»›i tree-based models, TreeExplainer hiá»‡u quáº£ hÆ¡n
explainer = shap.TreeExplainer(model)

# TÃ­nh toÃ¡n SHAP values cho máº«u cáº§n giáº£i thÃ­ch
# shap_values lÃ  má»™t list, má»—i pháº§n tá»­ lÃ  SHAP values cho má»™t lá»›p
shap_values = explainer.shap_values(instance_to_explain)

# 4. Trá»±c quan hÃ³a káº¿t quáº£ (Force Plot)
# Force plot cho tháº¥y cÃ¡ch cÃ¡c feature Ä‘áº©y dá»± Ä‘oÃ¡n tá»« baseline (expected value) Ä‘áº¿n giÃ¡ trá»‹ cuá»‘i cÃ¹ng.
print("\n--- SHAP Force Plot cho máº«u cá»¥ thá»ƒ ---")
# Index cá»§a lá»›p dá»± Ä‘oÃ¡n
class_id_to_explain = predicted_class_idx
shap.initjs() # Cáº§n thiáº¿t Ä‘á»ƒ hiá»ƒn thá»‹ interactive plot trong Jupyter
shap.force_plot(
    explainer.expected_value[class_id_to_explain], 
    shap_values[class_id_to_explain], 
    instance_to_explain, 
    feature_names=feature_names,
    matplotlib=True # Force plot to render as static Matplotlib figure
)
plt.title(f"SHAP Force Plot cho lá»›p: {predicted_class_name}")
plt.tight_layout()
plt.show()

# 5. SHAP Summary Plot (Global Explanation)
# Hiá»ƒn thá»‹ táº§m quan trá»ng vÃ  hÆ°á»›ng áº£nh hÆ°á»Ÿng cá»§a cÃ¡c feature trÃªn toÃ n bá»™ táº­p dá»¯ liá»‡u
print("\n--- SHAP Summary Plot (Global) ---")
shap_values_test = explainer.shap_values(X_test)
# Äá»‘i vá»›i multi-class, thÆ°á»ng chá»n shap_values cho lá»›p dÆ°Æ¡ng (hoáº·c lá»›p dá»± Ä‘oÃ¡n)
shap.summary_plot(
    shap_values_test, 
    X_test, 
    feature_names=feature_names, 
    class_names=target_names,
    show=False # Don't show immediately for better control
)
plt.title("SHAP Summary Plot (Iris Dataset)")
plt.tight_layout()
plt.show()

# 6. SHAP Dependence Plot (Feature Interaction)
# Hiá»ƒn thá»‹ má»‘i quan há»‡ giá»¯a má»™t feature vÃ  dá»± Ä‘oÃ¡n, cÃ³ thá»ƒ tháº¥y tÆ°Æ¡ng tÃ¡c vá»›i feature khÃ¡c
print("\n--- SHAP Dependence Plot (Feature Interaction) ---")
# VÃ­ dá»¥: TÃ¡c Ä‘á»™ng cá»§a 'petal length (cm)' lÃªn dá»± Ä‘oÃ¡n, tÆ°Æ¡ng tÃ¡c vá»›i 'petal width (cm)'
shap.dependence_plot(
    "petal length (cm)", 
    shap_values_test[predicted_class_idx], 
    X_test, 
    feature_names=feature_names,
    interaction_index="petal width (cm)",
    show=False
)
plt.title(f"SHAP Dependence Plot: petal length (cm) vs petal width (cm) for {predicted_class_name}")
plt.tight_layout()
plt.show()
```
---

## âš–ï¸ 4. Äáº¡o Ä‘á»©c vÃ  Sá»± cÃ´ng báº±ng trong AI (AI Ethics & Fairness)

XAI khÃ´ng chá»‰ lÃ  má»™t cÃ´ng cá»¥ ká»¹ thuáº­t mÃ  cÃ²n lÃ  ná»n táº£ng cho viá»‡c xÃ¢y dá»±ng cÃ¡c há»‡ thá»‘ng AI cÃ³ trÃ¡ch nhiá»‡m.

-   **Fairness (CÃ´ng báº±ng)**: XAI giÃºp phÃ¡t hiá»‡n xem mÃ´ hÃ¬nh cÃ³ Ä‘ang Ä‘Æ°a ra cÃ¡c quyáº¿t Ä‘á»‹nh báº¥t lá»£i má»™t cÃ¡ch cÃ³ há»‡ thá»‘ng cho má»™t nhÃ³m ngÆ°á»i cá»¥ thá»ƒ nÃ o Ä‘Ã³ hay khÃ´ng (vÃ­ dá»¥: tá»« chá»‘i cho vay Ä‘á»‘i vá»›i má»™t giá»›i tÃ­nh hoáº·c chá»§ng tá»™c nháº¥t Ä‘á»‹nh).
-   **Accountability (TrÃ¡ch nhiá»‡m giáº£i trÃ¬nh)**: Khi má»™t há»‡ thá»‘ng AI gÃ¢y ra lá»—i (vÃ­ dá»¥: xe tá»± lÃ¡i gÃ¢y tai náº¡n), XAI giÃºp truy váº¿t vÃ  xÃ¡c Ä‘á»‹nh thÃ nh pháº§n nÃ o trong mÃ´ hÃ¬nh Ä‘Ã£ gÃ¢y ra quyáº¿t Ä‘á»‹nh sai láº§m Ä‘Ã³.
-   **Transparency (Minh báº¡ch)**: Cung cáº¥p sá»± minh báº¡ch vá» cÃ¡ch cÃ¡c quyáº¿t Ä‘á»‹nh Ä‘Æ°á»£c Ä‘Æ°a ra, giÃºp xÃ¢y dá»±ng lÃ²ng tin vÃ  cho phÃ©p sá»± giÃ¡m sÃ¡t tá»« bÃªn ngoÃ i.

## ğŸ¯ 5. BÃ i táº­p vÃ  Tham kháº£o

### 5.1 BÃ i táº­p thá»±c hÃ nh
1.  **PhÃ¢n tÃ­ch Feature Importance**: Huáº¥n luyá»‡n má»™t mÃ´ hÃ¬nh RandomForest vÃ  sá»­ dá»¥ng thuá»™c tÃ­nh `feature_importances_` Ä‘á»ƒ tÃ¬m ra cÃ¡c feature quan trá»ng nháº¥t. So sÃ¡nh káº¿t quáº£ nÃ y vá»›i káº¿t quáº£ tá»« SHAP.
2.  **Giáº£i thÃ­ch dá»± Ä‘oÃ¡n cá»¥c bá»™**: Chá»n má»™t vÃ i dá»± Ä‘oÃ¡n Ä‘Ãºng vÃ  má»™t vÃ i dá»± Ä‘oÃ¡n sai tá»« mÃ´ hÃ¬nh cá»§a báº¡n. Sá»­ dá»¥ng LIME vÃ  SHAP (Force Plot) Ä‘á»ƒ giáº£i thÃ­ch táº¡i sao mÃ´ hÃ¬nh láº¡i Ä‘Æ°a ra cÃ¡c quyáº¿t Ä‘á»‹nh Ä‘Ã³. PhÃ¢n tÃ­ch xem lá»i giáº£i thÃ­ch cÃ³ há»£p lÃ½ khÃ´ng.
3.  **PhÃ¢n tÃ­ch Bias**: Sá»­ dá»¥ng SHAP Summary Plot Ä‘á»ƒ xem má»™t feature nháº¡y cáº£m (vÃ­ dá»¥: `Sex` trong bá»™ dá»¯ liá»‡u Titanic) cÃ³ áº£nh hÆ°á»Ÿng nhÆ° tháº¿ nÃ o Ä‘áº¿n Ä‘áº§u ra cá»§a mÃ´ hÃ¬nh trÃªn toÃ n bá»™ táº­p dá»¯ liá»‡u.

### 5.2 TÃ i liá»‡u tham kháº£o
-   **ThÆ° viá»‡n**: `lime`, `shap`, `eli5`, `interpret-community`.
-   **SÃ¡ch**: "Interpretable Machine Learning" cá»§a Christoph Molnar (má»™t nguá»“n tÃ i liá»‡u tuyá»‡t vá»i vÃ  miá»…n phÃ­).
-   **BÃ i bÃ¡o quan trá»ng**:
    -   "Why Should I Trust You?": Explaining the Predictions of Any Classifier" (LIME paper).
    -   "A Unified Approach to Interpreting Model Predictions" (SHAP paper).

---
*ChÃºc báº¡n há»c táº­p hiá»‡u quáº£! ğŸš€*
