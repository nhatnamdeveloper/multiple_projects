# üìÖ L·ªô tr√¨nh 12 tu·∫ßn - Master AI/ML/Data Science

> **M·ª•c ti√™u**: Cung c·∫•p l·ªô tr√¨nh h·ªçc t·∫≠p c√≥ c·∫•u tr√∫c theo th·ªùi gian, gi√∫p ng∆∞·ªùi h·ªçc ƒë·∫°t ƒë∆∞·ª£c m·ª•c ti√™u t·ª´ beginner ƒë·∫øn intermediate trong 12 tu·∫ßn

## üéØ **T·ªïng quan l·ªô tr√¨nh**

```mermaid
gantt
    title L·ªô tr√¨nh 12 tu·∫ßn - Master AI/ML/Data Science
    dateFormat  YYYY-MM-DD
    section N·ªÅn t·∫£ng
    Python & Tools           :a1, 2024-01-01, 7d
    To√°n h·ªçc & SQL          :a2, after a1, 7d
    Data Visualization      :a3, after a2, 7d
    
    section Data Analysis
    EDA & Statistics        :b1, after a3, 7d
    Business Intelligence   :b2, after b1, 7d
    A/B Testing            :b3, after b2, 7d
    
    section Machine Learning
    Feature Engineering     :c1, after b3, 7d
    Supervised Learning    :c2, after c1, 7d
    Model Evaluation       :c3, after c2, 7d
    
    section Deep Learning
    Neural Networks        :d1, after c3, 7d
    Computer Vision       :d2, after d1, 7d
    NLP & LLMs            :d3, after d2, 7d
    
    section MLOps
    Model Deployment      :e1, after d3, 7d
    Production Pipeline   :e2, after e1, 7d
```

![12-Week Roadmap](assets/12-week-roadmap.svg)

![12-Week Roadmap PNG](assets/12-week-roadmap.png)

**üìÅ [Xem file PNG tr·ª±c ti·∫øp](assets/12-week-roadmap.png)**

**üìÅ [Xem file PNG tr·ª±c ti·∫øp](assets/12-week-roadmap.png)**

**üìÅ [Xem file PNG tr·ª±c ti·∫øp](assets/12-week-roadmap.png)**

## üß© Ch∆∞∆°ng tr√¨nh 50/50 (L√Ω thuy·∫øt : Th·ª±c h√†nh)

- M·ª•c ti√™u: 50% l√Ω thuy·∫øt (m·ª•c ti√™u tu·∫ßn, ki·∫øn th·ª©c c·ªët l√µi), 50% th·ª±c h√†nh (deliverables r√µ r√†ng, ti√™u ch√≠ pass/fail)

| Giai ƒëo·∫°n | L√Ω thuy·∫øt (50%) | Th·ª±c h√†nh (50%) |
|---|---|---|
| Weeks 1-3 Foundations | Python/Math/SQL principles | Package + EDA notebook + SQL queries |
| Weeks 4-6 Analysis | CRISP-DM, visualization, A/B | Dashboard + A/B report |
| Weeks 7-9 ML | FE, algorithms, evaluation | ML pipeline + API predict |
| Weeks 10-12 DL/MLOps | NN/optim, serving, monitoring | DL model + serving + monitor |

Rubric tu·∫ßn (100ƒë): L√Ω thuy·∫øt 30 | Code 30 | K·∫øt qu·∫£ 30 | B√°o c√°o 10

---

## üöÄ **L·ªô tr√¨nh chi ti·∫øt theo tu·∫ßn**

### **üìö Tu·∫ßn 1-3: N·ªÅn t·∫£ng v·ªØng ch·∫Øc**

#### **Tu·∫ßn 1: Python & Development Tools**
> **M·ª•c ti√™u**: L√†m ch·ªß Python n√¢ng cao v√† setup m√¥i tr∆∞·ªùng ph√°t tri·ªÉn

**N·ªôi dung ch√≠nh**:
- **Python OOP**: Classes, inheritance, polymorphism, abstract classes
- **Advanced Python**: List comprehensions, generators, decorators, context managers
- **Packaging**: `pyproject.toml`, virtual environments, dependency management
- **Testing**: `pytest`, fixtures, parametrized tests, mocking
- **Git & CLI**: Version control, command line operations, branching strategies

**Deliverables**:
- Portfolio website v·ªõi Python backend
- Python package v·ªõi tests ƒë·∫ßy ƒë·ªß
- Git repository v·ªõi commit history r√µ r√†ng

**Learning Resources**:
- [Python OOP Tutorial](https://realpython.com/python3-object-oriented-programming/)
- [Pytest Documentation](https://docs.pytest.org/)
- [Git Handbook](https://guides.github.com/introduction/git-handbook/)

**Practice Projects**:
```python
# V√≠ d·ª•: T·∫°o m·ªôt class hierarchy cho shapes
from abc import ABC, abstractmethod
import math

class Shape(ABC):
    """Abstract base class cho t·∫•t c·∫£ shapes"""
    
    @abstractmethod
    def area(self) -> float:
        """T√≠nh di·ªán t√≠ch"""
        pass
    
    @abstractmethod
    def perimeter(self) -> float:
        """T√≠nh chu vi"""
        pass
    
    def describe(self) -> str:
        """M√¥ t·∫£ shape"""
        return f"{self.__class__.__name__} v·ªõi di·ªán t√≠ch {self.area():.2f}"

class Circle(Shape):
    def __init__(self, radius: float):
        if radius <= 0:
            raise ValueError("Radius ph·∫£i d∆∞∆°ng")
        self.radius = radius
    
    def area(self) -> float:
        return math.pi * self.radius ** 2
    
    def perimeter(self) -> float:
        return 2 * math.pi * self.radius

class Rectangle(Shape):
    def __init__(self, width: float, height: float):
        if width <= 0 or height <= 0:
            raise ValueError("Width v√† height ph·∫£i d∆∞∆°ng")
        self.width = width
        self.height = height
    
    def area(self) -> float:
        return self.width * self.height
    
    def perimeter(self) -> float:
        return 2 * (self.width + self.height)

# Tests
def test_shapes():
    circle = Circle(5)
    assert abs(circle.area() - 78.54) < 0.1
    assert abs(circle.perimeter() - 31.42) < 0.1
    
    rect = Rectangle(4, 6)
    assert rect.area() == 24
    assert rect.perimeter() == 20
    
    print("‚úÖ T·∫•t c·∫£ tests passed!")

if __name__ == "__main__":
    test_shapes()
```

#### **Tu·∫ßn 2: To√°n h·ªçc & SQL**
> **M·ª•c ti√™u**: N·∫Øm v·ªØng ki·∫øn th·ª©c to√°n h·ªçc c∆° b·∫£n v√† SQL cho data analysis

**N·ªôi dung ch√≠nh**:
- **Linear Algebra**: Vectors, matrices, eigenvalues, eigenvectors
- **Probability & Statistics**: Normal distribution, confidence intervals, hypothesis testing
- **SQL Fundamentals**: SELECT, JOINs, Window functions, subqueries
- **Database Design**: Normalization, indexing, query optimization
- **Statistical Analysis**: Descriptive statistics, correlation analysis, regression basics

**Deliverables**:
- Statistical analysis report v·ªõi Python
- SQL queries cho complex data analysis
- Database schema design document

**Practice Projects**:
```python
import numpy as np
import pandas as pd
from scipy import stats
import matplotlib.pyplot as plt

class StatisticalAnalyzer:
    def __init__(self, data):
        self.data = data
        self.results = {}
    
    def descriptive_statistics(self):
        """Th·ªëng k√™ m√¥ t·∫£ c∆° b·∫£n"""
        stats_dict = {
            'mean': np.mean(self.data),
            'median': np.median(self.data),
            'std': np.std(self.data),
            'skewness': stats.skew(self.data),
            'kurtosis': stats.kurtosis(self.data),
            'min': np.min(self.data),
            'max': np.max(self.data),
            'q25': np.percentile(self.data, 25),
            'q75': np.percentile(self.data, 75)
        }
        
        self.results['descriptive'] = stats_dict
        return stats_dict
    
    def normality_test(self):
        """Ki·ªÉm tra t√≠nh chu·∫©n c·ªßa d·ªØ li·ªáu"""
        # Shapiro-Wilk test
        shapiro_stat, shapiro_p = stats.shapiro(self.data)
        
        # Anderson-Darling test
        anderson_result = stats.anderson(self.data)
        
        normality_results = {
            'shapiro_wilk': {'statistic': shapiro_stat, 'p_value': shapiro_p},
            'anderson_darling': {'statistic': anderson_result.statistic, 'critical_values': anderson_result.critical_values}
        }
        
        self.results['normality'] = normality_results
        return normality_results
    
    def confidence_interval(self, confidence=0.95):
        """T√≠nh confidence interval cho mean"""
        n = len(self.data)
        mean = np.mean(self.data)
        std_err = stats.sem(self.data)
        
        ci = stats.t.interval(confidence, n-1, loc=mean, scale=std_err)
        
        self.results['confidence_interval'] = {
            'lower': ci[0],
            'upper': ci[1],
            'confidence_level': confidence
        }
        
        return self.results['confidence_interval']
    
    def plot_distribution(self):
        """V·∫Ω histogram v√† Q-Q plot"""
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))
        
        # Histogram
        ax1.hist(self.data, bins=30, alpha=0.7, edgecolor='black')
        ax1.axvline(np.mean(self.data), color='red', linestyle='--', label='Mean')
        ax1.axvline(np.median(self.data), color='green', linestyle='--', label='Median')
        ax1.set_title('Histogram c·ªßa d·ªØ li·ªáu')
        ax1.legend()
        
        # Q-Q plot
        stats.probplot(self.data, dist="norm", plot=ax2)
        ax2.set_title('Q-Q Plot (Normal Distribution)')
        
        plt.tight_layout()
        plt.show()

# S·ª≠ d·ª•ng
np.random.seed(42)
sample_data = np.random.normal(100, 15, 1000)
analyzer = StatisticalAnalyzer(sample_data)

print("=== TH·ªêNG K√ä M√î T·∫¢ ===")
desc_stats = analyzer.descriptive_statistics()
for key, value in desc_stats.items():
    print(f"{key}: {value:.4f}")

print("\n=== KI·ªÇM TRA T√çNH CHU·∫®N ===")
normality = analyzer.normality_test()
print(f"Shapiro-Wilk p-value: {normality['shapiro_wilk']['p_value']:.6f}")

print("\n=== CONFIDENCE INTERVAL (95%) ===")
ci = analyzer.confidence_interval()
print(f"95% CI: [{ci['lower']:.2f}, {ci['upper']:.2f}]")

analyzer.plot_distribution()
```

#### **Tu·∫ßn 3: Data Visualization & Dashboard**
> **M·ª•c ti√™u**: L√†m ch·ªß c√°c c√¥ng c·ª• visualization v√† t·∫°o dashboard t∆∞∆°ng t√°c

**N·ªôi dung ch√≠nh**:
- **Matplotlib & Seaborn**: Static visualizations, statistical plots
- **Plotly**: Interactive visualizations, 3D plots
- **Dash**: Web-based dashboards, real-time updates
- **Design Principles**: Color theory, chart selection, accessibility
- **Storytelling**: Data narrative, insights communication

**Deliverables**:
- Interactive dashboard v·ªõi Plotly Dash
- Portfolio visualization project
- Data storytelling presentation

### **üìä Tu·∫ßn 4-6: Data Analysis & Business Intelligence**

#### **Tu·∫ßn 4: Exploratory Data Analysis**
> **M·ª•c ti√™u**: Th·ª±c h√†nh EDA v·ªõi real-world datasets

**N·ªôi dung ch√≠nh**:
- **Data Understanding**: Business context, data quality assessment
- **Data Cleaning**: Missing values, outliers, data validation
- **Exploratory Analysis**: Univariate, bivariate, multivariate analysis
- **Statistical Testing**: T-tests, chi-square, ANOVA
- **Insights Generation**: Business implications, actionable recommendations

#### **Tu·∫ßn 5: Business Intelligence & Dashboarding**
> **M·ª•c ti√™u**: X√¢y d·ª±ng BI solutions v√† performance tracking

**N·ªôi dung ch√≠nh**:
- **KPI Design**: Business metrics, performance indicators
- **Dashboard Development**: Real-time monitoring, alerting
- **Data Storytelling**: Executive summaries, stakeholder communication
- **Business Context**: Industry knowledge, domain expertise
- **Performance Optimization**: Query optimization, caching strategies

#### **Tu·∫ßn 6: A/B Testing & Causal Inference**
> **M·ª•c ti√™u**: Thi·∫øt k·∫ø v√† ph√¢n t√≠ch experiments

**N·ªôi dung ch√≠nh**:
- **Experimental Design**: Hypothesis formulation, sample size calculation
- **Statistical Analysis**: T-tests, confidence intervals, effect sizes
- **Causal Inference**: Correlation vs causation, confounding variables
- **Business Impact**: ROI calculation, decision making
- **Ethics & Best Practices**: Informed consent, data privacy

### **ü§ñ Tu·∫ßn 7-9: Machine Learning & Model Development**

#### **Tu·∫ßn 7: Feature Engineering & Selection**
> **M·ª•c ti√™u**: T·∫°o features c√≥ √Ω nghƒ©a v√† ch·ªçn features t·ªëi ∆∞u

**N·ªôi dung ch√≠nh**:
- **Temporal Features**: Time-based variables, cyclical encoding
- **Categorical Encoding**: Label encoding, one-hot encoding, target encoding
- **Feature Selection**: Statistical methods, model-based selection
- **Domain Knowledge**: Business logic, industry expertise
- **Feature Store**: Feature versioning, reuse, monitoring

#### **Tu·∫ßn 8: Supervised Learning Models**
> **M·ª•c ti√™u**: X√¢y d·ª±ng v√† optimize c√°c m√¥ h√¨nh supervised learning

**N·ªôi dung ch√≠nh**:
- **Linear Models**: Linear regression, Ridge, Lasso, Elastic Net
- **Tree-based Models**: Decision trees, Random Forest, Gradient Boosting
- **Model Selection**: Cross-validation, hyperparameter tuning
- **Regularization**: Overfitting prevention, generalization
- **Model Interpretation**: SHAP, feature importance, business logic

#### **Tu·∫ßn 9: Model Evaluation & Deployment**
> **M·ª•c ti√™u**: ƒê√°nh gi√° m√¥ h√¨nh v√† chu·∫©n b·ªã deployment

**N·ªôi dung ch√≠nh**:
- **Performance Metrics**: Classification metrics, regression metrics
- **Model Validation**: Cross-validation strategies, time series CV
- **Error Analysis**: Bias-variance tradeoff, error patterns
- **Model Deployment**: API development, containerization
- **Monitoring**: Performance tracking, data drift detection

### **üß† Tu·∫ßn 10-12: Deep Learning & Production**

#### **Tu·∫ßn 10: Neural Networks & Deep Learning**
> **M·ª•c ti√™u**: Hi·ªÉu s√¢u v·ªÅ neural networks v√† deep learning

**N·ªôi dung ch√≠nh**:
- **Neural Network Theory**: Universal approximation, backpropagation
- **Optimization**: Gradient descent, learning rate scheduling
- **Regularization**: Dropout, batch normalization, early stopping
- **Architecture Design**: Layer design, activation functions
- **Transfer Learning**: Pre-trained models, fine-tuning

#### **Tu·∫ßn 11: Computer Vision & NLP**
> **M·ª•c ti√™u**: √Åp d·ª•ng deep learning cho CV v√† NLP

**N·ªôi dung ch√≠nh**:
- **Computer Vision**: CNN architectures, image preprocessing
- **Natural Language Processing**: RNNs, LSTMs, Transformers
- **Data Augmentation**: Image augmentation, text augmentation
- **Model Optimization**: GPU utilization, memory management
- **Real-world Applications**: Image classification, sentiment analysis

#### **Tu·∫ßn 12: MLOps & Production Pipeline**
> **M·ª•c ti√™u**: X√¢y d·ª±ng production-ready ML systems

**N·ªôi dung ch√≠nh**:
- **Model Serving**: REST APIs, gRPC, batch processing
- **CI/CD Pipeline**: Automated testing, deployment automation
- **Monitoring & Observability**: Model performance, data quality
- **Scalability**: Load balancing, horizontal scaling
- **Security & Compliance**: Authentication, data privacy, audit trails

## üìã **Deliverables & Milestones**

### **End of Week 3: Foundation Complete**
- ‚úÖ Python portfolio project
- ‚úÖ Statistical analysis report
- ‚úÖ Basic visualization skills
- ‚úÖ Git proficiency

### **End of Week 6: Data Analysis Complete**
- ‚úÖ EDA project v·ªõi real dataset
- ‚úÖ Interactive dashboard
- ‚úÖ A/B testing analysis
- ‚úÖ Business insights report

### **End of Week 9: ML Fundamentals Complete**
- ‚úÖ Feature engineering pipeline
- ‚úÖ ML model v·ªõi good performance
- ‚úÖ Model interpretation report
- ‚úÖ Basic deployment API

### **End of Week 12: Full Stack Complete**
- ‚úÖ Deep learning project
- ‚úÖ Production ML pipeline
- ‚úÖ Portfolio website
- ‚úÖ Technical presentation

## üéØ **Assessment & Evaluation**

### **Weekly Check-ins**
- **Self-assessment**: Rate progress 1-10
- **Code review**: Peer feedback
- **Mentor check-in**: Weekly progress discussion
- **Project milestones**: Deliverable completion

### **Final Evaluation**
- **Portfolio review**: Project showcase
- **Technical assessment**: Skills demonstration
- **Business presentation**: Stakeholder communication
- **Peer feedback**: Community evaluation

## üöÄ **Success Tips**

### **Time Management**
- **Daily practice**: 2-3 hours coding
- **Weekly review**: Sunday reflection & planning
- **Project focus**: One major project per phase
- **Balance**: Theory + practice + projects

### **Learning Strategies**
- **Active learning**: Code everything you learn
- **Project-based**: Apply knowledge immediately
- **Community**: Join study groups, forums
- **Documentation**: Write notes, create cheatsheets

### **Overcoming Challenges**
- **Imposter syndrome**: Normal feeling, focus on progress
- **Complex concepts**: Break down, practice incrementally
- **Time constraints**: Prioritize, use Pomodoro technique
- **Technical difficulties**: Stack Overflow, documentation, community help

## üìö **Resources & References**

### **Core Materials**
- [Python Documentation](https://docs.python.org/)
- [Scikit-learn User Guide](https://scikit-learn.org/stable/user_guide.html)
- [PyTorch Tutorials](https://pytorch.org/tutorials/)
- [FastAPI Documentation](https://fastapi.tiangolo.com/)

### **Practice Platforms**
- [Kaggle](https://www.kaggle.com/) - Datasets & competitions
- [LeetCode](https://leetcode.com/) - Algorithm practice
- [HackerRank](https://www.hackerrank.com/) - Python & ML challenges
- [DataCamp](https://www.datacamp.com/) - Interactive tutorials

### **Community & Support**
- [Stack Overflow](https://stackoverflow.com/) - Technical Q&A
- [Reddit r/learnpython](https://www.reddit.com/r/learnpython/) - Python community
- [Discord AI/ML servers](https://discord.gg/) - Real-time discussions
- [GitHub Discussions](https://github.com/) - Project collaboration

---

## üí° **L·ªùi khuy√™n t·ª´ chuy√™n gia**

> **"Consistency beats intensity"** - H·ªçc ƒë·ªÅu ƒë·∫∑n m·ªói ng√†y t·ªët h∆°n h·ªçc d·ªìn d·∫≠p

> **"Build in public"** - Chia s·∫ª qu√° tr√¨nh h·ªçc t·∫≠p v√† projects

> **"Learn by doing"** - L√Ω thuy·∫øt + th·ª±c h√†nh = th√†nh c√¥ng

> **"Community is key"** - K·∫øt n·ªëi v·ªõi ng∆∞·ªùi c√πng h·ªçc v√† mentors

---

*Ch√∫c b·∫°n th√†nh c√¥ng v·ªõi l·ªô tr√¨nh 12 tu·∫ßn! üéâ*

