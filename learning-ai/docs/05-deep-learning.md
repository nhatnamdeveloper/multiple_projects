# ğŸ§  Deep Learning (DL) - Há»c sÃ¢u vÃ  máº¡ng nÆ¡-ron

> **Má»¥c tiÃªu**: Trá»Ÿ thÃ nh chuyÃªn gia Deep Learning, hiá»ƒu sÃ¢u vá» lÃ½ thuyáº¿t máº¡ng nÆ¡-ron vÃ  cÃ³ kháº£ nÄƒng xÃ¢y dá»±ng cÃ¡c mÃ´ hÃ¬nh DL phá»©c táº¡p

## ğŸ“š **1. Báº£ng kÃ½ hiá»‡u (Notation)**

### **Neural Networks:**
- **Input**: $\mathbf{x} \in \mathbb{R}^d$ (vector Ä‘áº§u vÃ o)
- **Weight matrix**: $\mathbf{W}^{(l)} \in \mathbb{R}^{n_{l-1} \times n_l}$ (ma tráº­n trá»ng sá»‘ layer $l$)
- **Bias**: $\mathbf{b}^{(l)} \in \mathbb{R}^{n_l}$ (bias vector layer $l$)
- **Activation**: $\mathbf{a}^{(l)} = \sigma(\mathbf{z}^{(l)})$ (activation output layer $l$)
- **Pre-activation**: $\mathbf{z}^{(l)} = \mathbf{W}^{(l)} \mathbf{a}^{(l-1)} + \mathbf{b}^{(l)}$

### **Forward Pass:**
- **Layer output**: $\mathbf{a}^{(l)} = \sigma(\mathbf{W}^{(l)} \mathbf{a}^{(l-1)} + \mathbf{b}^{(l)})$
- **Network output**: $f_\theta(\mathbf{x}) = \mathbf{a}^{(L)}$
- **Parameters**: $\theta = \{\mathbf{W}^{(l)}, \mathbf{b}^{(l)}\}_{l=1}^L$

### **Backpropagation:**
- **Loss gradient**: $\frac{\partial \mathcal{L}}{\partial \mathbf{W}^{(l)}}$
- **Error signal**: $\delta^{(l)} = \frac{\partial \mathcal{L}}{\partial \mathbf{z}^{(l)}}$
- **Weight update**: $\mathbf{W}^{(l)} \leftarrow \mathbf{W}^{(l)} - \alpha \frac{\partial \mathcal{L}}{\partial \mathbf{W}^{(l)}}$

### **Activation Functions:**
- **ReLU**: $\sigma(x) = \max(0, x)$
- **Sigmoid**: $\sigma(x) = \frac{1}{1 + e^{-x}}$
- **Tanh**: $\sigma(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}}$
- **Softmax**: $\sigma(\mathbf{x})_i = \frac{e^{x_i}}{\sum_j e^{x_j}}$

### **Loss Functions:**
- **Cross-entropy**: $\mathcal{L} = -\sum_i y_i \log(\hat{y}_i)$
- **MSE**: $\mathcal{L} = \frac{1}{n}\sum_i (y_i - \hat{y}_i)^2$
- **Binary cross-entropy**: $\mathcal{L} = -[y \log(\hat{y}) + (1-y)\log(1-\hat{y})]$

## ğŸ“– **2. Glossary (Äá»‹nh nghÄ©a cá»‘t lÃµi)**

### **Neural Network Components:**
- **Neuron**: ÄÆ¡n vá»‹ cÆ¡ báº£n cá»§a neural network - nháº­n input, tÃ­nh weighted sum, apply activation
- **Layer**: Táº­p há»£p cÃ¡c neurons cÃ¹ng level - input layer, hidden layers, output layer
- **Weight**: Tham sá»‘ há»c Ä‘Æ°á»£c - strength cá»§a connection giá»¯a neurons
- **Bias**: Tham sá»‘ offset - giÃºp shift activation function

### **Training Concepts:**
- **Forward Pass**: TÃ­nh output tá»« input qua network
- **Backward Pass**: TÃ­nh gradients tá»« output vá» input
- **Backpropagation**: Algorithm Ä‘á»ƒ tÃ­nh gradients efficiently
- **Gradient Descent**: Optimization algorithm Ä‘á»ƒ update parameters

### **Activation Functions:**
- **Linear**: $f(x) = x$ - khÃ´ng cÃ³ non-linearity
- **Non-linear**: ReLU, Sigmoid, Tanh - introduce non-linearity
- **Saturation**: Sigmoid/Tanh cÃ³ thá»ƒ saturate â†’ vanishing gradients
- **Sparsity**: ReLU cÃ³ thá»ƒ create sparse representations

### **Optimization:**
- **Learning Rate**: Step size trong gradient descent
- **Momentum**: Accumulate gradients Ä‘á»ƒ accelerate convergence
- **Adaptive Learning**: Adam, RMSprop - adjust learning rate automatically
- **Regularization**: Techniques Ä‘á»ƒ prevent overfitting

## ğŸ“ **3. Tháº» thuáº­t toÃ¡n - Backpropagation**

### **1. BÃ i toÃ¡n & dá»¯ liá»‡u:**
- **BÃ i toÃ¡n**: TÃ­nh gradients cá»§a loss function vá»›i respect to network parameters
- **Dá»¯ liá»‡u**: Neural network vá»›i parameters $\theta$, loss function $\mathcal{L}$
- **á»¨ng dá»¥ng**: Training neural networks, gradient-based optimization

### **2. MÃ´ hÃ¬nh & cÃ´ng thá»©c:**
**Forward Pass:**
$$\mathbf{z}^{(l)} = \mathbf{W}^{(l)} \mathbf{a}^{(l-1)} + \mathbf{b}^{(l)}$$
$$\mathbf{a}^{(l)} = \sigma(\mathbf{z}^{(l)})$$

**Backward Pass:**
$$\delta^{(l)} = \frac{\partial \mathcal{L}}{\partial \mathbf{z}^{(l)}} = \frac{\partial \mathcal{L}}{\partial \mathbf{a}^{(l)}} \odot \sigma'(\mathbf{z}^{(l)})$$

**Weight Gradients:**
$$\frac{\partial \mathcal{L}}{\partial \mathbf{W}^{(l)}} = \delta^{(l)} (\mathbf{a}^{(l-1)})^T$$
$$\frac{\partial \mathcal{L}}{\partial \mathbf{b}^{(l)}} = \delta^{(l)}$$

### **3. Loss & má»¥c tiÃªu:**
- **Má»¥c tiÃªu**: Compute gradients efficiently Ä‘á»ƒ update parameters
- **Loss**: $\mathcal{L}(\theta)$ - loss function cáº§n minimize

### **4. Tá»‘i Æ°u hoÃ¡ & cáº­p nháº­t:**
- **Algorithm**: Chain rule application
- **Cáº­p nháº­t**: $\theta \leftarrow \theta - \alpha \nabla_\theta \mathcal{L}(\theta)$

### **5. Hyperparams:**
- **Learning rate**: $\alpha$ (step size)
- **Batch size**: Number of samples per update
- **Number of epochs**: Training iterations

### **6. Äá»™ phá»©c táº¡p:**
- **Time**: $O(L \times n^2)$ vá»›i $L$ layers, $n$ neurons per layer
- **Space**: $O(L \times n^2)$ cho storing activations vÃ  gradients

### **7. Metrics Ä‘Ã¡nh giÃ¡:**
- **Gradient norm**: $\|\nabla_\theta \mathcal{L}\|$
- **Training loss**: $\mathcal{L}(\theta)$
- **Validation accuracy**: Performance on validation set
- **Convergence speed**: Rate of loss decrease

### **8. Æ¯u / NhÆ°á»£c:**
**Æ¯u Ä‘iá»ƒm:**
- Computationally efficient
- Automatic differentiation
- Scales to large networks
- Well-established theory

**NhÆ°á»£c Ä‘iá»ƒm:**
- Vanishing/exploding gradients
- Local minima
- Requires careful initialization
- Sensitive to hyperparameters

### **9. Báº«y & máº¹o:**
- **Báº«y**: Vanishing gradients â†’ use ReLU, proper initialization
- **Báº«y**: Exploding gradients â†’ gradient clipping
- **Máº¹o**: Use batch normalization
- **Máº¹o**: Monitor gradient norms

### **10. Pseudocode:**
```python
def backpropagation(network, x, y, loss_function):
    # Forward pass
    activations = forward_pass(network, x)
    
    # Compute loss
    loss = loss_function(activations[-1], y)
    
    # Initialize gradients
    gradients = {}
    
    # Backward pass
    delta = compute_output_gradient(activations[-1], y, loss_function)
    
    for layer in reversed(network.layers):
        # Compute weight gradients
        gradients[layer.weights] = delta @ activations[layer-1].T
        gradients[layer.bias] = delta
        
        # Compute error signal for next layer
        if layer > 0:
            delta = layer.weights.T @ delta * layer.activation_derivative(activations[layer])
    
    return gradients
```

### **11. Code máº«u:**
```python
import numpy as np
import matplotlib.pyplot as plt

class NeuralNetwork:
    """Simple Neural Network with Backpropagation"""
    
    def __init__(self, layer_sizes, activation='relu'):
        self.layer_sizes = layer_sizes
        self.activation = activation
        self.weights = []
        self.biases = []
        self.initialize_parameters()
    
    def initialize_parameters(self):
        """Initialize weights and biases"""
        for i in range(len(self.layer_sizes) - 1):
            # He initialization for ReLU
            if self.activation == 'relu':
                w = np.random.randn(self.layer_sizes[i+1], self.layer_sizes[i]) * np.sqrt(2.0 / self.layer_sizes[i])
            else:
                w = np.random.randn(self.layer_sizes[i+1], self.layer_sizes[i]) * 0.01
            
            b = np.zeros((self.layer_sizes[i+1], 1))
            
            self.weights.append(w)
            self.biases.append(b)
    
    def activation_function(self, z, derivative=False):
        """Activation function"""
        if self.activation == 'relu':
            if derivative:
                return np.where(z > 0, 1, 0)
            return np.maximum(0, z)
        elif self.activation == 'sigmoid':
            if derivative:
                s = 1 / (1 + np.exp(-z))
                return s * (1 - s)
            return 1 / (1 + np.exp(-z))
        elif self.activation == 'tanh':
            if derivative:
                return 1 - np.tanh(z)**2
            return np.tanh(z)
    
    def forward_pass(self, X):
        """Forward pass through the network"""
        activations = [X]
        z_values = []
        
        for i in range(len(self.weights)):
            z = np.dot(self.weights[i], activations[-1]) + self.biases[i]
            z_values.append(z)
            a = self.activation_function(z)
            activations.append(a)
        
        return activations, z_values
    
    def compute_loss(self, y_pred, y_true):
        """Compute cross-entropy loss"""
        m = y_true.shape[1]
        loss = -np.sum(y_true * np.log(y_pred + 1e-15)) / m
        return loss
    
    def compute_loss_gradient(self, y_pred, y_true):
        """Compute gradient of loss with respect to output"""
        return y_pred - y_true
    
    def backward_pass(self, X, y_true, activations, z_values):
        """Backward pass to compute gradients"""
        m = X.shape[1]
        num_layers = len(self.weights)
        
        # Initialize gradients
        weight_gradients = [np.zeros_like(w) for w in self.weights]
        bias_gradients = [np.zeros_like(b) for b in self.biases]
        
        # Compute output gradient
        delta = self.compute_loss_gradient(activations[-1], y_true)
        
        # Backpropagate through layers
        for layer in range(num_layers - 1, -1, -1):
            # Compute gradients for current layer
            weight_gradients[layer] = np.dot(delta, activations[layer].T) / m
            bias_gradients[layer] = np.sum(delta, axis=1, keepdims=True) / m
            
            # Compute delta for previous layer
            if layer > 0:
                delta = np.dot(self.weights[layer].T, delta) * self.activation_function(z_values[layer-1], derivative=True)
        
        return weight_gradients, bias_gradients
    
    def update_parameters(self, weight_gradients, bias_gradients, learning_rate):
        """Update parameters using gradients"""
        for i in range(len(self.weights)):
            self.weights[i] -= learning_rate * weight_gradients[i]
            self.biases[i] -= learning_rate * bias_gradients[i]
    
    def train(self, X, y, learning_rate=0.01, epochs=1000, batch_size=32):
        """Train the neural network"""
        losses = []
        
        for epoch in range(epochs):
            # Mini-batch training
            for i in range(0, X.shape[1], batch_size):
                X_batch = X[:, i:i+batch_size]
                y_batch = y[:, i:i+batch_size]
                
                # Forward pass
                activations, z_values = self.forward_pass(X_batch)
                
                # Backward pass
                weight_gradients, bias_gradients = self.backward_pass(X_batch, y_batch, activations, z_values)
                
                # Update parameters
                self.update_parameters(weight_gradients, bias_gradients, learning_rate)
            
            # Compute loss for monitoring
            if epoch % 100 == 0:
                activations, _ = self.forward_pass(X)
                loss = self.compute_loss(activations[-1], y)
                losses.append(loss)
                print(f"Epoch {epoch}, Loss: {loss:.4f}")
        
        return losses
    
    def predict(self, X):
        """Make predictions"""
        activations, _ = self.forward_pass(X)
        return activations[-1]
    
    def evaluate(self, X, y):
        """Evaluate model performance"""
        predictions = self.predict(X)
        loss = self.compute_loss(predictions, y)
        
        # For classification
        if y.shape[0] == 1:  # Binary classification
            predictions_binary = (predictions > 0.5).astype(int)
            accuracy = np.mean(predictions_binary == y)
        else:  # Multi-class classification
            predictions_class = np.argmax(predictions, axis=0)
            y_class = np.argmax(y, axis=0)
            accuracy = np.mean(predictions_class == y_class)
        
        return loss, accuracy

# Example usage
def demonstrate_backpropagation():
    """Demonstrate backpropagation with XOR problem"""
    print("=== Backpropagation Demonstration (XOR Problem) ===\n")
    
    # XOR data
    X = np.array([[0, 0, 1, 1],
                  [0, 1, 0, 1]])
    y = np.array([[0, 1, 1, 0]])
    
    # Create neural network
    nn = NeuralNetwork([2, 4, 1], activation='sigmoid')
    
    # Train network
    losses = nn.train(X, y, learning_rate=0.1, epochs=5000)
    
    # Evaluate
    loss, accuracy = nn.evaluate(X, y)
    print(f"\nFinal Loss: {loss:.4f}")
    print(f"Accuracy: {accuracy:.4f}")
    
    # Make predictions
    predictions = nn.predict(X)
    print("\nPredictions:")
    for i in range(X.shape[1]):
        print(f"Input: {X[:, i]}, Target: {y[0, i]:.0f}, Prediction: {predictions[0, i]:.4f}")
    
    # Plot training loss
    plt.figure(figsize=(10, 6))
    plt.plot(range(0, 5000, 100), losses)
    plt.title('Training Loss Over Time')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.grid(True)
    plt.show()
    
    return nn, losses
```

### **12. Checklist kiá»ƒm tra nhanh:**
- [ ] Gradients cÃ³ Ä‘Æ°á»£c compute correctly?
- [ ] Parameters cÃ³ Ä‘Æ°á»£c update properly?
- [ ] Loss cÃ³ decrease over time?
- [ ] Network cÃ³ converge?
- [ ] Performance cÃ³ acceptable?

---

# ğŸ§  Deep Learning (DL) - Há»c sÃ¢u vÃ  máº¡ng nÆ¡-ron

> **Má»¥c tiÃªu**: Trá»Ÿ thÃ nh chuyÃªn gia Deep Learning, hiá»ƒu sÃ¢u vá» lÃ½ thuyáº¿t máº¡ng nÆ¡-ron vÃ  cÃ³ kháº£ nÄƒng xÃ¢y dá»±ng cÃ¡c mÃ´ hÃ¬nh DL phá»©c táº¡p

## ğŸ“‹ Tá»•ng quan ná»™i dung

```mermaid
graph TD
    A[ğŸ§  Deep Learning] --> B[ğŸ”¬ Neural Network Theory]
    A --> C[âš¡ Optimization & Training]
    A --> D[ğŸ—ï¸ Architecture Design]
    A --> E[ğŸ–¼ï¸ Computer Vision]
    A --> F[ğŸ“ Natural Language Processing]
    A --> G[ğŸš€ Advanced Techniques]
    
    B --> B1[Universal Approximation]
    B --> B2[Backpropagation]
    B --> B3[Activation Functions]
    B --> B4[Loss Functions]
    
    C --> C1[Initialization Strategies]
    C --> C2[Batch Normalization]
    C --> C3[Optimization Algorithms]
    C --> C4[Regularization]
    
    D --> D1[Feedforward Networks]
    D --> D2[Convolutional Networks]
    D --> D3[Recurrent Networks]
    D --> D4[Transformer Architecture]
    
    E --> E1[Image Classification]
    E --> E2[Object Detection]
    E --> E3[Image Segmentation]
    E --> E4[Style Transfer]
    
    F --> F1[Text Classification]
    F --> F2[Sequence Modeling]
    F --> F3[Language Models]
    F --> F4[Attention Mechanisms]
    
    G --> G1[Transfer Learning]
    G --> G2[Few-shot Learning]
    G --> G3[Meta Learning]
    G --> G4[Neural Architecture Search]
```

![Deep Learning Architecture](assets/deep-learning-architecture.svg)

![Deep Learning Architecture PNG](assets/deep-learning-architecture.png)

**ğŸ“ [Xem file PNG trá»±c tiáº¿p](assets/deep-learning-architecture.png)**

**ğŸ“ [Xem file PNG trá»±c tiáº¿p](assets/deep-learning-architecture.png)**

**ğŸ“ [Xem file PNG trá»±c tiáº¿p](assets/deep-learning-architecture.png)**

## ğŸ§© ChÆ°Æ¡ng trÃ¬nh 50/50 (LÃ½ thuyáº¿t : Thá»±c hÃ nh)

- Má»¥c tiÃªu: 50% lÃ½ thuyáº¿t (Ä‘á»‹nh lÃ½, cÃ´ng thá»©c tá»‘i Æ°u hÃ³a, Ä‘áº·c tÃ­nh kiáº¿n trÃºc), 50% thá»±c hÃ nh (thá»±c nghiá»‡m cÃ³ kiá»ƒm soÃ¡t, so sÃ¡nh, bÃ¡o cÃ¡o)

| MÃ´-Ä‘un | LÃ½ thuyáº¿t (50%) | Thá»±c hÃ nh (50%) |
|---|---|---|
| NN Theory | UAT, Backprop, Activation/Loss | Thá»­ activation/loss khÃ¡c nhau |
| Optimization | Init, BN, AdamW/SGD, LR schedule | So sÃ¡nh há»™i tá»¥/overfit/regularize |
| Architectures | CNN/RNN/Transformer fundamentals | Train cÃ¡c bÃ i toÃ¡n nhá» (CIFAR/IMDB) |
| Advanced | Transfer/Few-shot/NAS | Fine-tune + report, ablation |

Rubric (100Ä‘/module): LÃ½ thuyáº¿t 30 | Code 30 | Káº¿t quáº£ 30 | BÃ¡o cÃ¡o 10

---

## ğŸ”¬ 1. Neural Network Theory - LÃ½ thuyáº¿t máº¡ng nÆ¡-ron

### 1.1 Universal Approximation Theorem - Äá»‹nh lÃ½ xáº¥p xá»‰ phá»• quÃ¡t

> **Universal Approximation Theorem** lÃ  Ä‘á»‹nh lÃ½ cÆ¡ báº£n trong Deep Learning, chá»©ng minh ráº±ng neural networks cÃ³ thá»ƒ xáº¥p xá»‰ báº¥t ká»³ hÃ m liÃªn tá»¥c nÃ o.

#### Äá»‹nh lÃ½ vÃ  Ã nghÄ©a

**LÃ½ thuyáº¿t cÆ¡ báº£n:**
- **Universal Approximation Theorem (UAT)**: Neural networks vá»›i má»™t hidden layer cÃ³ thá»ƒ xáº¥p xá»‰ báº¥t ká»³ hÃ m liÃªn tá»¥c nÃ o
- **Stone-Weierstrass Theorem**: Má»i hÃ m liÃªn tá»¥c trÃªn compact set cÃ³ thá»ƒ xáº¥p xá»‰ bá»Ÿi Ä‘a thá»©c
- **Density Properties**: Neural networks táº¡o ra class of functions dense trong space of continuous functions

**Mathematical Foundations:**

**1. Formal Statement cá»§a UAT:**
```python
import numpy as np
import matplotlib.pyplot as plt
import torch
import torch.nn as nn
from scipy.special import expit
from typing import Callable, List, Tuple

class UniversalApproximationTheory:
    """Theoretical framework cho Universal Approximation Theorem"""
    
    @staticmethod
    def formal_statement():
        """Formal mathematical statement cá»§a UAT"""
        print("""
        **Universal Approximation Theorem (Cybenko, 1989):**
        
        Let Ïƒ be any continuous sigmoidal function. Then finite sums of the form:
        
            G(x) = Î£áµ¢ Î±áµ¢ Ïƒ(wáµ¢áµ€x + báµ¢)
        
        are dense in C([0,1]â¿).
        
        **Mathematical Meaning:**
        - For any continuous function f: [0,1]â¿ â†’ â„
        - For any Îµ > 0
        - There exists a neural network G(x) such that:
            |f(x) - G(x)| < Îµ for all x âˆˆ [0,1]â¿
        
        **Key Components:**
        - Ïƒ: Activation function (sigmoidal)
        - wáµ¢: Weight vectors
        - báµ¢: Bias terms
        - Î±áµ¢: Output weights
        - Dense: Can approximate any function arbitrarily well
        """)
    
    @staticmethod
    def prove_uat_for_simple_case():
        """Prove UAT cho simple case: 1D continuous function"""
        print("""
        **Proof Sketch cho 1D Case:**
        
        1. **Step 1: Function Approximation by Step Functions**
           - Any continuous function on [0,1] can be approximated by step functions
           - Step functions can be written as linear combinations of indicator functions
        
        2. **Step 2: Indicator Functions by Neural Networks**
           - Indicator function I[a,b](x) can be approximated by:
             Ïƒ(wx + b) - Ïƒ(wx + b') where w â†’ âˆ
           - This creates a "step" at x = -b/w
        
        3. **Step 3: Linear Combination**
           - Any step function = Î£áµ¢ Î±áµ¢ I[aáµ¢,báµ¢](x)
           - Can be approximated by Î£áµ¢ Î±áµ¢ Ïƒ(wáµ¢x + báµ¢)
        
        4. **Step 4: Arbitrary Precision**
           - By increasing number of neurons, can achieve arbitrary precision
           - Error bound: |f(x) - G(x)| < Îµ for all x
        """)
    
    @staticmethod
    def demonstrate_approximation_capability():
        """Demonstrate neural network approximation capability"""
        
        # Target function: f(x) = sin(2Ï€x) + 0.5*sin(4Ï€x)
        def target_function(x):
            return np.sin(2 * np.pi * x) + 0.5 * np.sin(4 * np.pi * x)
        
        # Generate training data
        x_train = np.linspace(0, 1, 1000).reshape(-1, 1)
        y_train = target_function(x_train)
        
        # Neural network architecture
        class ApproximationNetwork(nn.Module):
            def __init__(self, hidden_size: int):
                super().__init__()
                self.hidden = nn.Linear(1, hidden_size)
                self.output = nn.Linear(hidden_size, 1)
                self.activation = nn.Tanh()  # Sigmoidal activation
                
            def forward(self, x):
                x = self.activation(self.hidden(x))
                x = self.output(x)
                return x
        
        # Train networks with different hidden sizes
        hidden_sizes = [5, 10, 20, 50]
        trained_networks = []
        training_errors = []
        
        for hidden_size in hidden_sizes:
            # Initialize network
            net = ApproximationNetwork(hidden_size)
            criterion = nn.MSELoss()
            optimizer = torch.optim.Adam(net.parameters(), lr=0.01)
            
            # Training loop
            x_tensor = torch.FloatTensor(x_train)
            y_tensor = torch.FloatTensor(y_train)
            
            for epoch in range(5000):
                optimizer.zero_grad()
                outputs = net(x_tensor)
                loss = criterion(outputs, y_tensor)
                loss.backward()
                optimizer.step()
                
                if epoch % 1000 == 0:
                    print(f"Hidden size {hidden_size}, Epoch {epoch}, Loss: {loss.item():.6f}")
            
            # Evaluate
            with torch.no_grad():
                y_pred = net(x_tensor).numpy().flatten()
                mse = np.mean((y_train - y_pred)**2)
                training_errors.append(mse)
                trained_networks.append(net)
            
            print(f"Hidden size {hidden_size}, Final MSE: {mse:.6f}")
        
        # Visualization
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        
        for i, (hidden_size, net, error) in enumerate(zip(hidden_sizes, trained_networks, training_errors)):
            row = i // 2
            col = i % 2
            
            # Plot original vs approximated
            with torch.no_grad():
                y_pred = net(torch.FloatTensor(x_train)).numpy().flatten()
            
            axes[row, col].plot(x_train, y_train, 'b-', label='Target Function', linewidth=2)
            axes[row, col].plot(x_train, y_pred, 'r--', label=f'NN (hidden={hidden_size})', linewidth=2)
            axes[row, col].set_title(f'Approximation with {hidden_size} Hidden Neurons\nMSE: {error:.6f}')
            axes[row, col].set_xlabel('x')
            axes[row, col].set_ylabel('f(x)')
            axes[row, col].legend()
            axes[row, col].grid(True)
        
        plt.tight_layout()
        plt.show()
        
        # Error analysis
        print("\n**Approximation Error Analysis:**")
        for hidden_size, error in zip(hidden_sizes, training_errors):
            print(f"Hidden size {hidden_size}: MSE = {error:.6f}")
        
        return {
            'hidden_sizes': hidden_sizes,
            'training_errors': training_errors,
            'networks': trained_networks
        }
    
    @staticmethod
    def analyze_approximation_properties():
        """Analyze mathematical properties cá»§a neural network approximation"""
        
        print("""
        **Mathematical Properties cá»§a Neural Network Approximation:**
        
        1. **Density Property:**
           - Neural networks form a dense subset in C([0,1]â¿)
           - Can approximate any continuous function arbitrarily well
        
        2. **Approximation Rate:**
           - Error decreases as number of neurons increases
           - Rate depends on smoothness of target function
        
        3. **Curse of Dimensionality:**
           - Number of neurons needed grows exponentially with input dimension
           - Practical limitation for high-dimensional problems
        
        4. **Activation Function Requirements:**
           - Must be sigmoidal (bounded, non-constant, monotonically increasing)
           - Examples: tanh, sigmoid, ReLU (with proper scaling)
        
        5. **Weight Initialization:**
           - Weights must be properly initialized for good approximation
           - Random initialization often sufficient for large networks
        """)
        
        # Demonstrate curse of dimensionality
        dimensions = [1, 2, 3, 5, 10]
        neurons_needed = []
        
        for dim in dimensions:
            # Rough estimate: neurons needed scales exponentially
            neurons_needed.append(int(10 * (2**dim)))
        
        print("\n**Curse of Dimensionality Analysis:**")
        for dim, neurons in zip(dimensions, neurons_needed):
            print(f"Input dimension {dim}: Estimated neurons needed = {neurons}")
        
        # Visualization
        plt.figure(figsize=(10, 6))
        plt.plot(dimensions, neurons_needed, 'bo-', linewidth=2, markersize=8)
        plt.xlabel('Input Dimension')
        plt.ylabel('Estimated Neurons Needed')
        plt.title('Curse of Dimensionality: Neurons vs Input Dimension')
        plt.grid(True)
        plt.yscale('log')
        plt.show()

# Demonstrate UAT theory
uat_theory = UniversalApproximationTheory()
uat_theory.formal_statement()
uat_theory.prove_uat_for_simple_case()

# Demonstrate approximation capability
approximation_results = uat_theory.demonstrate_approximation_capability()

# Analyze properties
uat_theory.analyze_approximation_properties()
```

**2. Backpropagation Theory:**
```python
class BackpropagationTheory:
    """Theoretical framework cho backpropagation algorithm"""
    
    @staticmethod
    def explain_backpropagation():
        """Explain backpropagation mathematically"""
        print("""
        **Backpropagation Algorithm:**
        
        **Forward Pass:**
        - Input: x, weights W, biases b
        - Hidden layers: háµ¢ = Ïƒ(Wáµ¢h_{i-1} + báµ¢)
        - Output: Å· = Ïƒ(Wâ‚–h_{k-1} + bâ‚–)
        
        **Backward Pass (Chain Rule):**
        - Loss: L(Å·, y)
        - Gradient w.r.t. output: âˆ‚L/âˆ‚Å·
        - Gradient w.r.t. weights: âˆ‚L/âˆ‚Wáµ¢ = âˆ‚L/âˆ‚háµ¢ Ã— âˆ‚háµ¢/âˆ‚Wáµ¢
        - Gradient w.r.t. hidden: âˆ‚L/âˆ‚háµ¢ = Î£â±¼ âˆ‚L/âˆ‚h_{i+1} Ã— âˆ‚h_{i+1}/âˆ‚háµ¢
        
        **Mathematical Formulation:**
        - âˆ‚L/âˆ‚Wáµ¢ = âˆ‚L/âˆ‚Å· Ã— âˆ_{j=i+1}^k âˆ‚hâ±¼/âˆ‚h_{j-1} Ã— âˆ‚háµ¢/âˆ‚Wáµ¢
        - This is the chain rule applied recursively
        """)
    
    @staticmethod
    def demonstrate_chain_rule():
        """Demonstrate chain rule in backpropagation"""
        
        # Simple example: f(x) = sin(xÂ²)
        def f(x):
            return np.sin(x**2)
        
        def df_dx(x):
            # Chain rule: d/dx[sin(xÂ²)] = cos(xÂ²) Ã— 2x
            return np.cos(x**2) * 2 * x
        
        # Generate data
        x_values = np.linspace(-2, 2, 100)
        y_values = f(x_values)
        dy_dx_values = df_dx(x_values)
        
        # Visualization
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))
        
        # Function plot
        ax1.plot(x_values, y_values, 'b-', linewidth=2, label='f(x) = sin(xÂ²)')
        ax1.set_xlabel('x')
        ax1.set_ylabel('f(x)')
        ax1.set_title('Function: f(x) = sin(xÂ²)')
        ax1.grid(True)
        ax1.legend()
        
        # Derivative plot
        ax2.plot(x_values, dy_dx_values, 'r-', linewidth=2, label="f'(x) = 2x cos(xÂ²)")
        ax2.set_xlabel('x')
        ax2.set_ylabel("f'(x)")
        ax2.set_title('Derivative using Chain Rule')
        ax2.grid(True)
        ax2.legend()
        
        plt.tight_layout()
        plt.show()
        
        # Numerical verification
        def numerical_derivative(f, x, h=1e-6):
            return (f(x + h) - f(x - h)) / (2 * h)
        
        test_points = [-1.5, -0.5, 0, 0.5, 1.5]
        print("\n**Numerical Verification of Chain Rule:**")
        print("x\t\tAnalytical\t\tNumerical\t\tDifference")
        print("-" * 70)
        
        for x in test_points:
            analytical = df_dx(x)
            numerical = numerical_derivative(f, x)
            diff = abs(analytical - numerical)
            print(f"{x:6.1f}\t\t{analytical:10.6f}\t\t{numerical:10.6f}\t\t{diff:10.6f}")
    
    @staticmethod
    def implement_backpropagation():
        """Implement backpropagation manually cho simple network"""
        
        class SimpleNeuralNetwork:
            def __init__(self, input_size: int, hidden_size: int, output_size: int):
                # Initialize weights and biases
                self.W1 = np.random.randn(input_size, hidden_size) * 0.01
                self.b1 = np.zeros((1, hidden_size))
                self.W2 = np.random.randn(hidden_size, output_size) * 0.01
                self.b2 = np.zeros((1, output_size))
                
                # Learning rate
                self.lr = 0.1
            
            def sigmoid(self, x):
                return 1 / (1 + np.exp(-x))
            
            def sigmoid_derivative(self, x):
                return x * (1 - x)
            
            def forward(self, X):
                # Forward pass
                self.z1 = np.dot(X, self.W1) + self.b1
                self.a1 = self.sigmoid(self.z1)
                self.z2 = np.dot(self.a1, self.W2) + self.b2
                self.a2 = self.sigmoid(self.z2)
                return self.a2
            
            def backward(self, X, y, output):
                # Backward pass
                self.error = y - output
                self.delta2 = self.error * self.sigmoid_derivative(output)
                
                self.error_hidden = np.dot(self.delta2, self.W2.T)
                self.delta1 = self.error_hidden * self.sigmoid_derivative(self.a1)
                
                # Update weights and biases
                self.W2 += self.lr * np.dot(self.a1.T, self.delta2)
                self.b2 += self.lr * np.sum(self.delta2, axis=0, keepdims=True)
                self.W1 += self.lr * np.dot(X.T, self.delta1)
                self.b1 += self.lr * np.sum(self.delta1, axis=0, keepdims=True)
            
            def train(self, X, y, epochs):
                losses = []
                for epoch in range(epochs):
                    # Forward pass
                    output = self.forward(X)
                    
                    # Backward pass
                    self.backward(X, y, output)
                    
                    # Calculate loss
                    loss = np.mean(np.square(y - output))
                    losses.append(loss)
                    
                    if epoch % 1000 == 0:
                        print(f"Epoch {epoch}, Loss: {loss:.6f}")
                
                return losses
        
        # Generate simple dataset
        X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
        y = np.array([[0], [1], [1], [0]])  # XOR problem
        
        # Train network
        nn = SimpleNeuralNetwork(2, 4, 1)
        losses = nn.train(X, y, epochs=10000)
        
        # Test network
        predictions = nn.forward(X)
        print("\n**XOR Problem Results:**")
        print("Input\t\tTarget\t\tPrediction")
        print("-" * 40)
        for i in range(len(X)):
            print(f"{X[i]}\t\t{y[i][0]}\t\t{predictions[i][0]:.4f}")
        
        # Plot training loss
        plt.figure(figsize=(10, 6))
        plt.plot(losses)
        plt.xlabel('Epoch')
        plt.ylabel('Loss')
        plt.title('Training Loss over Epochs')
        plt.grid(True)
        plt.yscale('log')
        plt.show()
        
        return nn, losses

# Demonstrate backpropagation theory
backprop_theory = BackpropagationTheory()
backprop_theory.explain_backpropagation()
backprop_theory.demonstrate_chain_rule()

# Implement and test backpropagation
trained_nn, training_losses = backprop_theory.implement_backpropagation()
```

**3. Activation Functions Theory:**
```python
class ActivationFunctionTheory:
    """Theoretical analysis cá»§a activation functions"""
    
    @staticmethod
    def analyze_activation_functions():
        """Analyze mathematical properties cá»§a activation functions"""
        
        # Define activation functions
        def sigmoid(x):
            return 1 / (1 + np.exp(-x))
        
        def tanh(x):
            return np.tanh(x)
        
        def relu(x):
            return np.maximum(0, x)
        
        def leaky_relu(x, alpha=0.01):
            return np.where(x > 0, x, alpha * x)
        
        def swish(x, beta=1.0):
            return x * sigmoid(beta * x)
        
        # Generate data
        x = np.linspace(-5, 5, 1000)
        
        # Calculate function values and derivatives
        functions = {
            'Sigmoid': sigmoid,
            'Tanh': tanh,
            'ReLU': relu,
            'Leaky ReLU': lambda x: leaky_relu(x),
            'Swish': lambda x: swish(x)
        }
        
        # Calculate derivatives numerically
        def numerical_derivative(f, x, h=1e-6):
            return (f(x + h) - f(x - h)) / (2 * h)
        
        # Visualization
        fig, axes = plt.subplots(2, 3, figsize=(18, 10))
        
        for i, (name, func) in enumerate(functions.items()):
            row = i // 3
            col = i % 3
            
            # Function plot
            y = func(x)
            axes[row, col].plot(x, y, 'b-', linewidth=2, label=name)
            
            # Derivative plot
            dy_dx = numerical_derivative(func, x)
            axes[row, col].plot(x, dy_dx, 'r--', linewidth=2, label=f"{name}'")
            
            axes[row, col].set_title(f'{name} Function and Derivative')
            axes[row, col].set_xlabel('x')
            axes[row, col].set_ylabel('y')
            axes[row, col].grid(True)
            axes[row, col].legend()
            axes[row, col].set_xlim(-5, 5)
            axes[row, col].set_ylim(-2, 2)
        
        # Remove extra subplot
        axes[1, 2].remove()
        
        plt.tight_layout()
        plt.show()
        
        # Mathematical analysis
        print("""
        **Activation Function Analysis:**
        
        1. **Sigmoid:**
           - Range: (0, 1)
           - Derivative: Ïƒ'(x) = Ïƒ(x)(1-Ïƒ(x))
           - Issues: Vanishing gradient for large |x|
        
        2. **Tanh:**
           - Range: (-1, 1)
           - Derivative: tanh'(x) = 1 - tanhÂ²(x)
           - Better than sigmoid: zero-centered
        
        3. **ReLU:**
           - Range: [0, âˆ)
           - Derivative: 1 if x > 0, 0 if x â‰¤ 0
           - Issues: Dying ReLU problem
        
        4. **Leaky ReLU:**
           - Range: (-âˆ, âˆ)
           - Derivative: 1 if x > 0, Î± if x â‰¤ 0
           - Solves dying ReLU problem
        
        5. **Swish:**
           - Range: (-âˆ, âˆ)
           - Derivative: Ïƒ(Î²x) + Î²xÏƒ(Î²x)(1-Ïƒ(Î²x))
           - Smooth, non-monotonic
        """)
        
        # Demonstrate vanishing gradient problem
        def demonstrate_vanishing_gradient():
            """Demonstrate vanishing gradient problem"""
            
            # Create deep network with sigmoid
            def sigmoid_network(x, weights):
                """Forward pass through network with sigmoid"""
                current = x
                for w in weights:
                    current = sigmoid(np.dot(current, w))
                return current
            
            # Test with different weight magnitudes
            x_input = np.array([1.0])
            weight_scenarios = [
                [np.array([[0.1]]), np.array([[0.1]]), np.array([[0.1]])],  # Small weights
                [np.array([[1.0]]), np.array([[1.0]]), np.array([[1.0]])],  # Medium weights
                [np.array([[5.0]]), np.array([[5.0]]), np.array([[5.0]])]   # Large weights
            ]
            
            print("\n**Vanishing Gradient Demonstration:**")
            print("Weight Magnitude\tOutput\t\tGradient Magnitude")
            print("-" * 60)
            
            for i, weights in enumerate(weight_scenarios):
                output = sigmoid_network(x_input, weights)
                
                # Calculate gradient magnitude (simplified)
                grad_magnitude = np.prod([sigmoid(np.dot(x_input, w)) * (1 - sigmoid(np.dot(x_input, w))) 
                                        for w in weights])
                
                weight_mag = np.mean([np.mean(np.abs(w)) for w in weights])
                print(f"{weight_mag:15.1f}\t{output[0]:10.6f}\t{grad_magnitude:15.6f}")
        
        demonstrate_vanishing_gradient()

# Demonstrate activation function theory
activation_theory = ActivationFunctionTheory()
activation_theory.analyze_activation_functions()
```

**TÃ i liá»‡u tham kháº£o chuyÃªn sÃ¢u:**
- **Universal Approximation**: [Approximation by Superpositions of a Sigmoidal Function](https://www.sciencedirect.com/science/article/abs/pii/0893608089900148)
- **Backpropagation**: [Learning representations by back-propagating errors](https://www.nature.com/articles/323533a0)
- **Activation Functions**: [Deep Learning with Rectified Linear Units](https://arxiv.org/abs/1803.08375)
- **Neural Network Theory**: [Neural Networks and Learning Machines](https://www.pearson.com/us/higher-education/program/Haykin-Neural-Networks-and-Learning-Machines-3rd-Edition/PGM263675.html)

#### VÃ­ dá»¥ minh há»a

```python
import torch
import torch.nn as nn
import matplotlib.pyplot as plt
import numpy as np

def demonstrate_universal_approximation():
    """
    Minh há»a Universal Approximation Theorem
    Táº¡o neural network xáº¥p xá»‰ hÃ m sin(x)
    """
    
    # Táº¡o dá»¯ liá»‡u
    x = torch.linspace(0, 2*np.pi, 1000).reshape(-1, 1)
    y_true = torch.sin(x)
    
    # Neural network vá»›i 1 hidden layer
    class UniversalApproximator(nn.Module):
        def __init__(self, hidden_size=50):
            super().__init__()
            self.hidden = nn.Linear(1, hidden_size)
            self.output = nn.Linear(hidden_size, 1)
            self.activation = nn.Tanh()  # Tanh activation
            
        def forward(self, x):
            x = self.activation(self.hidden(x))
            x = self.output(x)
            return x
    
    # Khá»Ÿi táº¡o mÃ´ hÃ¬nh
    model = UniversalApproximator(hidden_size=50)
    criterion = nn.MSELoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)
    
    # Training
    losses = []
    for epoch in range(5000):
        optimizer.zero_grad()
        y_pred = model(x)
        loss = criterion(y_pred, y_true)
        loss.backward()
        optimizer.step()
        
        if epoch % 500 == 0:
            losses.append(loss.item())
            print(f"Epoch {epoch}, Loss: {loss.item():.6f}")
    
    # ÄÃ¡nh giÃ¡ káº¿t quáº£
    with torch.no_grad():
        y_pred = model(x)
        final_loss = criterion(y_pred, y_true)
        print(f"\nğŸ¯ Final Loss: {final_loss.item():.6f}")
        
        # TÃ­nh Ä‘á»™ chÃ­nh xÃ¡c
        mae = torch.mean(torch.abs(y_pred - y_true))
        print(f"ğŸ“Š Mean Absolute Error: {mae.item():.6f}")
    
    # Visualization
    plt.figure(figsize=(12, 5))
    
    plt.subplot(1, 2, 1)
    plt.plot(x.numpy(), y_true.numpy(), 'b-', label='True: sin(x)', linewidth=2)
    plt.plot(x.numpy(), y_pred.numpy(), 'r--', label='NN Approximation', linewidth=2)
    plt.xlabel('x')
    plt.ylabel('y')
    plt.title('Universal Approximation: sin(x)')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    plt.subplot(1, 2, 2)
    plt.plot(losses)
    plt.xlabel('Epoch (x500)')
    plt.ylabel('Loss')
    plt.title('Training Loss')
    plt.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.show()
    
    return model, final_loss.item()

# VÃ­ dá»¥ sá»­ dá»¥ng
# model, final_loss = demonstrate_universal_approximation()
```

**Giáº£i thÃ­ch káº¿t quáº£:**
- **Loss**: Äá»™ lá»—i giá»¯a dá»± Ä‘oÃ¡n vÃ  giÃ¡ trá»‹ tháº­t, cÃ ng tháº¥p cÃ ng tá»‘t
- **MAE**: Mean Absolute Error - sai sá»‘ tuyá»‡t Ä‘á»‘i trung bÃ¬nh
- **Hidden Size**: Sá»‘ nÆ¡-ron trong hidden layer, cÃ ng nhiá»u cÃ ng cÃ³ kháº£ nÄƒng xáº¥p xá»‰ phá»©c táº¡p

### 1.2 Backpropagation - Lan truyá»n ngÆ°á»£c

> **Backpropagation** (lan truyá»n ngÆ°á»£c) lÃ  thuáº­t toÃ¡n cá»‘t lÃµi, lÃ  "phÃ©p mÃ u" giÃºp cho máº¡ng nÆ¡-ron cÃ³ thá»ƒ há»c Ä‘Æ°á»£c. Vá» báº£n cháº¥t, nÃ³ lÃ  má»™t cÃ¡ch thÃ´ng minh Ä‘á»ƒ Ã¡p dá»¥ng **quy táº¯c chuá»—i (Chain Rule)** trong giáº£i tÃ­ch Ä‘á»ƒ tÃ­nh toÃ¡n gradient (Ä‘á»™ dá»‘c) cá»§a hÃ m máº¥t mÃ¡t theo tá»«ng tham sá»‘ (trá»ng sá»‘ vÃ  bias) trong máº¡ng.

#### TÆ° duy trá»±c quan
1.  **Forward Pass (Lan truyá»n xuÃ´i)**: Báº¡n Ä‘Æ°a dá»¯ liá»‡u vÃ o máº¡ng, tÃ­nh toÃ¡n qua tá»«ng layer Ä‘á»ƒ ra Ä‘Æ°á»£c má»™t dá»± Ä‘oÃ¡n (output).
2.  **TÃ­nh lá»—i (Compute Loss)**: Báº¡n so sÃ¡nh dá»± Ä‘oÃ¡n nÃ y vá»›i "Ä‘Ã¡p Ã¡n" Ä‘Ãºng (ground truth) Ä‘á»ƒ tÃ­nh ra má»™t con sá»‘ thá»ƒ hiá»‡n "má»©c Ä‘á»™ sai" cá»§a máº¡ng, gá»i lÃ  **loss**.
3.  **Backward Pass (Lan truyá»n ngÆ°á»£c)**:
    *   Báº¯t Ä‘áº§u tá»« con sá»‘ `loss` á»Ÿ cuá»‘i máº¡ng, backpropagation "lan truyá»n" lá»—i nÃ y ngÆ°á»£c vá» cÃ¡c layer phÃ­a trÆ°á»›c.
    *   Táº¡i má»—i layer, nÃ³ tá»± há»i: "Layer nÃ y Ä‘Ã£ 'Ä‘Ã³ng gÃ³p' vÃ o cÃ¡i lá»—i cuá»‘i cÃ¹ng nÃ y nhÆ° tháº¿ nÃ o?"
    *   Dá»±a trÃªn sá»± "Ä‘Ã³ng gÃ³p" Ä‘Ã³, nÃ³ tÃ­nh toÃ¡n gradient cho cÃ¡c tham sá»‘ cá»§a layer Ä‘Ã³. Gradient nÃ y cho biáº¿t: "Äá»ƒ giáº£m `loss`, ta nÃªn Ä‘iá»u chá»‰nh tham sá»‘ nÃ y theo hÆ°á»›ng nÃ o (tÄƒng hay giáº£m) vÃ  vá»›i má»©c Ä‘á»™ bao nhiÃªu?"
4.  **Cáº­p nháº­t trá»ng sá»‘ (Update Weights)**: DÃ¹ng cÃ¡c gradient Ä‘Ã£ tÃ­nh Ä‘Æ°á»£c Ä‘á»ƒ cáº­p nháº­t láº¡i táº¥t cáº£ cÃ¡c tham sá»‘ trong máº¡ng theo thuáº­t toÃ¡n Gradient Descent (hoáº·c cÃ¡c biáº¿n thá»ƒ cá»§a nÃ³).

Vá» cÆ¡ báº£n, Backpropagation lÃ  quy trÃ¬nh "quy trÃ¡ch nhiá»‡m" cho tá»«ng tham sá»‘ vá» cÃ¡i lá»—i tá»•ng thá»ƒ.

#### Chain Rule vÃ  Gradient Flow

Quy táº¯c chuá»—i cho phÃ©p chÃºng ta tÃ­nh Ä‘áº¡o hÃ m cá»§a má»™t hÃ m há»£p. VÃ­ dá»¥, náº¿u `L` lÃ  hÃ m cá»§a `a`, vÃ  `a` lÃ  hÃ m cá»§a `z`, vÃ  `z` lÃ  hÃ m cá»§a `w`, thÃ¬:
$$ \frac{\partial L}{\partial w} = \frac{\partial L}{\partial a} \cdot \frac{\partial a}{\partial z} \cdot \frac{\partial z}{\partial w} $$

Backpropagation Ã¡p dá»¥ng quy táº¯c nÃ y má»™t cÃ¡ch cÃ³ há»‡ thá»‘ng tá»« layer cuá»‘i cÃ¹ng ngÆ°á»£c vá» layer Ä‘áº§u tiÃªn.

**Luá»“ng tÃ­nh toÃ¡n gradient (Gradient Flow):**

1.  **Gradient cá»§a Loss theo Output cá»§a máº¡ng ($\frac{\partial L}{\partial \hat{y}}$)**: BÆ°á»›c Ä‘áº§u tiÃªn, dá»… tÃ­nh.
2.  **Gradient táº¡i layer cuá»‘i cÃ¹ng**:
    -   $\frac{\partial L}{\partial z^{(L)}} = \frac{\partial L}{\partial a^{(L)}} \odot \sigma'(z^{(L)})$ (vá»›i $a^{(L)} = \hat{y}$)
    -   $\frac{\partial L}{\partial W^{(L)}} = \frac{\partial L}{\partial z^{(L)}} \cdot (a^{(L-1)})^T$
3.  **Lan truyá»n ngÆ°á»£c ra sau**:
    -   $\frac{\partial L}{\partial a^{(L-1)}} = (W^{(L)})^T \cdot \frac{\partial L}{\partial z^{(L)}}$
    -   Sau Ä‘Ã³, láº·p láº¡i quy trÃ¬nh tÃ­nh $\frac{\partial L}{\partial z^{(L-1)}}$ vÃ  $\frac{\partial L}{\partial W^{(L-1)}}$ vÃ  tiáº¿p tá»¥c lan truyá»n ngÆ°á»£c.

#### VÃ­ dá»¥ cá»¥ thá»ƒ báº±ng sá»‘
HÃ£y xem má»™t máº¡ng nÆ¡-ron cá»±c ká»³ Ä‘Æ¡n giáº£n: 1 input, 1 hidden neuron, 1 output neuron.
-   Input `x = 2`
-   Target `y = 1`
-   Weights `w1 = 0.5`, `w2 = 0.8`
-   Biases `b1 = 0.1`, `b2 = 0.2`
-   Activation function: Sigmoid, $\sigma(z) = 1 / (1 + e^{-z})$
-   Loss function: Mean Squared Error, $L = \frac{1}{2}(\hat{y} - y)^2$

**1. Forward Pass:**
-   $z_1 = w_1 \cdot x + b_1 = 0.5 \cdot 2 + 0.1 = 1.1$
-   $a_1 = \sigma(z_1) = \sigma(1.1) \approx 0.75$
-   $z_2 = w_2 \cdot a_1 + b_2 = 0.8 \cdot 0.75 + 0.2 = 0.8$
-   $\hat{y} = a_2 = \sigma(z_2) = \sigma(0.8) \approx 0.69$
-   $L = \frac{1}{2}(0.69 - 1)^2 \approx 0.048$

**2. Backward Pass (tÃ­nh gradient cho `w2`):**
-   Ta cáº§n $\frac{\partial L}{\partial w_2}$. Ãp dá»¥ng chain rule:
    $$ \frac{\partial L}{\partial w_2} = \frac{\partial L}{\partial \hat{y}} \cdot \frac{\partial \hat{y}}{\partial z_2} \cdot \frac{\partial z_2}{\partial w_2} $$
-   TÃ­nh tá»«ng thÃ nh pháº§n:
    -   $\frac{\partial L}{\partial \hat{y}} = (\hat{y} - y) = 0.69 - 1 = -0.31$
    -   $\frac{\partial \hat{y}}{\partial z_2} = \sigma'(z_2) = \sigma(z_2)(1 - \sigma(z_2)) = 0.69 \cdot (1 - 0.69) \approx 0.21$
    -   $\frac{\partial z_2}{\partial w_2} = a_1 = 0.75$
-   Káº¿t há»£p láº¡i:
    -   $\frac{\partial L}{\partial w_2} = -0.31 \cdot 0.21 \cdot 0.75 \approx -0.049$

**3. Cáº­p nháº­t `w2`:**
-   Giáº£ sá»­ learning rate `Î± = 0.1`.
-   $w_{2, \text{new}} = w_{2, \text{old}} - \alpha \cdot \frac{\partial L}{\partial w_2} = 0.8 - 0.1 \cdot (-0.049) \approx 0.8049$
-   Trá»ng sá»‘ `w2` Ä‘Ã£ Ä‘Æ°á»£c cáº­p nháº­t má»™t chÃºt Ä‘á»ƒ giáº£m loss. QuÃ¡ trÃ¬nh nÃ y Ä‘Æ°á»£c láº·p láº¡i cho táº¥t cáº£ cÃ¡c tham sá»‘ khÃ¡c (`w1`, `b1`, `b2`) vÃ  cho hÃ ng nghÃ¬n, hÃ ng triá»‡u máº«u dá»¯ liá»‡u.

#### Implementation vá»›i PyTorch
PyTorch tá»± Ä‘á»™ng hÃ³a hoÃ n toÃ n quÃ¡ trÃ¬nh nÃ y vá»›i `autograd`.

```python
import torch
import torch.nn as nn

# Dá»¯ liá»‡u vÃ  mÃ´ hÃ¬nh giá»‘ng vÃ­ dá»¥ trÃªn
x = torch.tensor([2.0])
y = torch.tensor([1.0])

w1 = torch.tensor([0.5], requires_grad=True)
b1 = torch.tensor([0.1], requires_grad=True)
w2 = torch.tensor([0.8], requires_grad=True)
b2 = torch.tensor([0.2], requires_grad=True)

# 1. Forward Pass
z1 = w1 * x + b1
a1 = torch.sigmoid(z1)
z2 = w2 * a1 + b2
y_hat = torch.sigmoid(z2)
loss = 0.5 * (y_hat - y)**2

print(f"Dá»± Ä‘oÃ¡n y_hat: {y_hat.item():.4f}")
print(f"Loss ban Ä‘áº§u: {loss.item():.4f}")

# 2. Backward Pass
loss.backward() # PyTorch tá»± Ä‘á»™ng tÃ­nh táº¥t cáº£ gradient!

# In ra gradient
print(f"\nGradient cá»§a loss theo w2 (tÃ­nh tay â‰ˆ -0.049): {w2.grad.item():.4f}")
print(f"Gradient cá»§a loss theo b2: {b2.grad.item():.4f}")
print(f"Gradient cá»§a loss theo w1: {w1.grad.item():.4f}")
print(f"Gradient cá»§a loss theo b1: {b1.grad.item():.4f}")

# 3. Cáº­p nháº­t trá»ng sá»‘ (thá»§ cÃ´ng)
lr = 0.1
with torch.no_grad(): # Táº¯t theo dÃµi gradient khi cáº­p nháº­t
    w2 -= lr * w2.grad
    b2 -= lr * b2.grad
    w1 -= lr * w1.grad
    b1 -= lr * b1.grad

    # Reset gradients cho láº§n láº·p tiáº¿p theo
    w2.grad.zero_()
    b2.grad.zero_()
    w1.grad.zero_()
    b1.grad.zero_()

print(f"\nw2 má»›i sau 1 bÆ°á»›c cáº­p nháº­t: {w2.item():.4f}")
```
**Giáº£i thÃ­ch khÃ¡i niá»‡m:**
- **Forward Pass**: TÃ­nh toÃ¡n "xuÃ´i" tá»« input Ä‘áº¿n output Ä‘á»ƒ ra dá»± Ä‘oÃ¡n.
- **Backward Pass**: TÃ­nh toÃ¡n "ngÆ°á»£c" tá»« loss vá» input Ä‘á»ƒ tÃ­nh gradient cho má»—i tham sá»‘.
- **Chain Rule**: CÃ´ng cá»¥ giáº£i tÃ­ch cá»‘t lÃµi cho phÃ©p "báº» nhá»" Ä‘áº¡o hÃ m cá»§a má»™t hÃ m phá»©c táº¡p thÃ nh tÃ­ch cá»§a cÃ¡c Ä‘áº¡o hÃ m Ä‘Æ¡n giáº£n hÆ¡n.
- **Gradient**: Vector chá»‰ hÆ°á»›ng vÃ  Ä‘á»™ lá»›n cá»§a sá»± thay Ä‘á»•i lá»›n nháº¥t cá»§a hÃ m sá»‘, lÃ  kim chá»‰ nam cho viá»‡c cáº­p nháº­t trá»ng sá»‘.

## âš¡ 2. Optimization trong Deep Learning

Tá»‘i Æ°u hÃ³a lÃ  quÃ¡ trÃ¬nh Ä‘iá»u chá»‰nh cÃ¡c tham sá»‘ cá»§a mÃ´ hÃ¬nh (trá»ng sá»‘ vÃ  bias) Ä‘á»ƒ giáº£m thiá»ƒu hÃ m máº¥t mÃ¡t. ÄÃ¢y lÃ  trÃ¡i tim cá»§a quÃ¡ trÃ¬nh training.

### 2.1 Initialization Strategies - Chiáº¿n lÆ°á»£c khá»Ÿi táº¡o

> **Táº¡i sao quan trá»ng?** Viá»‡c khá»Ÿi táº¡o trá»ng sá»‘ ban Ä‘áº§u cÃ³ áº£nh hÆ°á»Ÿng ráº¥t lá»›n Ä‘áº¿n quÃ¡ trÃ¬nh há»™i tá»¥ cá»§a mÃ´ hÃ¬nh. Khá»Ÿi táº¡o sai cÃ¡ch cÃ³ thá»ƒ dáº«n Ä‘áº¿n hiá»‡n tÆ°á»£ng **vanishing gradients** (gradient quÃ¡ nhá») hoáº·c **exploding gradients** (gradient quÃ¡ lá»›n), khiáº¿n mÃ´ hÃ¬nh khÃ´ng há»c Ä‘Æ°á»£c.

#### Xavier/Glorot Initialization
- **TÆ° tÆ°á»Ÿng**: Giá»¯ cho phÆ°Æ¡ng sai (variance) cá»§a cÃ¡c activation vÃ  gradient khÃ´ng Ä‘á»•i qua cÃ¡c layer.
- **CÃ´ng thá»©c**: Láº¥y máº«u tá»« phÃ¢n phá»‘i chuáº©n vá»›i mean=0 vÃ  variance = $2 / (n_{in} + n_{out})$.
- **Khi nÃ o dÃ¹ng**: Hiá»‡u quáº£ vá»›i cÃ¡c activation function Ä‘á»‘i xá»©ng quanh 0 nhÆ° `tanh` hoáº·c `sigmoid`.

#### He Initialization
- **TÆ° tÆ°á»Ÿng**: TÆ°Æ¡ng tá»± Xavier, nhÆ°ng Ä‘Æ°á»£c Ä‘iá»u chá»‰nh cho `ReLU` activation.
- **LÃ½ do**: `ReLU` "giáº¿t cháº¿t" má»™t ná»­a sá»‘ neuron (cho output báº±ng 0), lÃ m giáº£m phÆ°Æ¡ng sai cá»§a output. He initialization bÃ¹ láº¡i báº±ng cÃ¡ch nhÃ¢n Ä‘Ã´i phÆ°Æ¡ng sai.
- **CÃ´ng thá»©c**: Láº¥y máº«u tá»« phÃ¢n phá»‘i chuáº©n vá»›i mean=0 vÃ  variance = $2 / n_{in}$.
- **Khi nÃ o dÃ¹ng**: Háº§u háº¿t cÃ¡c máº¡ng hiá»‡n Ä‘áº¡i sá»­ dá»¥ng `ReLU` hoáº·c cÃ¡c biáº¿n thá»ƒ cá»§a nÃ³, do Ä‘Ã³ He Initialization lÃ  lá»±a chá»n máº·c Ä‘á»‹nh phá»• biáº¿n.

### 2.2 Batch Normalization - Chuáº©n hÃ³a theo batch

> **Váº¥n Ä‘á» (Internal Covariate Shift)**: Trong quÃ¡ trÃ¬nh training, phÃ¢n phá»‘i cá»§a output tá»« má»—i layer thay Ä‘á»•i liÃªn tá»¥c khi cÃ¡c trá»ng sá»‘ cá»§a layer trÆ°á»›c Ä‘Ã³ Ä‘Æ°á»£c cáº­p nháº­t. Äiá»u nÃ y lÃ m cho cÃ¡c layer sau pháº£i liÃªn tá»¥c thÃ­ch á»©ng vá»›i má»™t "má»¥c tiÃªu di Ä‘á»™ng", lÃ m cháº­m quÃ¡ trÃ¬nh há»c.

**LÃ½ thuyáº¿t Batch Normalization**:
- **CÃ¡ch hoáº¡t Ä‘á»™ng**: Táº¡i má»—i mini-batch, Batch Normalization chuáº©n hÃ³a output cá»§a má»™t layer Ä‘á»ƒ chÃºng cÃ³ **mean=0 vÃ  variance=1**. Sau Ä‘Ã³, nÃ³ dÃ¹ng hai tham sá»‘ cÃ³ thá»ƒ há»c Ä‘Æ°á»£c lÃ  **gamma ($\gamma$)** vÃ  **beta ($\beta$)** Ä‘á»ƒ scale vÃ  shift láº¡i phÃ¢n phá»‘i nÃ y.
    ```
    Î¼_B = (1/m)Î£áµ¢ xáµ¢
    ÏƒÂ²_B = (1/m)Î£áµ¢(xáµ¢ - Î¼_B)Â²
    xÌ‚áµ¢ = (xáµ¢ - Î¼_B) / âˆš(ÏƒÂ²_B + Îµ)
    yáµ¢ = Î³xÌ‚áµ¢ + Î²  # Î³ vÃ  Î² lÃ  tham sá»‘ há»c Ä‘Æ°á»£c
    ```
- **Lá»£i Ã­ch**:
    - **á»”n Ä‘á»‹nh hÃ³a quÃ¡ trÃ¬nh training**: Giáº£m Internal Covariate Shift.
    - **TÄƒng tá»‘c Ä‘á»™ há»™i tá»¥**: Cho phÃ©p sá»­ dá»¥ng learning rate cao hÆ¡n.
    - **Regularization**: CÃ³ tÃ¡c dá»¥ng Ä‘iá»u chuáº©n nháº¹, Ä‘Ã´i khi cÃ³ thá»ƒ thay tháº¿ Dropout.

### 2.3 CÃ¡c thuáº­t toÃ¡n tá»‘i Æ°u hÃ³a (Optimization Algorithms)

Gradient Descent lÃ  ná»n táº£ng, nhÆ°ng cÃ³ nhiá»u biáº¿n thá»ƒ Ä‘á»ƒ cáº£i thiá»‡n tá»‘c Ä‘á»™ vÃ  sá»± á»•n Ä‘á»‹nh.

#### Batch vs. Stochastic vs. Mini-batch Gradient Descent

1.  **Batch Gradient Descent**:
    -   **CÃ¡ch hoáº¡t Ä‘á»™ng**: TÃ­nh toÃ¡n gradient trÃªn **toÃ n bá»™** táº­p dá»¯ liá»‡u training rá»“i má»›i cáº­p nháº­t trá»ng sá»‘.
    -   **Æ¯u Ä‘iá»ƒm**: HÆ°á»›ng Ä‘i Ä‘áº¿n cá»±c tiá»ƒu ráº¥t á»•n Ä‘á»‹nh vÃ  trá»±c tiáº¿p.
    -   **NhÆ°á»£c Ä‘iá»ƒm**: Cá»±c ká»³ cháº­m vÃ  tá»‘n bá»™ nhá»› vá»›i cÃ¡c táº­p dá»¯ liá»‡u lá»›n. KhÃ´ng kháº£ thi trong thá»±c táº¿ cho deep learning.

2.  **Stochastic Gradient Descent (SGD)**:
    -   **CÃ¡ch hoáº¡t Ä‘á»™ng**: TÃ­nh toÃ¡n gradient vÃ  cáº­p nháº­t trá»ng sá»‘ cho **tá»«ng máº«u dá»¯ liá»‡u má»™t**.
    -   **Æ¯u Ä‘iá»ƒm**: Nhanh, tá»‘n Ã­t bá»™ nhá»›, cÃ³ thá»ƒ "nháº£y" ra khá»i cÃ¡c Ä‘iá»ƒm cá»±c tiá»ƒu cá»¥c bá»™ (local minima) khÃ´ng tá»‘t nhá» sá»± "nhiá»…u" cá»§a nÃ³.
    -   **NhÆ°á»£c Ä‘iá»ƒm**: QuÃ¡ trÃ¬nh há»™i tá»¥ ráº¥t "á»“n Ã o" vÃ  khÃ´ng á»•n Ä‘á»‹nh.

3.  **Mini-batch Gradient Descent**:
    -   **CÃ¡ch hoáº¡t Ä‘á»™ng**: Thá»a hiá»‡p giá»¯a hai phÆ°Æ¡ng phÃ¡p trÃªn. TÃ­nh toÃ¡n gradient vÃ  cáº­p nháº­t trá»ng sá»‘ trÃªn má»™t **batch nhá»** (vÃ­ dá»¥: 32, 64, 128 máº«u) dá»¯ liá»‡u.
    -   **Æ¯u Ä‘iá»ƒm**: Táº­n dá»¥ng Ä‘Æ°á»£c cáº£ lá»£i tháº¿ cá»§a hai phÆ°Æ¡ng phÃ¡p: há»™i tá»¥ á»•n Ä‘á»‹nh hÆ¡n SGD vÃ  hiá»‡u quáº£ vá» máº·t tÃ­nh toÃ¡n hÆ¡n Batch GD.
    -   **Thá»±c táº¿**: ÄÃ¢y lÃ  phÆ°Æ¡ng phÃ¡p Ä‘Æ°á»£c sá»­ dá»¥ng phá»• biáº¿n nháº¥t trong deep learning. Khi ngÆ°á»i ta nÃ³i "SGD", há» thÆ°á»ng ngá»¥ Ã½ lÃ  "Mini-batch SGD".

#### CÃ¡c Optimizer nÃ¢ng cao

-   **Momentum**:
    -   **TÆ° tÆ°á»Ÿng**: ThÃªm "Ä‘Ã " (momentum) vÃ o quÃ¡ trÃ¬nh cáº­p nháº­t. Giá»‘ng nhÆ° má»™t quáº£ bÃ³ng lÄƒn xuá»‘ng dá»‘c, nÃ³ tÃ­ch lÅ©y váº­n tá»‘c vÃ  cÃ³ xu hÆ°á»›ng tiáº¿p tá»¥c di chuyá»ƒn theo hÆ°á»›ng cÅ©.
    -   **TÃ¡c dá»¥ng**: GiÃºp vÆ°á»£t qua cÃ¡c vÃ¹ng "pháº³ng" (plateaus) vÃ  cÃ¡c Ä‘iá»ƒm cá»±c tiá»ƒu cá»¥c bá»™ (local minima) nÃ´ng, tÄƒng tá»‘c Ä‘á»™ há»™i tá»¥.

-   **Adam (Adaptive Moment Estimation)**:
    -   **TÆ° tÆ°á»Ÿng**: Káº¿t há»£p Ã½ tÆ°á»Ÿng cá»§a Momentum vÃ  RMSprop (má»™t thuáº­t toÃ¡n khÃ¡c cÅ©ng Ä‘iá»u chá»‰nh learning rate). NÃ³ duy trÃ¬ cáº£ "momentum" vÃ  má»™t learning rate riÃªng cho tá»«ng tham sá»‘.
    -   **TÃ¡c dá»¥ng**: ThÆ°á»ng há»™i tá»¥ ráº¥t nhanh vÃ  hoáº¡t Ä‘á»™ng tá»‘t trÃªn nhiá»u loáº¡i bÃ i toÃ¡n khÃ¡c nhau. LÃ  má»™t trong nhá»¯ng optimizer phá»• biáº¿n vÃ  an toÃ n nháº¥t Ä‘á»ƒ báº¯t Ä‘áº§u.

### 2.4 CÃ¡c ká»¹ thuáº­t Regularization khÃ¡c
Regularization lÃ  báº¥t ká»³ ká»¹ thuáº­t nÃ o Ä‘Æ°á»£c thÃªm vÃ o quÃ¡ trÃ¬nh há»c Ä‘á»ƒ ngÄƒn cháº·n overfitting.

#### Dropout
-   **TÆ° tÆ°á»Ÿng**: "Äá»«ng bá» táº¥t cáº£ trá»©ng vÃ o má»™t giá»".
-   **CÃ¡ch hoáº¡t Ä‘á»™ng**: Trong má»—i lÆ°á»£t training, "táº¯t" (Ä‘áº·t output báº±ng 0) má»™t cÃ¡ch ngáº«u nhiÃªn má»™t tá»· lá»‡ cÃ¡c neuron trong má»™t layer.
-   **Táº¡i sao hiá»‡u quáº£?**:
    -   NÃ³ buá»™c máº¡ng pháº£i há»c cÃ¡c **biá»ƒu diá»…n dÆ° thá»«a (redundant representations)**. Máº¡ng khÃ´ng thá»ƒ phá»¥ thuá»™c vÃ o má»™t vÃ i neuron cá»¥ thá»ƒ nÃ o Ä‘Ã³, vÃ¬ chÃºng cÃ³ thá»ƒ bá»‹ "táº¯t" báº¥t cá»© lÃºc nÃ o.
    -   CÃ³ thá»ƒ xem Dropout nhÆ° viá»‡c huáº¥n luyá»‡n má»™t **táº­p há»£p (ensemble)** khá»•ng lá»“ cÃ¡c máº¡ng nÆ¡-ron nhá» hÆ¡n, khÃ¡c nhau trÃªn cÃ¹ng má»™t lÃºc, rá»“i láº¥y trung bÃ¬nh káº¿t quáº£.
-   **LÆ°u Ã½**: Dropout chá»‰ Ä‘Æ°á»£c Ã¡p dá»¥ng trong quÃ¡ trÃ¬nh **training**. Khi **testing/inference**, táº¥t cáº£ cÃ¡c neuron Ä‘á»u Ä‘Æ°á»£c sá»­ dá»¥ng.

#### Early Stopping
-   **TÆ° tÆ°á»Ÿng**: "Dá»«ng láº¡i khi má»i thá»© báº¯t Ä‘áº§u tá»‡ Ä‘i."
-   **CÃ¡ch hoáº¡t Ä‘á»™ng**:
    1.  Trong quÃ¡ trÃ¬nh training, theo dÃµi loss/metric trÃªn má»™t táº­p dá»¯ liá»‡u riÃªng gá»i lÃ  **validation set**.
    2.  LÆ°u láº¡i tráº¡ng thÃ¡i (checkpoint) cá»§a mÃ´ hÃ¬nh má»—i khi hiá»‡u suáº¥t trÃªn validation set Ä‘Æ°á»£c cáº£i thiá»‡n.
    3.  Náº¿u hiá»‡u suáº¥t trÃªn validation set khÃ´ng cáº£i thiá»‡n (tháº­m chÃ­ tá»‡ Ä‘i) trong má»™t sá»‘ epoch nháº¥t Ä‘á»‹nh (gá»i lÃ  `patience`), hÃ£y dá»«ng viá»‡c training láº¡i.
    4.  MÃ´ hÃ¬nh tá»‘t nháº¥t cá»§a báº¡n lÃ  mÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c lÆ°u á»Ÿ checkpoint cuá»‘i cÃ¹ng.
-   **Táº¡i sao hiá»‡u quáº£?**: LÃ  má»™t cÃ¡ch cá»±c ká»³ Ä‘Æ¡n giáº£n vÃ  hiá»‡u quáº£ Ä‘á»ƒ ngÄƒn overfitting. Khi training loss tiáº¿p tá»¥c giáº£m nhÆ°ng validation loss báº¯t Ä‘áº§u tÄƒng, Ä‘Ã³ lÃ  dáº¥u hiá»‡u rÃµ rÃ ng cá»§a overfitting, vÃ  Early Stopping giÃºp ta dá»«ng láº¡i ngay táº¡i thá»i Ä‘iá»ƒm Ä‘Ã³.

## ğŸ—ï¸ 3. Kiáº¿n trÃºc máº¡ng (Network Architectures)

Viá»‡c lá»±a chá»n kiáº¿n trÃºc máº¡ng phÃ¹ há»£p lÃ  ráº¥t quan trá»ng vÃ¬ má»—i loáº¡i kiáº¿n trÃºc Ä‘Æ°á»£c tá»‘i Æ°u hÃ³a cho má»™t dáº¡ng dá»¯ liá»‡u vÃ  bÃ i toÃ¡n cá»¥ thá»ƒ.

### 3.1 Convolutional Neural Networks (CNNs) - Máº¡ng nÆ¡-ron tÃ­ch cháº­p

-   **Dáº¡ng dá»¯ liá»‡u**: Chá»§ yáº¿u dÃ¹ng cho **dá»¯ liá»‡u dáº¡ng lÆ°á»›i (grid-like data)** nhÆ° hÃ¬nh áº£nh (2D), video (3D: khÃ´ng gian + thá»i gian).
-   **TÆ° tÆ°á»Ÿng cá»‘t lÃµi**: CNN táº­n dá»¥ng cáº¥u trÃºc khÃ´ng gian cá»¥c bá»™ cá»§a dá»¯ liá»‡u báº±ng cÃ¡ch sá»­ dá»¥ng cÃ¡c bá»™ lá»c (filters) nhá» Ä‘á»ƒ quÃ©t qua dá»¯ liá»‡u. Äiá»u nÃ y giÃºp phÃ¡t hiá»‡n cÃ¡c máº«u (patterns) cá»¥c bá»™ (nhÆ° cáº¡nh, gÃ³c, hÃ¬nh dáº¡ng) vÃ  tÃ¡i sá»­ dá»¥ng cÃ¡c bá»™ lá»c Ä‘Ã³ trÃªn toÃ n bá»™ áº£nh.
-   **CÃ¡c thÃ nh pháº§n chÃ­nh**:
    1.  **Convolutional Layer**: Ãp dá»¥ng cÃ¡c bá»™ lá»c (kernels) Ä‘á»ƒ táº¡o ra cÃ¡c feature map.
    2.  **Pooling Layer**: Giáº£m kÃ­ch thÆ°á»›c khÃ´ng gian cá»§a feature map (Max Pooling, Average Pooling) Ä‘á»ƒ giáº£m sá»‘ lÆ°á»£ng tham sá»‘ vÃ  chá»‘ng overfitting.
    3.  **Fully Connected Layer**: CÃ¡c layer dense truyá»n thá»‘ng á»Ÿ cuá»‘i máº¡ng Ä‘á»ƒ thá»±c hiá»‡n phÃ¢n loáº¡i hoáº·c há»“i quy.

#### CÃ¡c kiáº¿n trÃºc CNN ná»•i báº­t
1.  **VGG (Visual Geometry Group)**:
    -   **Äáº·c Ä‘iá»ƒm**: Ná»•i tiáº¿ng vá»›i sá»± Ä‘Æ¡n giáº£n nhÆ°ng hiá»‡u quáº£. VGG chá»§ yáº¿u sá»­ dá»¥ng cÃ¡c khá»‘i tÃ­ch cháº­p 3x3 nhá» (small 3x3 convolutional filters) láº·p Ä‘i láº·p láº¡i.
    -   **Ã tÆ°á»Ÿng**: Chá»©ng minh ráº±ng Ä‘á»™ sÃ¢u cá»§a máº¡ng (stacking many small convolutional layers) quan trá»ng hÆ¡n kÃ­ch thÆ°á»›c bá»™ lá»c lá»›n.
2.  **Inception (GoogLeNet)**:
    -   **Äáº·c Ä‘iá»ƒm**: Giá»›i thiá»‡u "Inception module", má»™t khá»‘i xÃ¢y dá»±ng mÃ  thá»±c hiá»‡n nhiá»u loáº¡i tÃ­ch cháº­p (vÃ­ dá»¥: 1x1, 3x3, 5x5) vÃ  pooling song song.
    -   **Ã tÆ°á»Ÿng**: Cho phÃ©p mÃ´ hÃ¬nh tá»± Ä‘á»™ng chá»n cÃ¡c bá»™ lá»c cÃ³ kÃ­ch thÆ°á»›c phÃ¹ há»£p nháº¥t á»Ÿ má»—i cáº¥p Ä‘á»™ trá»«u tÆ°á»£ng, Ä‘á»“ng thá»i giáº£m chi phÃ­ tÃ­nh toÃ¡n thÃ´ng qua tÃ­ch cháº­p 1x1.
3.  **ResNet (Residual Network)**:
    -   **Äáº·c Ä‘iá»ƒm**: Giá»›i thiá»‡u **káº¿t ná»‘i dÆ° (Residual Connections)** hoáº·c "skip connections".
    -   **Ã tÆ°á»Ÿng**: Cho phÃ©p xÃ¢y dá»±ng cÃ¡c máº¡ng cá»±c ká»³ sÃ¢u (hÃ ng trÄƒm layer) mÃ  khÃ´ng gáº·p váº¥n Ä‘á» vanishing gradients. Vá» cÆ¡ báº£n, má»™t layer há»c `F(x)` (pháº§n dÆ°) thay vÃ¬ `H(x)` (mapping Ä‘áº§y Ä‘á»§), vÃ  `H(x) = x + F(x)`. Äiá»u nÃ y giÃºp tá»‘i Æ°u hÃ³a dá»… dÃ ng hÆ¡n vÃ¬ `F(x)` thÆ°á»ng dá»… há»c hÆ¡n `H(x)`.

### 3.2 Recurrent Neural Networks (RNNs) - Máº¡ng nÆ¡-ron há»“i quy

-   **Dáº¡ng dá»¯ liá»‡u**: Tá»‘i Æ°u cho **dá»¯ liá»‡u tuáº§n tá»± (sequential data)** nhÆ° vÄƒn báº£n, chuá»—i thá»i gian, Ã¢m thanh.
-   **TÆ° tÆ°á»Ÿng cá»‘t lÃµi**: RNN cÃ³ má»™t "bá»™ nhá»›" bÃªn trong (state áº©n) cho phÃ©p nÃ³ xá»­ lÃ½ thÃ´ng tin tá»« cÃ¡c bÆ°á»›c thá»i gian trÆ°á»›c Ä‘Ã³ vÃ  sá»­ dá»¥ng nÃ³ Ä‘á»ƒ áº£nh hÆ°á»Ÿng Ä‘áº¿n output hiá»‡n táº¡i.
-   **Váº¥n Ä‘á» Vanishing/Exploding Gradients**: Trong cÃ¡c RNN truyá»n thá»‘ng, gradient cÃ³ thá»ƒ trá»Ÿ nÃªn quÃ¡ nhá» (vanishing) hoáº·c quÃ¡ lá»›n (exploding) khi lan truyá»n qua cÃ¡c chuá»—i dÃ i, khiáº¿n mÃ´ hÃ¬nh khÃ³ há»c Ä‘Æ°á»£c cÃ¡c phá»¥ thuá»™c dÃ i háº¡n.

#### LSTM (Long Short-Term Memory) vÃ  GRU (Gated Recurrent Unit)
ÄÃ¢y lÃ  cÃ¡c biáº¿n thá»ƒ cá»§a RNN Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘áº·c biá»‡t Ä‘á»ƒ giáº£i quyáº¿t váº¥n Ä‘á» Vanishing Gradients vÃ  há»c Ä‘Æ°á»£c cÃ¡c phá»¥ thuá»™c dÃ i háº¡n.
1.  **LSTM**:
    -   **Ã tÆ°á»Ÿng**: Sá»­ dá»¥ng cÃ¡c "cá»•ng" (gates) Ä‘á»ƒ kiá»ƒm soÃ¡t dÃ²ng thÃ´ng tin vÃ o/ra khá»i "tráº¡ng thÃ¡i Ã´ nhá»›" (cell state).
    -   **Gates**:
        -   **Forget Gate**: Quyáº¿t Ä‘á»‹nh thÃ´ng tin nÃ o tá»« cell state cÅ© sáº½ bá»‹ quÃªn.
        -   **Input Gate**: Quyáº¿t Ä‘á»‹nh thÃ´ng tin nÃ o má»›i sáº½ Ä‘Æ°á»£c thÃªm vÃ o cell state.
        -   **Output Gate**: Quyáº¿t Ä‘á»‹nh thÃ´ng tin nÃ o tá»« cell state sáº½ Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ tÃ­nh hidden state vÃ  output.
    -   CÃ¡c cá»•ng nÃ y Ä‘Æ°á»£c Ä‘iá»u khiá»ƒn bá»Ÿi cÃ¡c phÃ©p toÃ¡n sigmoid vÃ  phÃ©p nhÃ¢n element-wise.
2.  **GRU**:
    -   **Ã tÆ°á»Ÿng**: LÃ  má»™t phiÃªn báº£n Ä‘Æ¡n giáº£n hÆ¡n cá»§a LSTM, vá»›i Ã­t cá»•ng hÆ¡n (chá»‰ cÃ³ Update Gate vÃ  Reset Gate).
    -   **Æ¯u Ä‘iá»ƒm**: Huáº¥n luyá»‡n nhanh hÆ¡n LSTM má»™t chÃºt, nhÆ°ng thÆ°á»ng cho hiá»‡u suáº¥t tÆ°Æ¡ng Ä‘Æ°Æ¡ng.

### 3.3 Transformer Architecture

-   **Dáº¡ng dá»¯ liá»‡u**: CÅ©ng dÃ¹ng cho **dá»¯ liá»‡u tuáº§n tá»±**, Ä‘áº·c biá»‡t lÃ  vÄƒn báº£n.
-   **TÆ° tÆ°á»Ÿng cá»‘t lÃµi**: HoÃ n toÃ n bá» qua kiáº¿n trÃºc há»“i quy vÃ  chá»‰ dá»±a vÃ o cÆ¡ cháº¿ **Self-Attention** Ä‘á»ƒ xá»­ lÃ½ cÃ¡c phá»¥ thuá»™c dÃ i háº¡n trong chuá»—i.
-   **Äáº·c Ä‘iá»ƒm**: CÃ³ thá»ƒ xá»­ lÃ½ cÃ¡c pháº§n cá»§a chuá»—i song song (parallelization), giÃºp tÄƒng tá»‘c Ä‘á»™ training Ä‘Ã¡ng ká»ƒ.

(Äá»ƒ biáº¿t thÃªm chi tiáº¿t vá» Transformer, vui lÃ²ng tham kháº£o tÃ i liá»‡u `06-llms.md`).

## ğŸ“š TÃ i liá»‡u tham kháº£o

### LÃ½ thuyáº¿t Neural Networks
- [Deep Learning - Ian Goodfellow](https://www.deeplearningbook.org/) - SÃ¡ch giÃ¡o khoa cÆ¡ báº£n
- [Neural Networks and Deep Learning - Michael Nielsen](http://neuralnetworksanddeeplearning.com/) - HÆ°á»›ng dáº«n trá»±c tuyáº¿n

### Optimization vÃ  Training
- [Understanding the difficulty of training deep feedforward neural networks](https://proceedings.mlr.press/v9/glorot10a.html) - Xavier/Glorot paper
- [Delving Deep into Rectifiers](https://arxiv.org/abs/1502.01852) - He initialization paper
- [Batch Normalization: Accelerating Deep Network Training](https://arxiv.org/abs/1502.03167) - BatchNorm paper

### Kiáº¿n trÃºc máº¡ng
- [Very Deep Convolutional Networks for Large-Scale Image Recognition (VGG)](https://arxiv.org/abs/1409.1556)
- [Going Deeper with Convolutions (Inception/GoogLeNet)](https://arxiv.org/abs/1409.4842)
- [Deep Residual Learning for Image Recognition (ResNet)](https://arxiv.org/abs/1512.03385)
- [Long Short-Term Memory (LSTM)](https://www.bioinf.jku.at/publications/older/2604.pdf)
- [Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation (GRU)](https://arxiv.org/abs/1406.1078)

### Implementation
- [PyTorch Tutorials](https://pytorch.org/tutorials/) - HÆ°á»›ng dáº«n PyTorch chÃ­nh thá»©c
- [PyTorch Documentation](https://pytorch.org/docs/stable/) - TÃ i liá»‡u PyTorch

## ğŸ¯ BÃ i táº­p thá»±c hÃ nh

1.  **Universal Approximation**: Implement neural network xáº¥p xá»‰ cÃ¡c hÃ m phá»©c táº¡p.
2.  **Backpropagation**: Tá»± implement backpropagation tá»« Ä‘áº§u.
3.  **Initialization**: So sÃ¡nh hiá»‡u quáº£ cÃ¡c phÆ°Æ¡ng phÃ¡p initialization.
4.  **Batch Normalization**: Implement BatchNorm tá»« Ä‘áº§u vÃ  so sÃ¡nh vá»›i PyTorch.
5.  **Kiáº¿n trÃºc CNN**: XÃ¢y dá»±ng vÃ  huáº¥n luyá»‡n má»™t mÃ´ hÃ¬nh VGG hoáº·c ResNet Ä‘Æ¡n giáº£n cho bá»™ dá»¯ liá»‡u CIFAR-10.
6.  **Kiáº¿n trÃºc RNN**: XÃ¢y dá»±ng vÃ  huáº¥n luyá»‡n má»™t mÃ´ hÃ¬nh LSTM hoáº·c GRU cho bÃ i toÃ¡n phÃ¢n loáº¡i chuá»—i (vÃ­ dá»¥: phÃ¢n loáº¡i sentiment cho vÄƒn báº£n ngáº¯n).

## ğŸš€ BÆ°á»›c tiáº¿p theo

Sau khi hoÃ n thÃ nh Deep Learning cÆ¡ báº£n, báº¡n sáº½:
-   Hiá»ƒu sÃ¢u vá» lÃ½ thuyáº¿t neural networks.
-   Biáº¿t cÃ¡ch tá»‘i Æ°u hÃ³a training process.
-   CÃ³ thá»ƒ thiáº¿t káº¿ kiáº¿n trÃºc máº¡ng phÃ¹ há»£p cho cÃ¡c bÃ i toÃ¡n khÃ¡c nhau.
-   Sáºµn sÃ ng há»c cÃ¡c á»©ng dá»¥ng cá»¥ thá»ƒ trong Computer Vision vÃ  NLP.

---

*ChÃºc báº¡n trá»Ÿ thÃ nh Deep Learning Engineer xuáº¥t sáº¯c! ğŸ‰*

