# üöÄ D·ª± √°n th·ª±c h√†nh - Portfolio Building

> **M·ª•c ti√™u**: X√¢y d·ª±ng portfolio chuy√™n nghi·ªáp th√¥ng qua c√°c d·ª± √°n th·ª±c t·∫ø, √°p d·ª•ng ki·∫øn th·ª©c AI/ML v√†o gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ th·ª±c t·∫ø

## üìã T·ªïng quan d·ª± √°n

```mermaid
graph TD
    A[üöÄ Portfolio Building] --> B[üìä Data Analysis Projects]
    A --> C[ü§ñ Machine Learning Projects]
    A --> D[üß† Deep Learning Projects]
    A --> E[üìà Time Series Projects]
    A --> F[ü§ñ LLM Applications]
    A --> G[üöÄ MLOps Projects]
    
    B --> B1[Exploratory Data Analysis]
    B --> B2[Business Intelligence Dashboard]
    B --> B3[A/B Testing Analysis]
    B --> B4[Customer Segmentation]
    
    C --> C1[Predictive Modeling]
    C --> C2[Recommendation System]
    C --> C3[Anomaly Detection]
    C --> C4[Classification Models]
    
    D --> D1[Computer Vision]
    D --> D2[Natural Language Processing]
    D --> D3[Audio Processing]
    D --> D4[Generative AI]
    
    E --> E1[Sales Forecasting]
    E --> E2[Stock Price Prediction]
    E --> E3[Energy Consumption]
    E --> E4[Weather Prediction]
    
    F --> F1[Chatbot Development]
    F --> F2[Document Q&A System]
    F --> F3[Code Generation]
    F --> F4[Content Summarization]
    
    G --> G1[Model Deployment]
    G --> G2[ML Pipeline Automation]
    G --> G3[Model Monitoring]
    G --> G4[CI/CD for ML]
```

![Portfolio Projects](assets/portfolio-projects.svg)

![Portfolio Projects PNG](assets/portfolio-projects.png)

**üìÅ [Xem file PNG tr·ª±c ti·∫øp](assets/portfolio-projects.png)**

**üìÅ [Xem file PNG tr·ª±c ti·∫øp](assets/portfolio-projects.png)**

**üìÅ [Xem file PNG tr·ª±c ti·∫øp](assets/portfolio-projects.png)**

## üéØ **D·ª± √°n theo c·∫•p ƒë·ªô**

### üå± **C·∫•p ƒë·ªô 1: Data Analysis (Beginner)**

#### N·ªÅn t·∫£ng l√Ω thuy·∫øt c·∫ßn n·∫Øm
Tr∆∞·ªõc khi b·∫Øt ƒë·∫ßu c√°c d·ª± √°n n√†y, h√£y ƒë·∫£m b·∫£o b·∫°n ƒë√£ quen thu·ªôc v·ªõi c√°c kh√°i ni·ªám sau (t·ª´ c√°c t√†i li·ªáu tr∆∞·ªõc):
-   **Quy tr√¨nh CRISP-DM**: ƒê·∫∑c bi·ªát l√† 3 pha ƒë·∫ßu: Business Understanding, Data Understanding, v√† Data Preparation.
-   **Th·ªëng k√™ m√¥ t·∫£**: Mean, median, standard deviation. Bi·∫øt c√°ch d√πng `df.describe()` v√† di·ªÖn gi·∫£i k·∫øt qu·∫£.
-   **Tr·ª±c quan h√≥a d·ªØ li·ªáu**: Bi·∫øt khi n√†o n√™n d√πng bi·ªÉu ƒë·ªì c·ªôt (bar chart), bi·ªÉu ƒë·ªì ƒë∆∞·ªùng (line chart), bi·ªÉu ƒë·ªì ph√¢n t√°n (scatter plot), v√† bi·ªÉu ƒë·ªì h·ªôp (box plot).
-   **Thao t√°c d·ªØ li·ªáu v·ªõi Pandas**: L·ªçc, nh√≥m (`groupby`), t·ªïng h·ª£p (`agg`), v√† x·ª≠ l√Ω gi√° tr·ªã thi·∫øu.

---

#### **1.1 Exploratory Data Analysis - Ph√¢n t√≠ch d·ªØ li·ªáu t√†u Titanic**
> **M·ª•c ti√™u**: √Åp d·ª•ng quy tr√¨nh EDA m·ªôt c√°ch c√≥ h·ªá th·ªëng ƒë·ªÉ kh√°m ph√° m·ªôt b·ªô d·ªØ li·ªáu kinh ƒëi·ªÉn, t·ª´ ƒë√≥ r√∫t ra c√°c insight v√† gi·∫£ thuy·∫øt ban ƒë·∫ßu.

-   **Dataset**: [Titanic - Machine Learning from Disaster](https://www.kaggle.com/c/titanic)
-   **Problem Framing**:
    -   **B·ªëi c·∫£nh kinh doanh**: C√¥ng ty v·∫≠n t·∫£i White Star Line mu·ªën hi·ªÉu c√°c y·∫øu t·ªë n√†o ƒë√£ ·∫£nh h∆∞·ªüng ƒë·∫øn t·ª∑ l·ªá s·ªëng s√≥t trong th·∫£m h·ªça Titanic ƒë·ªÉ c·∫£i thi·ªán c√°c quy ƒë·ªãnh an to√†n cho c√°c chuy·∫øn ƒëi trong t∆∞∆°ng lai.
    -   **B√†i to√°n ph√¢n t√≠ch**: Ph√¢n t√≠ch c√°c ƒë·∫∑c ƒëi·ªÉm c·ªßa h√†nh kh√°ch (tu·ªïi, gi·ªõi t√≠nh, h·∫°ng v√©,...) ƒë·ªÉ t√¨m ra c√°c nh√≥m c√≥ t·ª∑ l·ªá s·ªëng s√≥t cao ho·∫∑c th·∫•p b·∫•t th∆∞·ªùng.
-   **Key Challenges**:
    -   **D·ªØ li·ªáu thi·∫øu**: C·ªôt `Age`, `Cabin`, v√† `Embarked` c√≥ nhi·ªÅu gi√° tr·ªã b·ªã thi·∫øu. C·∫ßn c√≥ chi·∫øn l∆∞·ª£c x·ª≠ l√Ω ph√π h·ª£p (v√≠ d·ª•: ƒëi·ªÅn tu·ªïi b·∫±ng gi√° tr·ªã trung v·ªã theo gi·ªõi t√≠nh v√† h·∫°ng v√©).
    -   **Feature Engineering**: C·ªôt `Name` ch·ª©a th√¥ng tin v·ªÅ danh x∆∞ng (Mr., Mrs., Miss., Master) c√≥ th·ªÉ h·ªØu √≠ch. C·∫ßn tr√≠ch xu·∫•t th√¥ng tin n√†y.
-   **Success Metrics**:
    -   **Ph√¢n t√≠ch**: T√¨m ra √≠t nh·∫•t 3-5 gi·∫£ thuy·∫øt c√≥ √Ω nghƒ©a v√† ƒë∆∞·ª£c ch·ª©ng minh b·∫±ng bi·ªÉu ƒë·ªì (v√≠ d·ª•: "Ph·ª• n·ªØ ·ªü khoang h·∫°ng nh·∫•t c√≥ t·ª∑ l·ªá s·ªëng s√≥t cao nh·∫•t").
    -   **Tr√¨nh b√†y**: M·ªôt b·∫£n tr√¨nh b√†y (notebook ho·∫∑c slide) r√µ r√†ng, logic, c√≥ kh·∫£ nƒÉng k·ªÉ m·ªôt "c√¢u chuy·ªán" v·ªÅ nh·ªØng g√¨ ƒë√£ x·∫£y ra d·ª±a tr√™n d·ªØ li·ªáu.
-   **Theoretical Connections**:
    -   **Data Understanding & Preparation**: √Åp d·ª•ng tr·ª±c ti·∫øp c√°c b∆∞·ªõc 2 v√† 3 c·ªßa CRISP-DM.
    -   **Univariate & Bivariate Analysis**: Ph√¢n t√≠ch ph√¢n ph·ªëi c·ªßa `Age` (univariate) v√† m·ªëi quan h·ªá gi·ªØa `Pclass` v√† `Survived` (bivariate).
-   **Deliverables**:
    -   Jupyter notebook ghi l·∫°i to√†n b·ªô qu√° tr√¨nh ph√¢n t√≠ch.
    -   M·ªôt b·∫£n b√°o c√°o t√≥m t·∫Øt c√°c insight ch√≠nh v√† c√°c ƒë·ªÅ xu·∫•t (n·∫øu c√≥).

---

#### **1.2 Business Intelligence Dashboard - Ph√¢n t√≠ch d·ªØ li·ªáu b√°n h√†ng**
> **M·ª•c ti√™u**: ƒê√≥ng vai m·ªôt Business Intelligence Analyst, x√¢y d·ª±ng m·ªôt dashboard t∆∞∆°ng t√°c ƒë·ªÉ gi√∫p gi√°m ƒë·ªëc kinh doanh theo d√µi hi·ªáu su·∫•t v√† ƒë∆∞a ra quy·∫øt ƒë·ªãnh.

-   **Dataset**: [Sample Sales Data](https://www.kaggle.com/datasets/kyanyoga/sample-sales-data)
-   **Problem Framing**:
    -   **B·ªëi c·∫£nh kinh doanh**: M·ªôt c√¥ng ty b√°n l·∫ª to√†n c·∫ßu c·∫ßn m·ªôt c√¥ng c·ª• ƒë·ªÉ theo d√µi c√°c ch·ªâ s·ªë hi·ªáu su·∫•t kinh doanh (KPIs) theo th·ªùi gian th·ª±c ·ªü c√°c khu v·ª±c v√† d√≤ng s·∫£n ph·∫©m kh√°c nhau.
    -   **B√†i to√°n ph√¢n t√≠ch**: X√¢y d·ª±ng m·ªôt dashboard cho ph√©p c√°c nh√† qu·∫£n l√Ω l·ªçc d·ªØ li·ªáu theo th·ªùi gian, khu v·ª±c, s·∫£n ph·∫©m v√† xem c√°c KPI ch√≠nh nh∆∞ doanh thu, l·ª£i nhu·∫≠n, s·ªë l∆∞·ª£ng ƒë∆°n h√†ng.
-   **Key Challenges**:
    -   **Thi·∫øt k·∫ø KPI**: X√°c ƒë·ªãnh c√°c KPI th·ª±c s·ª± quan tr·ªçng ƒë·ªëi v·ªõi doanh nghi·ªáp (v√≠ d·ª•: Doanh thu, L·ª£i nhu·∫≠n, T·ª∑ l·ªá tƒÉng tr∆∞·ªüng so v·ªõi th√°ng tr∆∞·ªõc, S·∫£n ph·∫©m b√°n ch·∫°y nh·∫•t).
    -   **Thi·∫øt k·∫ø Dashboard**: B·ªë c·ª•c dashboard ph·∫£i logic, d·ªÖ hi·ªÉu v√† kh√¥ng g√¢y qu√° t·∫£i th√¥ng tin. Bi·ªÉu ƒë·ªì ph·∫£i ƒë∆∞·ª£c ch·ªçn ph√π h·ª£p v·ªõi lo·∫°i d·ªØ li·ªáu.
-   **Success Metrics**:
    -   **T∆∞∆°ng t√°c**: Dashboard cho ph√©p ng∆∞·ªùi d√πng t·ª± kh√°m ph√° d·ªØ li·ªáu th√¥ng qua c√°c b·ªô l·ªçc (filters).
    -   **R√µ r√†ng**: C√°c KPI ch√≠nh ƒë∆∞·ª£c l√†m n·ªïi b·∫≠t v√† d·ªÖ ƒë·ªçc. C√°c bi·ªÉu ƒë·ªì c√≥ ti√™u ƒë·ªÅ v√† nh√£n tr·ª•c r√µ r√†ng.
    -   **Insightful**: Dashboard kh√¥ng ch·ªâ hi·ªÉn th·ªã d·ªØ li·ªáu m√† c√≤n gi√∫p ng∆∞·ªùi d√πng ph√°t hi·ªán ra c√°c xu h∆∞·ªõng ho·∫∑c ƒëi·ªÉm b·∫•t th∆∞·ªùng (v√≠ d·ª•: m·ªôt d√≤ng s·∫£n ph·∫©m b·∫•t ng·ªù s·ª•t gi·∫£m doanh s·ªë).
-   **Theoretical Connections**:
    -   **Visualization Principles**: √Åp d·ª•ng c√°c nguy√™n t·∫Øc v·ªÅ vi·ªác ch·ªçn ƒë√∫ng lo·∫°i bi·ªÉu ƒë·ªì cho ƒë√∫ng m·ª•c ƒë√≠ch.
    -   **Data Storytelling**: S·∫Øp x·∫øp c√°c th√†nh ph·∫ßn trong dashboard ƒë·ªÉ k·ªÉ m·ªôt c√¢u chuy·ªán v·ªÅ hi·ªáu su·∫•t kinh doanh.
-   **Deliverables**:
    -   M·ªôt ·ª©ng d·ª•ng web dashboard (s·ª≠ d·ª•ng Plotly Dash, Streamlit, ho·∫∑c Tableau).
    -   M·ªôt b·∫£n tr√¨nh b√†y ng·∫Øn gi·∫£i th√≠ch c√°ch s·ª≠ d·ª•ng dashboard v√† c√°c insight ch√≠nh c√≥ th·ªÉ r√∫t ra.

### üåø **C·∫•p ƒë·ªô 2: Machine Learning (Intermediate)**

#### N·ªÅn t·∫£ng l√Ω thuy·∫øt c·∫ßn n·∫Øm
-   **Feature Engineering**: C√°c k·ªπ thu·∫≠t x·ª≠ l√Ω v√† t·∫°o feature m·ªõi, ƒë·∫∑c bi·ªát l√† `Temporal Features` v√† `Categorical Encoding`.
-   **Feature Selection**: Hi·ªÉu v√† √°p d·ª•ng ƒë∆∞·ª£c c√°c ph∆∞∆°ng ph√°p Filter, Wrapper, v√† Embedded.
-   **Supervised Learning**:
    -   Hi·ªÉu r√µ **Bias-Variance Tradeoff**.
    -   N·∫Øm ƒë∆∞·ª£c c√°ch ho·∫°t ƒë·ªông v√† khi n√†o n√™n d√πng **Linear Models** v·ªõi **Regularization** (Ridge, Lasso).
    -   Hi·ªÉu ƒë∆∞·ª£c nguy√™n l√Ω c·ªßa **Ensemble Methods**, ƒë·∫∑c bi·ªát l√† **Random Forest** (Bagging) v√† **Gradient Boosting** (Boosting).
-   **Model Evaluation**:
    -   S·ª≠ d·ª•ng c√°c metric ph√π h·ª£p cho b√†i to√°n h·ªìi quy (RMSE, R¬≤, MAE) v√† ph√¢n lo·∫°i (Accuracy, Precision, Recall, F1-score).
    -   Hi·ªÉu v√† √°p d·ª•ng **Cross-Validation**.

---

#### **2.1 Predictive Modeling - D·ª± ƒëo√°n gi√° nh√†**
> **M·ª•c ti√™u**: X√¢y d·ª±ng m·ªôt pipeline machine learning ho√†n ch·ªânh cho b√†i to√°n h·ªìi quy, t·ª´ feature engineering ph·ª©c t·∫°p, so s√°nh nhi·ªÅu m√¥ h√¨nh, ƒë·∫øn di·ªÖn gi·∫£i k·∫øt qu·∫£.

-   **Dataset**: [House Prices: Advanced Regression Techniques](https://www.kaggle.com/c/house-prices-advanced-regression-techniques)
-   **Problem Framing**:
    -   **B·ªëi c·∫£nh kinh doanh**: M·ªôt c√¥ng ty b·∫•t ƒë·ªông s·∫£n mu·ªën x√¢y d·ª±ng m·ªôt c√¥ng c·ª• ƒë·ªãnh gi√° nh√† t·ª± ƒë·ªông ƒë·ªÉ gi√∫p c√°c chuy√™n vi√™n t∆∞ v·∫•n v√† kh√°ch h√†ng c√≥ ƒë∆∞·ª£c ∆∞·ªõc t√≠nh nhanh ch√≥ng v√† ch√≠nh x√°c.
    -   **B√†i to√°n ML**: X√¢y d·ª±ng m·ªôt m√¥ h√¨nh **h·ªìi quy (regression)** ƒë·ªÉ d·ª± ƒëo√°n `SalePrice` d·ª±a tr√™n 79 thu·ªôc t√≠nh kh√°c c·ªßa ng√¥i nh√†.
-   **Key Challenges**:
    -   **D·ªØ li·ªáu ph·ª©c t·∫°p**: B·ªô d·ªØ li·ªáu ch·ª©a h·ªón h·ª£p nhi·ªÅu ki·ªÉu d·ªØ li·ªáu (s·ªë, ph√¢n lo·∫°i c√≥ th·ª© t·ª±, ph√¢n lo·∫°i kh√¥ng c√≥ th·ª© t·ª±).
    -   **S·ªë l∆∞·ª£ng Feature l·ªõn**: C·∫ßn √°p d·ª•ng c√°c k·ªπ thu·∫≠t Feature Selection ƒë·ªÉ ch·ªçn ra nh·ªØng feature quan tr·ªçng nh·∫•t.
    -   **Feature Engineering**: Nhi·ªÅu feature c·∫ßn ƒë∆∞·ª£c bi·∫øn ƒë·ªïi (v√≠ d·ª•: `YearBuilt` th√†nh `HouseAge`) ho·∫∑c k·∫øt h·ª£p ƒë·ªÉ t·∫°o ra t√≠n hi·ªáu t·ªët h∆°n cho m√¥ h√¨nh.
    -   **Model Interpretability**: C·∫ßn gi·∫£i th√≠ch ƒë∆∞·ª£c cho ng∆∞·ªùi d√πng t·∫°i sao m√¥ h√¨nh l·∫°i ƒë∆∞a ra m·ªôt m·ª©c gi√° c·ª• th·ªÉ (v√≠ d·ª•: "gi√° cao h∆°n v√¨ c√≥ di·ªán t√≠ch l·ªõn v√† ·ªü khu v·ª±c trung t√¢m").
-   **Success Metrics**:
    -   **K·ªπ thu·∫≠t**: **Root Mean Squared Logarithmic Error (RMSLE)** tr√™n t·∫≠p test (ƒë√¢y l√† metric ch√≠nh c·ªßa cu·ªôc thi tr√™n Kaggle). R¬≤ score c≈©ng l√† m·ªôt metric t·ªët ƒë·ªÉ ƒëo m·ª©c ƒë·ªô gi·∫£i th√≠ch c·ªßa m√¥ h√¨nh.
    -   **Kinh doanh**: T·ª∑ l·ªá ph·∫ßn trƒÉm c√°c d·ª± ƒëo√°n n·∫±m trong kho·∫£ng ¬±15% so v·ªõi gi√° b√°n th·ª±c t·∫ø.
-   **Theoretical Connections**:
    -   **Feature Engineering**: √Åp d·ª•ng t·∫•t c·∫£ c√°c k·ªπ thu·∫≠t ƒë√£ h·ªçc, t·ª´ x·ª≠ l√Ω gi√° tr·ªã thi·∫øu, m√£ h√≥a bi·∫øn ph√¢n lo·∫°i, ƒë·∫øn t·∫°o feature t∆∞∆°ng t√°c.
    -   **Regularization**: S·ª≠ d·ª•ng Ridge v√† Lasso ƒë·ªÉ xem ch√∫ng x·ª≠ l√Ω s·ªë l∆∞·ª£ng l·ªõn c√°c feature nh∆∞ th·∫ø n√†o. Lasso c√≥ th·ªÉ gi√∫p l·ª±a ch·ªçn feature.
    -   **Ensemble Methods**: So s√°nh s·ª©c m·∫°nh c·ªßa Random Forest v√† Gradient Boosting.
    -   **Model Interpretation**: D√πng `feature_importances_` t·ª´ c√°c m√¥ h√¨nh c√¢y ho·∫∑c SHAP ƒë·ªÉ gi·∫£i th√≠ch d·ª± ƒëo√°n.
-   **Deliverables**:
    -   M·ªôt pipeline x·ª≠ l√Ω d·ªØ li·ªáu v√† hu·∫•n luy·ªán m√¥ h√¨nh c√≥ th·ªÉ t√°i s·ª≠ d·ª•ng.
    -   Notebook so s√°nh hi·ªáu su·∫•t c·ªßa √≠t nh·∫•t 3-4 m√¥ h√¨nh kh√°c nhau.
    -   B√°o c√°o di·ªÖn gi·∫£i m√¥ h√¨nh, ch·ªâ ra c√°c feature quan tr·ªçng nh·∫•t ·∫£nh h∆∞·ªüng ƒë·∫øn gi√° nh√†.
    -   (N√¢ng cao) M·ªôt API ƒë∆°n gi·∫£n (d√πng FastAPI) ƒë·ªÉ nh·∫≠n th√¥ng tin m·ªôt ng√¥i nh√† v√† tr·∫£ v·ªÅ gi√° d·ª± ƒëo√°n.

---

#### **2.2 Recommendation System - G·ª£i √Ω phim**
> **M·ª•c ti√™u**: X√¢y d·ª±ng m·ªôt h·ªá th·ªëng g·ª£i √Ω phim ƒë∆°n gi·∫£n, t√¨m hi·ªÉu c√°c ph∆∞∆°ng ph√°p l·ªçc c·ªông t√°c v√† l·ªçc d·ª±a tr√™n n·ªôi dung.

-   **Dataset**: [MovieLens Latest Datasets (small)](https://grouplens.org/datasets/movielens/)
-   **Problem Framing**:
    -   **B·ªëi c·∫£nh kinh doanh**: M·ªôt n·ªÅn t·∫£ng streaming phim (nh∆∞ Netflix) mu·ªën tƒÉng m·ª©c ƒë·ªô g·∫Øn k·∫øt c·ªßa ng∆∞·ªùi d√πng (user engagement) b·∫±ng c√°ch g·ª£i √Ω nh·ªØng b·ªô phim m√† h·ªç c√≥ kh·∫£ nƒÉng s·∫Ω th√≠ch.
    -   **B√†i to√°n ML**: D·ª±a tr√™n l·ªãch s·ª≠ xem v√† ƒë√°nh gi√° phim c·ªßa ng∆∞·ªùi d√πng, d·ª± ƒëo√°n rating m√† m·ªôt ng∆∞·ªùi d√πng s·∫Ω cho m·ªôt b·ªô phim h·ªç ch∆∞a xem, v√† g·ª£i √Ω nh·ªØng phim c√≥ rating d·ª± ƒëo√°n cao nh·∫•t.
-   **Key Challenges**:
    -   **Data Sparsity (D·ªØ li·ªáu th∆∞a th·ªõt)**: Ma tr·∫≠n user-item (ng∆∞·ªùi d√πng - phim) r·∫•t th∆∞a th·ªõt v√¨ m·ªói ng∆∞·ªùi d√πng ch·ªâ xem/ƒë√°nh gi√° m·ªôt ph·∫ßn r·∫•t nh·ªè trong t·ªïng s·ªë phim.
    -   **Cold Start Problem**: L√†m th·∫ø n√†o ƒë·ªÉ g·ª£i √Ω cho m·ªôt **ng∆∞·ªùi d√πng m·ªõi** (ch∆∞a c√≥ l·ªãch s·ª≠) ho·∫∑c g·ª£i √Ω m·ªôt **b·ªô phim m·ªõi** (ch∆∞a c√≥ ai ƒë√°nh gi√°)?
    -   **Scalability**: L√†m th·∫ø n√†o ƒë·ªÉ h·ªá th·ªëng ho·∫°t ƒë·ªông hi·ªáu qu·∫£ v·ªõi h√†ng tri·ªáu ng∆∞·ªùi d√πng v√† h√†ng tri·ªáu b·ªô phim?
-   **Success Metrics**:
    -   **K·ªπ thu·∫≠t (Offline)**: Precision@k, Recall@k, NDCG@k. C√°c metric n√†y ƒëo l∆∞·ªùng m·ª©c ƒë·ªô li√™n quan c·ªßa top `k` phim ƒë∆∞·ª£c g·ª£i √Ω.
    -   **Kinh doanh (Online)**: T·ª∑ l·ªá click v√†o phim ƒë∆∞·ª£c g·ª£i √Ω (Click-Through Rate), th·ªùi gian xem phim tƒÉng l√™n, t·ª∑ l·ªá ng∆∞·ªùi d√πng quay l·∫°i.
-   **Theoretical Connections**:
    -   **ƒê·∫°i s·ªë tuy·∫øn t√≠nh**: N·ªÅn t·∫£ng c·ªßa **Collaborative Filtering** th√¥ng qua c√°c k·ªπ thu·∫≠t **Matrix Factorization** (ph√¢n r√£ ma tr·∫≠n) nh∆∞ SVD. √ù t∆∞·ªüng l√† ph√¢n r√£ ma tr·∫≠n user-item th√†nh hai ma tr·∫≠n nh·ªè h∆°n: user-latent features v√† item-latent features.
    -   **ƒêo l∆∞·ªùng ƒë·ªô t∆∞∆°ng ƒë·ªìng**: S·ª≠ d·ª•ng Cosine Similarity ho·∫∑c Dot Product ƒë·ªÉ t√¨m nh·ªØng ng∆∞·ªùi d√πng/phim t∆∞∆°ng t·ª± nhau.
-   **Deliverables**:
    -   Notebook ph√¢n t√≠ch ma tr·∫≠n user-item.
    -   Implementation c·ªßa thu·∫≠t to√°n Collaborative Filtering (v√≠ d·ª•: d√πng SVD ho·∫∑c c√°c th∆∞ vi·ªán nh∆∞ `surprise`).
    -   (N√¢ng cao) Implementation c·ªßa Content-Based Filtering (d·ª±a tr√™n th·ªÉ lo·∫°i, di·ªÖn vi√™n) ƒë·ªÉ gi·∫£i quy·∫øt Cold Start problem.
    -   (N√¢ng cao) M·ªôt ·ª©ng d·ª•ng web ƒë∆°n gi·∫£n cho ph√©p nh·∫≠p user ID v√† nh·∫≠n v·ªÅ danh s√°ch phim ƒë∆∞·ª£c g·ª£i √Ω.

### üå≥ **C·∫•p ƒë·ªô 3: Deep Learning (Advanced)**

#### N·ªÅn t·∫£ng l√Ω thuy·∫øt c·∫ßn n·∫Øm
-   **Neural Network Fundamentals**: Hi·ªÉu r√µ c√°ch ho·∫°t ƒë·ªông c·ªßa Backpropagation, c√°c h√†m activation, v√† c√°c thu·∫≠t to√°n t·ªëi ∆∞u h√≥a nh∆∞ Adam.
-   **Regularization**: N·∫Øm v·ªØng Dropout v√† Batch Normalization.
-   **CNN Architectures**: Hi·ªÉu c√°c th√†nh ph·∫ßn c·ªët l√µi: Convolution, Pooling, v√† √Ω t∆∞·ªüng ƒë·∫±ng sau c√°c ki·∫øn tr√∫c s√¢u nh∆∞ ResNet (Residual Connections).
-   **Transfer Learning**: Hi·ªÉu kh√°i ni·ªám "fine-tuning" v√† t·∫°i sao n√≥ hi·ªáu qu·∫£.
-   **NLP Concepts**: Hi·ªÉu v·ªÅ Word Embeddings v√† ki·∫øn tr√∫c Transformer ·ªü m·ª©c ƒë·ªô cao.

---

#### **3.1 Computer Vision - Ph√¢n lo·∫°i ·∫£nh**
> **M·ª•c ti√™u**: X√¢y d·ª±ng v√† hu·∫•n luy·ªán m·ªôt m·∫°ng n∆°-ron t√≠ch ch·∫≠p (CNN) hi·ªán ƒë·∫°i, √°p d·ª•ng c√°c k·ªπ thu·∫≠t ti√™n ti·∫øn nh∆∞ data augmentation v√† transfer learning.

-   **Dataset**: [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) (kh·ªüi ƒë·∫ßu t·ªët) ho·∫∑c [ImageNet](http://www.image-net.org/) (th·ª≠ th√°ch l·ªõn h∆°n).
-   **Problem Framing**:
    -   **B·ªëi c·∫£nh kinh doanh**: M·ªôt c√¥ng ty mu·ªën t·ª± ƒë·ªông ph√¢n lo·∫°i h√†ng ngh√¨n b·ª©c ·∫£nh s·∫£n ph·∫©m v√†o c√°c danh m·ª•c kh√°c nhau ƒë·ªÉ qu·∫£n l√Ω kho h√†ng.
    -   **B√†i to√°n ML**: X√¢y d·ª±ng m·ªôt m√¥ h√¨nh **ph√¢n lo·∫°i ƒëa l·ªõp (multi-class classification)** c√≥ kh·∫£ nƒÉng nh·∫≠n m·ªôt b·ª©c ·∫£nh v√† d·ª± ƒëo√°n n√≥ thu·ªôc v·ªÅ l·ªõp n√†o trong N l·ªõp cho tr∆∞·ªõc (v√≠ d·ª•: 10 l·ªõp trong CIFAR-10).
-   **Key Challenges**:
    -   **Computational Cost**: Hu·∫•n luy·ªán c√°c m√¥ h√¨nh CNN s√¢u ƒë√≤i h·ªèi t√†i nguy√™n GPU ƒë√°ng k·ªÉ.
    -   **Overfitting**: V·ªõi h√†ng tri·ªáu tham s·ªë, c√°c m√¥ h√¨nh deep learning r·∫•t d·ªÖ overfitting, ƒë√≤i h·ªèi c√°c k·ªπ thu·∫≠t regularization m·∫°nh m·∫Ω.
    -   **Data Augmentation**: C·∫ßn thi·∫øt k·∫ø m·ªôt pipeline tƒÉng c∆∞·ªùng d·ªØ li·ªáu (xoay, l·∫≠t, thay ƒë·ªïi m√†u s·∫Øc,...) hi·ªáu qu·∫£ ƒë·ªÉ gi√∫p m√¥ h√¨nh t·ªïng qu√°t h√≥a t·ªët h∆°n.
-   **Success Metrics**:
    -   **K·ªπ thu·∫≠t**: **Top-1 Accuracy** (d·ª± ƒëo√°n ƒë√∫ng ngay l·ªõp c√≥ x√°c su·∫•t cao nh·∫•t) v√† **Top-5 Accuracy** (l·ªõp ƒë√∫ng n·∫±m trong top 5 d·ª± ƒëo√°n) tr√™n t·∫≠p test. Theo d√µi learning curves (train/val loss) ƒë·ªÉ ph√°t hi·ªán overfitting.
    -   **Kinh doanh**: T·ªëc ƒë·ªô x·ª≠ l√Ω ·∫£nh (inferences per second) v√† ƒë·ªô ch√≠nh x√°c tr√™n d·ªØ li·ªáu th·ª±c t·∫ø c·ªßa c√¥ng ty.
-   **Theoretical Connections**:
    -   **CNNs**: √Åp d·ª•ng ki·∫øn th·ª©c v·ªÅ c√°c l·ªõp `Conv2d`, `MaxPool2d`, `BatchNorm2d`.
    -   **Architectures**: X√¢y d·ª±ng m·ªôt ki·∫øn tr√∫c t√πy ch·ªânh ho·∫∑c s·ª≠ d·ª•ng l·∫°i c√°c ki·∫øn tr√∫c n·ªïi ti·∫øng nh∆∞ **ResNet**.
    -   **Optimization & Regularization**: S·ª≠ d·ª•ng `AdamW`, `learning rate scheduling`, v√† `Dropout` ƒë·ªÉ hu·∫•n luy·ªán m√¥ h√¨nh hi·ªáu qu·∫£.
-   **Deliverables**:
    -   Code hu·∫•n luy·ªán m√¥ h√¨nh, bao g·ªìm c·∫£ data augmentation pipeline.
    -   So s√°nh hi·ªáu su·∫•t gi·ªØa vi·ªác hu·∫•n luy·ªán t·ª´ ƒë·∫ßu (from scratch) v√† s·ª≠ d·ª•ng **Transfer Learning** (fine-tuning m·ªôt m√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c pre-trained tr√™n ImageNet).
    -   M·ªôt API ƒë∆°n gi·∫£n ƒë·ªÉ nh·∫≠n m·ªôt ·∫£nh v√† tr·∫£ v·ªÅ l·ªõp d·ª± ƒëo√°n c√πng x√°c su·∫•t.

---

#### **3.2 Natural Language Processing - Ph√¢n t√≠ch c·∫£m x√∫c**
> **M·ª•c ti√™u**: Fine-tune m·ªôt m√¥ h√¨nh Transformer (nh∆∞ BERT) cho b√†i to√°n ph√¢n t√≠ch c·∫£m x√∫c, m·ªôt t√°c v·ª• NLP kinh ƒëi·ªÉn.

-   **Dataset**: [IMDB Movie Reviews](https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews)
-   **Problem Framing**:
    -   **B·ªëi c·∫£nh kinh doanh**: M·ªôt chu·ªói r·∫°p chi·∫øu phim mu·ªën t·ª± ƒë·ªông ph√¢n t√≠ch h√†ng ngh√¨n b√¨nh lu·∫≠n c·ªßa kh√°n gi·∫£ tr√™n m·∫°ng x√£ h·ªôi ƒë·ªÉ ƒë√°nh gi√° ph·∫£n ·ª©ng c·ªßa c√¥ng ch√∫ng ƒë·ªëi v·ªõi m·ªôt b·ªô phim m·ªõi.
    -   **B√†i to√°n ML**: X√¢y d·ª±ng m·ªôt m√¥ h√¨nh **ph√¢n lo·∫°i vƒÉn b·∫£n (text classification)** ƒë·ªÉ x√°c ƒë·ªãnh m·ªôt b√¨nh lu·∫≠n l√† "t√≠ch c·ª±c" (positive) hay "ti√™u c·ª±c" (negative).
-   **Key Challenges**:
    -   **Hi·ªÉu ng·ªØ c·∫£nh**: M√¥ h√¨nh c·∫ßn hi·ªÉu ƒë∆∞·ª£c c√°c m·ªëi quan h·ªá ph·ª©c t·∫°p v√† xa trong c√¢u ch·ªØ.
    -   **S·ª± tinh t·∫ø c·ªßa ng√¥n ng·ªØ**: X·ª≠ l√Ω c√°c hi·ªán t∆∞·ª£ng nh∆∞ m·ªâa mai, ch√¢m bi·∫øm, ph·ªß ƒë·ªãnh.
    -   **T√†i nguy√™n**: Fine-tuning c√°c m√¥ h√¨nh Transformer l·ªõn v·∫´n ƒë√≤i h·ªèi GPU.
-   **Success Metrics**:
    -   **K·ªπ thu·∫≠t**: **F1-score** l√† m·ªôt metric t·ªët cho b√†i to√°n n√†y, v√¨ n√≥ c√¢n b·∫±ng gi·ªØa Precision v√† Recall. Accuracy c≈©ng quan tr·ªçng.
    -   **Kinh doanh**: M·ª©c ƒë·ªô t∆∞∆°ng ƒë·ªìng gi·ªØa k·∫øt qu·∫£ ph√¢n lo·∫°i c·ªßa m√¥ h√¨nh v√† ƒë√°nh gi√° c·ªßa con ng∆∞·ªùi.
-   **Theoretical Connections**:
    -   **Embeddings**: Hi·ªÉu c√°ch vƒÉn b·∫£n ƒë∆∞·ª£c chuy·ªÉn th√†nh vector.
    -   **Transformer & Attention**: T·∫≠n d·ª•ng s·ª©c m·∫°nh c·ªßa ki·∫øn tr√∫c Transformer (m√† BERT d·ª±a tr√™n) ƒë·ªÉ hi·ªÉu ng·ªØ c·∫£nh.
    -   **Fine-tuning**: √Åp d·ª•ng ki·∫øn th·ª©c v·ªÅ vi·ªác ƒëi·ªÅu ch·ªânh m·ªôt m√¥ h√¨nh pre-trained cho m·ªôt t√°c v·ª• c·ª• th·ªÉ.
-   **Deliverables**:
    -   M·ªôt pipeline ho√†n ch·ªânh t·ª´ ti·ªÅn x·ª≠ l√Ω vƒÉn b·∫£n (tokenization) ƒë·∫øn fine-tuning m√¥ h√¨nh.
    -   ƒê√°nh gi√° m√¥ h√¨nh tr√™n t·∫≠p test v√† ph√¢n t√≠ch c√°c tr∆∞·ªùng h·ª£p d·ª± ƒëo√°n sai.
    -   M·ªôt c√¥ng c·ª• demo th·ªùi gian th·ª±c (v√≠ d·ª•: web app) cho ph√©p ng∆∞·ªùi d√πng nh·∫≠p m·ªôt c√¢u v√† nh·∫≠n v·ªÅ ph√¢n t√≠ch c·∫£m x√∫c.

### üöÄ **C·∫•p ƒë·ªô 4: Production & MLOps (Expert)**

#### N·ªÅn t·∫£ng l√Ω thuy·∫øt c·∫ßn n·∫Øm
-   **MLOps Principles**: Hi·ªÉu r√µ v√≤ng ƒë·ªùi c·ªßa m·ªôt h·ªá th·ªëng ML, bao g·ªìm development, deployment, v√† monitoring.
-   **CI/CD/CT**: Hi·ªÉu kh√°i ni·ªám T√≠ch h·ª£p li√™n t·ª•c, Giao h√†ng li√™n t·ª•c, v√† ƒë·∫∑c bi·ªát l√† **Hu·∫•n luy·ªán li√™n t·ª•c**.
-   **Containerization & Orchestration**: N·∫Øm v·ªØng Docker ƒë·ªÉ ƒë√≥ng g√≥i ·ª©ng d·ª•ng v√† Kubernetes (·ªü m·ª©c ƒë·ªô kh√°i ni·ªám) ƒë·ªÉ ƒëi·ªÅu ph·ªëi.
-   **Model Monitoring**: Hi·ªÉu c√°c kh√°i ni·ªám v·ªÅ **Data Drift** (ph√¢n ph·ªëi c·ªßa d·ªØ li·ªáu ƒë·∫ßu v√†o thay ƒë·ªïi) v√† **Concept Drift** (m·ªëi quan h·ªá gi·ªØa input v√† output thay ƒë·ªïi).
-   **Infrastructure as Code (IaC)**: C√≥ kh√°i ni·ªám v·ªÅ vi·ªác qu·∫£n l√Ω h·∫° t·∫ßng b·∫±ng code (v√≠ d·ª•: Terraform, Ansible).

---

#### **4.1 End-to-End ML Pipeline - X√¢y d·ª±ng Pipeline ML ho√†n ch·ªânh**
> **M·ª•c ti√™u**: Thi·∫øt k·∫ø v√† tri·ªÉn khai m·ªôt h·ªá th·ªëng t·ª± ƒë·ªông h√≥a to√†n b·ªô v√≤ng ƒë·ªùi ML, t·ª´ thu th·∫≠p d·ªØ li·ªáu, hu·∫•n luy·ªán, ƒë√°nh gi√°, ƒë·∫øn tri·ªÉn khai v√† gi√°m s√°t.

-   **Problem Framing**:
    -   **B·ªëi c·∫£nh kinh doanh**: M·ªôt c√¥ng ty mu·ªën t·ª± ƒë·ªông c·∫≠p nh·∫≠t m√¥ h√¨nh d·ª± ƒëo√°n churn c·ªßa h·ªç m·ªói tu·∫ßn v·ªõi d·ªØ li·ªáu m·ªõi m√† kh√¥ng c·∫ßn s·ª± can thi·ªáp th·ªß c√¥ng c·ªßa data scientist, ƒë·ªìng th·ªùi ƒë·∫£m b·∫£o ch·∫•t l∆∞·ª£ng c·ªßa m√¥ h√¨nh m·ªõi tr∆∞·ªõc khi tri·ªÉn khai.
    -   **B√†i to√°n MLOps**: X√¢y d·ª±ng m·ªôt pipeline t·ª± ƒë·ªông, ƒë√°ng tin c·∫≠y, c√≥ kh·∫£ nƒÉng: 1) K√≠ch ho·∫°t khi c√≥ d·ªØ li·ªáu m·ªõi, 2) Hu·∫•n luy·ªán l·∫°i m√¥ h√¨nh, 3) ƒê√°nh gi√° v√† so s√°nh v·ªõi m√¥ h√¨nh production hi·ªán t·∫°i, 4) T·ª± ƒë·ªông "thƒÉng h·∫°ng" m√¥ h√¨nh m·ªõi n·∫øu t·ªët h∆°n, v√† 5) Tri·ªÉn khai m√¥ h√¨nh m·ªõi m√† kh√¥ng g√¢y gi√°n ƒëo·∫°n d·ªãch v·ª•.
-   **Key Challenges**:
    -   **T√≠ch h·ª£p c√¥ng c·ª•**: K·∫øt n·ªëi nhi·ªÅu c√¥ng c·ª• kh√°c nhau m·ªôt c√°ch li·ªÅn m·∫°ch (v√≠ d·ª•: Airflow cho l·∫≠p l·ªãch, MLflow cho experiment tracking, Docker cho ƒë√≥ng g√≥i, Kubernetes cho ƒëi·ªÅu ph·ªëi, Prometheus/Grafana cho gi√°m s√°t).
    -   **T·ª± ƒë·ªông h√≥a ki·ªÉm th·ª≠**: Vi·∫øt c√°c b√†i test kh√¥ng ch·ªâ cho code, m√† c√≤n cho d·ªØ li·ªáu (data validation) v√† cho m√¥ h√¨nh (model evaluation).
    -   **Qu·∫£n l√Ω h·∫° t·∫ßng**: Qu·∫£n l√Ω t√†i nguy√™n t√≠nh to√°n (CPU/GPU) cho c√°c b∆∞·ªõc kh√°c nhau c·ªßa pipeline.
-   **Success Metrics**:
    -   **T·∫ßn su·∫•t tri·ªÉn khai (Deployment Frequency)**: C√≥ th·ªÉ tri·ªÉn khai m√¥ h√¨nh m·ªõi m·ªôt c√°ch an to√†n nhanh nh∆∞ th·∫ø n√†o?
    -   **Th·ªùi gian thay ƒë·ªïi (Lead Time for Changes)**: M·∫•t bao l√¢u t·ª´ l√∫c code m·ªôt thay ƒë·ªïi ƒë·∫øn l√∫c n√≥ ƒë∆∞·ª£c ch·∫°y tr√™n production?
    -   **T·ª∑ l·ªá l·ªói thay ƒë·ªïi (Change Failure Rate)**: Bao nhi√™u ph·∫ßn trƒÉm c√°c l·∫ßn tri·ªÉn khai g√¢y ra l·ªói?
    -   **Th·ªùi gian kh√¥i ph·ª•c d·ªãch v·ª• (Time to Restore Service)**: M·∫•t bao l√¢u ƒë·ªÉ rollback v·ªÅ phi√™n b·∫£n ·ªïn ƒë·ªãnh tr∆∞·ªõc ƒë√≥ n·∫øu c√≥ l·ªói?
-   **Theoretical Connections**:
    -   **Experiment Tracking & Model Registry**: L√† tr√°i tim c·ªßa pipeline, l∆∞u tr·ªØ m·ªçi th√¥ng tin v√† hi·ªán v·∫≠t.
    -   **CI/CD/CT**: √Åp d·ª•ng to√†n b·ªô chu tr√¨nh n√†y.
    -   **Model Serving & Monitoring**: Giai ƒëo·∫°n cu·ªëi c·ªßa pipeline, v√† c≈©ng l√† ngu·ªìn trigger cho m·ªôt chu tr√¨nh m·ªõi.
-   **Deliverables**:
    -   M√£ ngu·ªìn cho to√†n b·ªô pipeline, ƒë∆∞·ª£c qu·∫£n l√Ω b·∫±ng Git.
    -   M·ªôt file c·∫•u h√¨nh pipeline (v√≠ d·ª•: `dag.py` cho Airflow, `.github/workflows/main.yml` cho GitHub Actions).
    -   T√†i li·ªáu ki·∫øn tr√∫c h·ªá th·ªëng.
    -   M·ªôt dashboard gi√°m s√°t (monitoring) hi·ªÉn th·ªã hi·ªáu su·∫•t c·ªßa m√¥ h√¨nh v√† s·ª©c kh·ªèe c·ªßa h·ªá th·ªëng.

## üìä **Rubric ch·∫•m ƒëi·ªÉm**

### **C·∫•p ƒë·ªô 1: Data Analysis (100 ƒëi·ªÉm)**

| Ti√™u ch√≠ | ƒêi·ªÉm | M√¥ t·∫£ |
|----------|------|-------|
| **Data Understanding** | 20 | Hi·ªÉu r√µ d·ªØ li·ªáu, business context |
| **Data Cleaning** | 20 | X·ª≠ l√Ω missing values, outliers, data quality |
| **Exploratory Analysis** | 25 | Visualization, statistical analysis, insights |
| **Business Insights** | 20 | R√∫t ra insights c√≥ √Ω nghƒ©a business |
| **Documentation** | 15 | Code comments, README, presentation |

### **C·∫•p ƒë·ªô 2: Machine Learning (100 ƒëi·ªÉm)**

| Ti√™u ch√≠ | ƒêi·ªÉm | M√¥ t·∫£ |
|----------|------|-------|
| **Feature Engineering** | 20 | T·∫°o features c√≥ √Ω nghƒ©a, data preprocessing |
| **Model Selection** | 20 | So s√°nh multiple models, hyperparameter tuning |
| **Model Performance** | 25 | Metrics, cross-validation, error analysis |
| **Model Interpretation** | 20 | SHAP, feature importance, business logic |
| **Code Quality** | 15 | Clean code, modular design, testing |

### **C·∫•p ƒë·ªô 3: Deep Learning (100 ƒëi·ªÉm)**

| Ti√™u ch√≠ | ƒêi·ªÉm | M√¥ t·∫£ |
|----------|------|-------|
| **Architecture Design** | 20 | Network design, layer choices, activation functions |
| **Training Process** | 20 | Loss function, optimizer, learning rate scheduling |
| **Data Augmentation** | 15 | Preprocessing, augmentation techniques |
| **Model Performance** | 25 | Accuracy, loss curves, overfitting prevention |
| **Technical Implementation** | 20 | PyTorch/TensorFlow, GPU utilization, memory management |

### **C·∫•p ƒë·ªô 4: Production & MLOps (100 ƒëi·ªÉm)**

| Ti√™u ch√≠ | ƒêi·ªÉm | M√¥ t·∫£ |
|----------|------|-------|
| **System Architecture** | 25 | Scalable design, microservices, API design |
| **Automation** | 20 | CI/CD, automated training, deployment |
| **Monitoring** | 20 | Model performance, data drift, alerting |
| **Security & Reliability** | 20 | Authentication, error handling, testing |
| **Documentation** | 15 | API docs, deployment guide, troubleshooting |

## üéØ **H∆∞·ªõng d·∫´n th·ª±c hi·ªán**

### **1. Planning Phase (1-2 tu·∫ßn)**
- Ch·ªçn d·ª± √°n ph√π h·ª£p v·ªõi skill level
- Ph√¢n t√≠ch requirements v√† deliverables
- Thi·∫øt k·∫ø architecture v√† timeline
- Setup development environment

### **2. Development Phase (2-4 tu·∫ßn)**
- Implement core functionality
- Test v√† debug
- Optimize performance
- Document code

### **3. Evaluation Phase (1 tu·∫ßn)**
- Self-assessment theo rubric
- Peer review
- Mentor feedback
- Iterate v√† improve

### **4. Presentation Phase (1 tu·∫ßn)**
- Prepare demo
- Create presentation slides
- Practice presentation
- Present to stakeholders

## üìö **T√†i li·ªáu tham kh·∫£o**

### **Project Templates**
- [Cookiecutter Data Science](https://drivendata.github.io/cookiecutter-data-science/)
- [MLOps Template](https://github.com/zenml-io/zenml)
- [FastAPI Template](https://github.com/tiangolo/full-stack-fastapi-postgresql)

### **Best Practices**
- [Google ML Guide](https://developers.google.com/machine-learning/guides)
- [Microsoft ML Best Practices](https://docs.microsoft.com/en-us/azure/machine-learning/concept-model-management-and-deployment)
- [AWS ML Best Practices](https://aws.amazon.com/machine-learning/ml-best-practices/)

### **Tools & Platforms**
- **Version Control**: Git, GitHub
- **Code Quality**: Black, Flake8, Pylint
- **Testing**: Pytest, Hypothesis
- **CI/CD**: GitHub Actions, GitLab CI
- **Deployment**: Docker, Kubernetes, Cloud platforms

## üéØ **B√†i t·∫≠p th·ª±c h√†nh**

### **Exercise 1: Portfolio Planning**
1. Ch·ªçn 3 d·ª± √°n ph√π h·ª£p v·ªõi skill level hi·ªán t·∫°i
2. T·∫°o timeline cho m·ªói d·ª± √°n
3. X√°c ƒë·ªãnh learning objectives
4. Plan deliverables v√† milestones

### **Exercise 2: Project Setup**
1. Setup development environment
2. Create project structure
3. Initialize Git repository
4. Setup CI/CD pipeline

### **Exercise 3: MVP Development**
1. Implement core functionality
2. Create basic tests
3. Setup monitoring
4. Deploy to staging environment

## üöÄ **B∆∞·ªõc ti·∫øp theo**

### **Immediate Actions**
1. **Ch·ªçn d·ª± √°n ƒë·∫ßu ti√™n** d·ª±a tr√™n skill level
2. **Setup development environment** v·ªõi tools c·∫ßn thi·∫øt
3. **Create project plan** v·ªõi timeline c·ª• th·ªÉ
4. **Start coding** v·ªõi MVP approach

### **Short-term Goals (1-2 th√°ng)**
- Ho√†n th√†nh 1-2 d·ª± √°n c∆° b·∫£n
- Build portfolio website
- Practice presentation skills
- Get feedback t·ª´ mentors

### **Long-term Goals (3-6 th√°ng)**
- Complete 3-5 projects across different domains
- Deploy projects to production
- Contribute to open source
- Build professional network

---

## üí° **L·ªùi khuy√™n t·ª´ chuy√™n gia**

> **"Start small, think big"** - B·∫Øt ƒë·∫ßu v·ªõi d·ª± √°n ƒë∆°n gi·∫£n nh∆∞ng c√≥ vision l·ªõn

> **"Code is read much more than it is written"** - Vi·∫øt code d·ªÖ ƒë·ªçc, d·ªÖ maintain

> **"Fail fast, learn faster"** - Th·ª≠ nghi·ªám, th·∫•t b·∫°i v√† h·ªçc h·ªèi nhanh ch√≥ng

> **"Documentation is a love letter to your future self"** - Vi·∫øt docs t·ªët cho ch√≠nh m√¨nh

---

*Ch√∫c b·∫°n th√†nh c√¥ng v·ªõi c√°c d·ª± √°n th·ª±c h√†nh! üéâ*

## üß© Ch∆∞∆°ng tr√¨nh 50/50 (L√Ω thuy·∫øt : Th·ª±c h√†nh)

- M·ª•c ti√™u: 50% l√Ω thuy·∫øt (m·ª•c ti√™u d·ª± √°n, ti√™u ch√≠ th√†nh c√¥ng, thi·∫øt k·∫ø th√≠ nghi·ªám, ƒë√°nh gi√°), 50% th·ª±c h√†nh (x√¢y d·ª±ng d·ª± √°n end-to-end)

| Giai ƒëo·∫°n | L√Ω thuy·∫øt (50%) | Th·ª±c h√†nh (50%) |
|---|---|---|
| Planning | Problem framing, KPI, scope | Project brief + timeline |
| Development | Thi·∫øt k·∫ø ki·∫øn tr√∫c, chu·∫©n d·ªØ li·ªáu | Data pipeline + model + UI |
| Evaluation | Metric/benchmark, A/B design | B√°o c√°o k·∫øt qu·∫£ + slide |
| Presentation | Storytelling, demo plan | Live demo + README ho√†n ch·ªânh |

Rubric (100ƒë/d·ª± √°n): L√Ω thuy·∫øt 30 | Code 30 | K·∫øt qu·∫£ 30 | Tr√¨nh b√†y 10

---

