# ðŸ”§ Setup Guide - AI Chatbot vá»›i RAG

> **Má»¥c tiÃªu**: HÆ°á»›ng dáº«n cÃ i Ä‘áº·t vÃ  cáº¥u hÃ¬nh mÃ´i trÆ°á»ng phÃ¡t triá»ƒn cho dá»± Ã¡n RAG Chatbot

## ðŸ“š **1. Báº£ng kÃ½ hiá»‡u (Notation)**

### **System Requirements:**
- **OS**: Ubuntu 20.04+ / macOS 10.15+ / Windows 10+
- **RAM**: 8GB (16GB recommended)
- **Storage**: 10GB free space
- **Python**: 3.9+
- **Node.js**: 16+ (for frontend)

### **Environment Variables:**
- **API Keys**: `OPENAI_API_KEY`, `ANTHROPIC_API_KEY`
- **Database**: `VECTOR_DB_PATH`, `CHUNK_SIZE`, `CHUNK_OVERLAP`
- **Server**: `HOST`, `PORT`, `DEBUG`

### **File Paths:**
- **Project root**: `./rag_chatbot/`
- **Backend**: `./rag_chatbot/backend/`
- **Frontend**: `./rag_chatbot/frontend/`
- **Data**: `./rag_chatbot/data/`

## ðŸ“– **2. Glossary (Äá»‹nh nghÄ©a cá»‘t lÃµi)**

### **Development Environment:**
- **Virtual Environment**: Isolated Python environment
- **Dependencies**: External libraries required by project
- **Package Manager**: Tool to install dependencies (pip, npm)
- **Version Control**: System to track code changes (Git)

### **System Components:**
- **Backend**: Server-side application (FastAPI)
- **Frontend**: Client-side application (React)
- **Database**: Storage system (FAISS, ChromaDB)
- **API**: Interface for communication between components

### **Deployment Terms:**
- **Docker**: Containerization platform
- **Kubernetes**: Container orchestration
- **CI/CD**: Continuous Integration/Deployment
- **Production**: Live environment for users

## ðŸ“‹ **YÃªu cáº§u há»‡ thá»‘ng**

### **Minimum Requirements:**
- **OS**: Ubuntu 20.04+ / macOS 10.15+ / Windows 10+
- **RAM**: 8GB (16GB recommended)
- **Storage**: 10GB free space
- **Python**: 3.9+
- **Node.js**: 16+ (for frontend)

### **Recommended Setup:**
- **RAM**: 16GB+
- **GPU**: NVIDIA GPU vá»›i CUDA support (optional)
- **Storage**: SSD vá»›i 20GB+ free space

## ðŸ **3. Tháº» thuáº­t toÃ¡n - Python Environment Setup**

### **1. BÃ i toÃ¡n & dá»¯ liá»‡u:**
- **BÃ i toÃ¡n**: Táº¡o mÃ´i trÆ°á»ng Python isolated cho development
- **Dá»¯ liá»‡u**: Python interpreter, project dependencies
- **á»¨ng dá»¥ng**: Development, testing, production deployment

### **2. MÃ´ hÃ¬nh & cÃ´ng thá»©c:**
**Virtual Environment Creation:**
```bash
python -m venv rag_env
```

**Environment Activation:**
```bash
# Linux/macOS:
source rag_env/bin/activate
# Windows:
rag_env\Scripts\activate
```

### **3. Loss & má»¥c tiÃªu:**
- **Má»¥c tiÃªu**: Táº¡o isolated environment Ä‘á»ƒ trÃ¡nh conflicts
- **Loss**: KhÃ´ng cÃ³ loss, lÃ  setup step

### **4. Tá»‘i Æ°u hoÃ¡ & cáº­p nháº­t:**
- **Algorithm**: Create virtual environment
- **Cáº­p nháº­t**: Activate environment khi cáº§n

### **5. Hyperparams:**
- **Python version**: 3.9+
- **Environment name**: rag_env
- **Path**: ./rag_env/

### **6. Äá»™ phá»©c táº¡p:**
- **Time**: $O(1)$ cho creation
- **Space**: $O(\text{dependencies})$ cho storage

### **7. Metrics Ä‘Ã¡nh giÃ¡:**
- **Environment isolation**: KhÃ´ng conflict vá»›i system Python
- **Dependency management**: Clean install/uninstall
- **Reproducibility**: Same environment across machines

### **8. Æ¯u / NhÆ°á»£c:**
**Æ¯u Ä‘iá»ƒm:**
- Isolated dependencies
- Easy to reproduce
- Clean uninstall

**NhÆ°á»£c Ä‘iá»ƒm:**
- Additional setup step
- Memory overhead
- Need to remember activation

### **9. Báº«y & máº¹o:**
- **Báº«y**: QuÃªn activate environment â†’ install globally
- **Báº«y**: KhÃ´ng add to .gitignore â†’ commit large files
- **Máº¹o**: Use virtualenvwrapper for easier management
- **Máº¹o**: Add environment to .gitignore

### **10. Pseudocode:**
```bash
# Create virtual environment
python -m venv rag_env

# Activate environment
source rag_env/bin/activate  # Linux/macOS
# rag_env\Scripts\activate   # Windows

# Upgrade pip
pip install --upgrade pip

# Install dependencies
pip install -r requirements.txt
```

### **11. Code máº«u:**
```bash
# Táº¡o virtual environment
python -m venv rag_env

# Activate environment
# Linux/macOS:
source rag_env/bin/activate
# Windows:
rag_env\Scripts\activate

# Upgrade pip
pip install --upgrade pip
```

### **12. Checklist kiá»ƒm tra nhanh:**
- [ ] Virtual environment cÃ³ Ä‘Æ°á»£c táº¡o?
- [ ] Environment cÃ³ Ä‘Æ°á»£c activate?
- [ ] Python version cÃ³ Ä‘Ãºng?
- [ ] Pip cÃ³ Ä‘Æ°á»£c upgrade?
- [ ] Environment cÃ³ isolated?

---

## ðŸ—„ï¸ **4. Tháº» thuáº­t toÃ¡n - Vector Database Setup**

### **1. BÃ i toÃ¡n & dá»¯ liá»‡u:**
- **BÃ i toÃ¡n**: CÃ i Ä‘áº·t vÃ  cáº¥u hÃ¬nh vector database cho RAG
- **Dá»¯ liá»‡u**: FAISS, ChromaDB, embedding vectors
- **á»¨ng dá»¥ng**: Vector similarity search, RAG systems

### **2. MÃ´ hÃ¬nh & cÃ´ng thá»©c:**
**FAISS Installation:**
```bash
pip install faiss-cpu  # CPU version
pip install faiss-gpu  # GPU version (if available)
```

**ChromaDB Setup:**
```python
import chromadb
client = chromadb.Client(Settings(persist_directory="./chroma_db"))
```

### **3. Loss & má»¥c tiÃªu:**
- **Má»¥c tiÃªu**: Setup vector database cho fast similarity search
- **Loss**: KhÃ´ng cÃ³ loss, lÃ  infrastructure setup

### **4. Tá»‘i Æ°u hoÃ¡ & cáº­p nháº­t:**
- **Algorithm**: Install and configure database
- **Cáº­p nháº­t**: KhÃ´ng cÃ³ parameter learning

### **5. Hyperparams:**
- **Index type**: FlatIP, HNSW, IVF
- **Dimension**: 384, 768, 1536
- **Persist directory**: ./vector_db/

### **6. Äá»™ phá»©c táº¡p:**
- **Time**: $O(n \times d)$ cho exact search
- **Space**: $O(n \times d)$ cho storing vectors

### **7. Metrics Ä‘Ã¡nh giÃ¡:**
- **Installation success**: Package installed correctly
- **Performance**: Search speed and accuracy
- **Memory usage**: Storage efficiency

### **8. Æ¯u / NhÆ°á»£c:**
**Æ¯u Ä‘iá»ƒm:**
- Fast similarity search
- Scalable vá»›i large datasets
- Multiple index types

**NhÆ°á»£c Ä‘iá»ƒm:**
- Complex setup vá»›i GPU
- Memory intensive
- Learning curve

### **9. Báº«y & máº¹o:**
- **Báº«y**: GPU version khÃ´ng compatible â†’ use CPU
- **Báº«y**: Memory issues vá»›i large datasets
- **Máº¹o**: Start vá»›i CPU version
- **Máº¹o**: Use appropriate index type

### **10. Pseudocode:**
```python
# FAISS Setup
import faiss
import numpy as np

def test_faiss_installation():
    # Create sample data
    dimension = 384
    num_vectors = 1000
    vectors = np.random.randn(num_vectors, dimension).astype('float32')
    
    # Normalize vectors
    faiss.normalize_L2(vectors)
    
    # Create index
    index = faiss.IndexFlatIP(dimension)
    index.add(vectors)
    
    # Test search
    query = np.random.randn(1, dimension).astype('float32')
    faiss.normalize_L2(query)
    scores, indices = index.search(query, 5)
    
    return len(indices[0]) > 0
```

### **11. Code máº«u:**
```python
# test_faiss.py
import faiss
import numpy as np

def test_faiss_installation():
    """Test FAISS installation"""
    # Create sample data
    dimension = 384
    num_vectors = 1000
    
    # Generate random vectors
    vectors = np.random.randn(num_vectors, dimension).astype('float32')
    
    # Normalize vectors
    faiss.normalize_L2(vectors)
    
    # Create index
    index = faiss.IndexFlatIP(dimension)
    index.add(vectors)
    
    # Test search
    query = np.random.randn(1, dimension).astype('float32')
    faiss.normalize_L2(query)
    
    scores, indices = index.search(query, 5)
    
    print("FAISS test successful!")
    print(f"Found {len(indices[0])} similar vectors")
    
    return True

if __name__ == "__main__":
    test_faiss_installation()
```

### **12. Checklist kiá»ƒm tra nhanh:**
- [ ] FAISS cÃ³ Ä‘Æ°á»£c install?
- [ ] Test script cÃ³ cháº¡y thÃ nh cÃ´ng?
- [ ] Memory usage cÃ³ acceptable?
- [ ] Search cÃ³ fast enough?
- [ ] Index cÃ³ Ä‘Æ°á»£c táº¡o?

---

## ðŸŒ **5. Tháº» thuáº­t toÃ¡n - Frontend Setup**

### **1. BÃ i toÃ¡n & dá»¯ liá»‡u:**
- **BÃ i toÃ¡n**: Setup React frontend cho RAG chatbot
- **Dá»¯ liá»‡u**: Node.js, React, dependencies
- **á»¨ng dá»¥ng**: Web interface, real-time chat

### **2. MÃ´ hÃ¬nh & cÃ´ng thá»©c:**
**React App Creation:**
```bash
npx create-react-app rag-frontend
```

**Dependencies Installation:**
```bash
npm install axios react-router-dom @mui/material
```

### **3. Loss & má»¥c tiÃªu:**
- **Má»¥c tiÃªu**: Táº¡o responsive web interface
- **Loss**: KhÃ´ng cÃ³ loss, lÃ  UI development

### **4. Tá»‘i Æ°u hoÃ¡ & cáº­p nháº­t:**
- **Algorithm**: Create React app and install dependencies
- **Cáº­p nháº­t**: Hot reload during development

### **5. Hyperparams:**
- **Node.js version**: 16+
- **React version**: Latest stable
- **Port**: 3000 (default)

### **6. Äá»™ phá»©c táº¡p:**
- **Time**: $O(\text{dependencies})$ cho installation
- **Space**: $O(\text{node_modules})$ cho storage

### **7. Metrics Ä‘Ã¡nh giÃ¡:**
- **Build success**: App compiles without errors
- **Performance**: Load time and responsiveness
- **User experience**: Intuitive interface

### **8. Æ¯u / NhÆ°á»£c:**
**Æ¯u Ä‘iá»ƒm:**
- Fast development vá»›i hot reload
- Rich ecosystem
- Good performance

**NhÆ°á»£c Ä‘iá»ƒm:**
- Large bundle size
- Complex setup
- Learning curve

### **9. Báº«y & máº¹o:**
- **Báº«y**: Node.js version incompatible
- **Báº«y**: Dependencies conflicts
- **Máº¹o**: Use nvm for Node.js version management
- **Máº¹o**: Check compatibility matrix

### **10. Pseudocode:**
```bash
# Install Node.js
curl -fsSL https://deb.nodesource.com/setup_18.x | sudo -E bash -
sudo apt-get install -y nodejs

# Create React app
npx create-react-app rag-frontend
cd rag-frontend

# Install dependencies
npm install axios react-router-dom @mui/material

# Start development server
npm start
```

### **11. Code máº«u:**
```bash
# Install Node.js (náº¿u chÆ°a cÃ³)
# Ubuntu/Debian:
curl -fsSL https://deb.nodesource.com/setup_18.x | sudo -E bash -
sudo apt-get install -y nodejs

# macOS:
brew install node

# Windows: Download tá»« https://nodejs.org/

# Verify installation
node --version
npm --version

# Táº¡o React app
npx create-react-app rag-frontend
cd rag-frontend

# Install dependencies
npm install axios react-router-dom
npm install @mui/material @emotion/react @emotion/styled
npm install @mui/icons-material

# Development dependencies
npm install --save-dev @types/react @types/react-dom
```

### **12. Checklist kiá»ƒm tra nhanh:**
- [ ] Node.js cÃ³ Ä‘Æ°á»£c install?
- [ ] React app cÃ³ Ä‘Æ°á»£c táº¡o?
- [ ] Dependencies cÃ³ Ä‘Æ°á»£c install?
- [ ] Development server cÃ³ cháº¡y?
- [ ] Browser cÃ³ hiá»ƒn thá»‹ app?

---

## ðŸ”§ **Development Tools Setup**

### **1. Code Quality Tools**

```bash
# Install pre-commit hooks
pip install pre-commit
pre-commit install

# Create .pre-commit-config.yaml
cat > .pre-commit-config.yaml << EOF
repos:
  - repo: https://github.com/psf/black
    rev: 23.3.0
    hooks:
      - id: black
        language_version: python3.9
  - repo: https://github.com/pycqa/isort
    rev: 5.12.0
    hooks:
      - id: isort
  - repo: https://github.com/pycqa/flake8
    rev: 6.0.0
    hooks:
      - id: flake8
EOF
```

### **2. Testing Setup**

```bash
# Install testing dependencies
pip install pytest pytest-asyncio pytest-cov
pip install httpx  # for FastAPI testing

# Create pytest.ini
cat > pytest.ini << EOF
[tool:pytest]
testpaths = tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*
addopts = -v --cov=app --cov-report=html
EOF
```

### **3. Docker Setup**

```bash
# Install Docker
# Ubuntu:
sudo apt-get update
sudo apt-get install docker.io docker-compose

# macOS: Download Docker Desktop
# Windows: Download Docker Desktop

# Verify installation
docker --version
docker-compose --version
```

## ðŸ“ **Project Structure**

```bash
# Táº¡o cáº¥u trÃºc thÆ° má»¥c
mkdir -p rag_chatbot/{backend,frontend,tests,docs,data}

# Backend structure
mkdir -p rag_chatbot/backend/{app,models,services,utils}
mkdir -p rag_chatbot/backend/app/{api,core,db}

# Frontend structure
mkdir -p rag_chatbot/frontend/src/{components,pages,services,utils}

# Data directories
mkdir -p rag_chatbot/data/{documents,embeddings,vector_db}

# Create necessary files
touch rag_chatbot/backend/requirements.txt
touch rag_chatbot/backend/main.py
touch rag_chatbot/frontend/package.json
touch rag_chatbot/docker-compose.yml
touch rag_chatbot/README.md
```

## ðŸš€ **Quick Start**

### **1. Backend Setup**

```bash
cd rag_chatbot/backend

# Install dependencies
pip install -r requirements.txt

# Set environment variables
export OPENAI_API_KEY="your_key_here"

# Run development server
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

### **2. Frontend Setup**

```bash
cd rag_chatbot/frontend

# Install dependencies
npm install

# Start development server
npm start
```

### **3. Test Installation**

```bash
# Test backend
cd backend
python -m pytest tests/ -v

# Test frontend
cd frontend
npm test

# Test API
curl http://localhost:8000/health
```

## ðŸ” **Troubleshooting**

### **Common Issues:**

1. **FAISS Installation Error:**
```bash
# Ubuntu/Debian
sudo apt-get install libblas-dev liblapack-dev
pip install faiss-cpu --no-cache-dir

# macOS
brew install openblas
export LDFLAGS="-L/usr/local/opt/openblas/lib"
export CPPFLAGS="-I/usr/local/opt/openblas/include"
pip install faiss-cpu
```

2. **CUDA Issues:**
```bash
# Check CUDA version
nvidia-smi

# Install appropriate PyTorch version
# https://pytorch.org/get-started/locally/
```

3. **Memory Issues:**
```bash
# Reduce batch size in config
CHUNK_SIZE=256
BATCH_SIZE=32
```

4. **API Key Issues:**
```bash
# Verify API key
python -c "import openai; openai.api_key='your_key'; print('Valid')"
```

## ðŸ“Š **Performance Monitoring**

### **1. System Monitoring**

```bash
# Install monitoring tools
pip install psutil memory-profiler

# Monitor resource usage
python -m memory_profiler your_script.py
```

### **2. API Monitoring**

```python
# Add to FastAPI app
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
import time
import logging

app = FastAPI()

# Add CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Add logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@app.middleware("http")
async def log_requests(request, call_next):
    start_time = time.time()
    response = await call_next(request)
    process_time = time.time() - start_time
    logger.info(f"{request.method} {request.url} - {process_time:.2f}s")
    return response
```

## ðŸ”’ **Security Setup**

### **1. API Security**

```python
# Add to main.py
from fastapi import Depends, HTTPException, status
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials

security = HTTPBearer()

async def verify_token(credentials: HTTPAuthorizationCredentials = Depends(security)):
    token = credentials.credentials
    # Implement your token verification logic
    if not is_valid_token(token):
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Invalid token"
        )
    return token
```

### **2. Environment Security**

```bash
# Create .env.example (khÃ´ng chá»©a sensitive data)
cp .env .env.example
# Edit .env.example Ä‘á»ƒ remove sensitive data

# Add .env to .gitignore
echo ".env" >> .gitignore
echo "*.key" >> .gitignore
echo "vector_db/" >> .gitignore
```

## ðŸ“š **Next Steps**

1. **Complete Setup Verification:**
   - Test all components individually
   - Verify API connectivity
   - Check frontend-backend communication

2. **Data Preparation:**
   - Prepare sample documents
   - Test document processing pipeline
   - Verify embedding generation

3. **Development Workflow:**
   - Set up Git repository
   - Configure CI/CD pipeline
   - Set up development branches

4. **Production Preparation:**
   - Configure production environment
   - Set up monitoring and logging
   - Prepare deployment scripts

---

## ðŸŽ“ **CÃ¡ch há»c hiá»‡u quáº£**

### **BÆ°á»›c 1: Äá»c cÃ´ng thá»©c â†’ tra kÃ½ hiá»‡u â†’ hiá»ƒu trá»±c giÃ¡c**
- Äá»c setup instructions
- Tra cá»©u báº£ng kÃ½ hiá»‡u Ä‘á»ƒ hiá»ƒu tá»«ng component
- TÃ¬m hiá»ƒu Ã½ nghÄ©a cá»§a tá»«ng bÆ°á»›c setup

### **BÆ°á»›c 2: Äiá»n "Tháº» thuáº­t toÃ¡n" cho tá»«ng mÃ´ hÃ¬nh**
- HoÃ n thÃ nh 12 má»¥c trong tháº» thuáº­t toÃ¡n cho má»—i setup step
- Viáº¿t pseudocode vÃ  commands
- Kiá»ƒm tra checklist

### **BÆ°á»›c 3: LÃ m Lab nhá» â†’ Mini-project â†’ Case study**
- Báº¯t Ä‘áº§u vá»›i lab Ä‘Æ¡n giáº£n (Python environment)
- Tiáº¿n tá»›i mini-project phá»©c táº¡p hÆ¡n (full stack setup)
- Ãp dá»¥ng vÃ o case study thá»±c táº¿ (production deployment)

### **BÆ°á»›c 4: ÄÃ¡nh giÃ¡ báº±ng metric phÃ¹ há»£p**
- Chá»n metric Ä‘Ã¡nh giÃ¡ phÃ¹ há»£p (setup success, performance)
- So sÃ¡nh vá»›i baseline
- PhÃ¢n tÃ­ch káº¿t quáº£ vÃ  optimize

---

*ChÃºc báº¡n setup thÃ nh cÃ´ng! ðŸš€*

## ðŸ **Python Environment Setup**

### **1. Virtual Environment**

```bash
# Táº¡o virtual environment
python -m venv rag_env

# Activate environment
# Linux/macOS:
source rag_env/bin/activate
# Windows:
rag_env\Scripts\activate

# Upgrade pip
pip install --upgrade pip
```

### **2. Install Dependencies**

```bash
# Core dependencies
pip install fastapi uvicorn pydantic

# ML/AI libraries
pip install torch torchvision torchaudio
pip install transformers sentence-transformers
pip install openai anthropic

# Vector database
pip install faiss-cpu  # hoáº·c faiss-gpu náº¿u cÃ³ GPU
pip install chromadb

# Data processing
pip install pandas numpy scipy
pip install scikit-learn

# Web scraping (optional)
pip install beautifulsoup4 requests

# Evaluation
pip install nltk rouge-score

# Development tools
pip install pytest black isort
pip install jupyter notebook
```

### **3. Environment Variables**

Táº¡o file `.env`:
```bash
# OpenAI API
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-3.5-turbo

# Anthropic API (optional)
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Vector database
VECTOR_DB_PATH=./vector_db
CHUNK_SIZE=512
CHUNK_OVERLAP=50

# Server settings
HOST=0.0.0.0
PORT=8000
DEBUG=True
```

## ðŸ—„ï¸ **Vector Database Setup**

### **1. FAISS Setup**

```python
# test_faiss.py
import faiss
import numpy as np

def test_faiss_installation():
    """Test FAISS installation"""
    # Create sample data
    dimension = 384
    num_vectors = 1000
    
    # Generate random vectors
    vectors = np.random.randn(num_vectors, dimension).astype('float32')
    
    # Normalize vectors
    faiss.normalize_L2(vectors)
    
    # Create index
    index = faiss.IndexFlatIP(dimension)
    index.add(vectors)
    
    # Test search
    query = np.random.randn(1, dimension).astype('float32')
    faiss.normalize_L2(query)
    
    scores, indices = index.search(query, 5)
    
    print("FAISS test successful!")
    print(f"Found {len(indices[0])} similar vectors")
    
    return True

if __name__ == "__main__":
    test_faiss_installation()
```

### **2. ChromaDB Setup**

```python
# test_chroma.py
import chromadb
from chromadb.config import Settings

def test_chroma_installation():
    """Test ChromaDB installation"""
    # Create client
    client = chromadb.Client(Settings(
        chroma_db_impl="duckdb+parquet",
        persist_directory="./chroma_db"
    ))
    
    # Create collection
    collection = client.create_collection("test_collection")
    
    # Add documents
    documents = [
        "This is a test document about AI.",
        "Machine learning is a subset of AI.",
        "Deep learning uses neural networks."
    ]
    
    collection.add(
        documents=documents,
        metadatas=[{"source": "test"} for _ in documents],
        ids=["1", "2", "3"]
    )
    
    # Test query
    results = collection.query(
        query_texts=["What is AI?"],
        n_results=2
    )
    
    print("ChromaDB test successful!")
    print(f"Found {len(results['documents'][0])} relevant documents")
    
    return True

if __name__ == "__main__":
    test_chroma_installation()
```

## ðŸŒ **Frontend Setup**

### **1. Node.js Environment**

```bash
# Install Node.js (náº¿u chÆ°a cÃ³)
# Ubuntu/Debian:
curl -fsSL https://deb.nodesource.com/setup_18.x | sudo -E bash -
sudo apt-get install -y nodejs

# macOS:
brew install node

# Windows: Download tá»« https://nodejs.org/

# Verify installation
node --version
npm --version
```

### **2. React Frontend**

```bash
# Táº¡o React app
npx create-react-app rag-frontend
cd rag-frontend

# Install dependencies
npm install axios react-router-dom
npm install @mui/material @emotion/react @emotion/styled
npm install @mui/icons-material

# Development dependencies
npm install --save-dev @types/react @types/react-dom
```

### **3. Frontend Configuration**

Táº¡o file `src/config/api.js`:
```javascript
const API_CONFIG = {
    baseURL: process.env.REACT_APP_API_URL || 'http://localhost:8000',
    timeout: 30000,
    headers: {
        'Content-Type': 'application/json',
    }
};

export default API_CONFIG;
```

## ðŸ”§ **Development Tools Setup**

### **1. Code Quality Tools**

```bash
# Install pre-commit hooks
pip install pre-commit
pre-commit install

# Create .pre-commit-config.yaml
cat > .pre-commit-config.yaml << EOF
repos:
  - repo: https://github.com/psf/black
    rev: 23.3.0
    hooks:
      - id: black
        language_version: python3.9
  - repo: https://github.com/pycqa/isort
    rev: 5.12.0
    hooks:
      - id: isort
  - repo: https://github.com/pycqa/flake8
    rev: 6.0.0
    hooks:
      - id: flake8
EOF
```

### **2. Testing Setup**

```bash
# Install testing dependencies
pip install pytest pytest-asyncio pytest-cov
pip install httpx  # for FastAPI testing

# Create pytest.ini
cat > pytest.ini << EOF
[tool:pytest]
testpaths = tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*
addopts = -v --cov=app --cov-report=html
EOF
```

### **3. Docker Setup**

```bash
# Install Docker
# Ubuntu:
sudo apt-get update
sudo apt-get install docker.io docker-compose

# macOS: Download Docker Desktop
# Windows: Download Docker Desktop

# Verify installation
docker --version
docker-compose --version
```

## ðŸ“ **Project Structure**

```bash
# Táº¡o cáº¥u trÃºc thÆ° má»¥c
mkdir -p rag_chatbot/{backend,frontend,tests,docs,data}

# Backend structure
mkdir -p rag_chatbot/backend/{app,models,services,utils}
mkdir -p rag_chatbot/backend/app/{api,core,db}

# Frontend structure
mkdir -p rag_chatbot/frontend/src/{components,pages,services,utils}

# Data directories
mkdir -p rag_chatbot/data/{documents,embeddings,vector_db}

# Create necessary files
touch rag_chatbot/backend/requirements.txt
touch rag_chatbot/backend/main.py
touch rag_chatbot/frontend/package.json
touch rag_chatbot/docker-compose.yml
touch rag_chatbot/README.md
```

## ðŸš€ **Quick Start**

### **1. Backend Setup**

```bash
cd rag_chatbot/backend

# Install dependencies
pip install -r requirements.txt

# Set environment variables
export OPENAI_API_KEY="your_key_here"

# Run development server
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

### **2. Frontend Setup**

```bash
cd rag_chatbot/frontend

# Install dependencies
npm install

# Start development server
npm start
```

### **3. Test Installation**

```bash
# Test backend
cd backend
python -m pytest tests/ -v

# Test frontend
cd frontend
npm test

# Test API
curl http://localhost:8000/health
```

## ðŸ” **Troubleshooting**

### **Common Issues:**

1. **FAISS Installation Error:**
```bash
# Ubuntu/Debian
sudo apt-get install libblas-dev liblapack-dev
pip install faiss-cpu --no-cache-dir

# macOS
brew install openblas
export LDFLAGS="-L/usr/local/opt/openblas/lib"
export CPPFLAGS="-I/usr/local/opt/openblas/include"
pip install faiss-cpu
```

2. **CUDA Issues:**
```bash
# Check CUDA version
nvidia-smi

# Install appropriate PyTorch version
# https://pytorch.org/get-started/locally/
```

3. **Memory Issues:**
```bash
# Reduce batch size in config
CHUNK_SIZE=256
BATCH_SIZE=32
```

4. **API Key Issues:**
```bash
# Verify API key
python -c "import openai; openai.api_key='your_key'; print('Valid')"
```

## ðŸ“Š **Performance Monitoring**

### **1. System Monitoring**

```bash
# Install monitoring tools
pip install psutil memory-profiler

# Monitor resource usage
python -m memory_profiler your_script.py
```

### **2. API Monitoring**

```python
# Add to FastAPI app
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
import time
import logging

app = FastAPI()

# Add CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Add logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@app.middleware("http")
async def log_requests(request, call_next):
    start_time = time.time()
    response = await call_next(request)
    process_time = time.time() - start_time
    logger.info(f"{request.method} {request.url} - {process_time:.2f}s")
    return response
```

## ðŸ”’ **Security Setup**

### **1. API Security**

```python
# Add to main.py
from fastapi import Depends, HTTPException, status
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials

security = HTTPBearer()

async def verify_token(credentials: HTTPAuthorizationCredentials = Depends(security)):
    token = credentials.credentials
    # Implement your token verification logic
    if not is_valid_token(token):
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Invalid token"
        )
    return token
```

### **2. Environment Security**

```bash
# Create .env.example (khÃ´ng chá»©a sensitive data)
cp .env .env.example
# Edit .env.example Ä‘á»ƒ remove sensitive data

# Add .env to .gitignore
echo ".env" >> .gitignore
echo "*.key" >> .gitignore
echo "vector_db/" >> .gitignore
```

## ðŸ“š **Next Steps**

1. **Complete Setup Verification:**
   - Test all components individually
   - Verify API connectivity
   - Check frontend-backend communication

2. **Data Preparation:**
   - Prepare sample documents
   - Test document processing pipeline
   - Verify embedding generation

3. **Development Workflow:**
   - Set up Git repository
   - Configure CI/CD pipeline
   - Set up development branches

4. **Production Preparation:**
   - Configure production environment
   - Set up monitoring and logging
   - Prepare deployment scripts

---

*ChÃºc báº¡n setup thÃ nh cÃ´ng! ðŸš€*
